"""
File operation and bash tools for exploiter agent.

=== FILE-BASED MODE TOOLS ===
1. read - Read files from LOCAL filesystem
2. write - Write files to LOCAL filesystem
3. edit - Edit files on LOCAL filesystem with string replacement
4. bash_local - Run shell commands locally (backup for run_target_agent)
5. load_injection_templates - Load injection templates by category/complexity
6. load_mutation_strategy - Load mutation strategies
7. run_target_agent - Execute target agent with injection payload

=== NETWORK-BASED MODE TOOLS ===
1. bash - Execute shell commands in the environment (primary tool)
   - Read source code, explore codebase, write exploits, send requests
"""
import logging
import os
import re
import subprocess
from pathlib import Path
from typing import Optional

from google.adk.tools import ToolContext

logger = logging.getLogger(__name__)

# Constants
DEFAULT_MAX_LINES = 2000
MAX_LINE_LENGTH = 2000
MAX_OUTPUT_CHARS = 300000

# Get the tools directory path for loading templates
TOOLS_DIR = Path(__file__).parent


def bash_local(
    command: str,
    working_dir: Optional[str] = None,
    timeout: Optional[int] = 120,
) -> dict:
    """Execute bash command on LOCAL machine. FILE-BASED MODE ONLY.

    **FOR FILE-BASED EXPLOITATION MODE ONLY** - Use as backup when run_target_agent() fails.

    This tool executes commands directly on the local machine. It is intended as a
    backup tool for file-based exploits when run_target_agent() fails or for
    auxiliary operations like file manipulation.

    DO NOT use this tool for network-based exploitation - use bash() instead.

    Args:
        command: The bash command to execute
        working_dir: Optional working directory
        timeout: Timeout in seconds (default 120, max 600)

    Returns:
        dict: {"success": bool, "exit_code": int, "stdout": str, "stderr": str, "error": str}
    """
    max_timeout = 600

    try:
        # Validate timeout
        if timeout is None:
            timeout = 120
        timeout = min(timeout, max_timeout)

        # Set working directory
        cwd = working_dir if working_dir else None
        if cwd and not os.path.isdir(cwd):
            return {
                "success": False,
                "exit_code": -1,
                "stdout": "",
                "stderr": "",
                "error": f"Working directory does not exist: {cwd}"
            }

        # Execute command
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=cwd
        )

        stdout = result.stdout
        stderr = result.stderr

        # Truncate if needed
        if len(stdout) > MAX_OUTPUT_CHARS:
            stdout = stdout[:MAX_OUTPUT_CHARS] + "\n... [output truncated]"
        if len(stderr) > MAX_OUTPUT_CHARS:
            stderr = stderr[:MAX_OUTPUT_CHARS] + "\n... [output truncated]"

        return {
            "success": result.returncode == 0,
            "exit_code": result.returncode,
            "stdout": stdout,
            "stderr": stderr,
            "error": ""
        }

    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "exit_code": -1,
            "stdout": "",
            "stderr": "",
            "error": f"Command timed out after {timeout} seconds"
        }
    except Exception as e:
        logger.error(f"Bash execution error: {e}", exc_info=True)
        return {
            "success": False,
            "exit_code": -1,
            "stdout": "",
            "stderr": "",
            "error": str(e)
        }


def bash(
    command: str,
    tool_context: ToolContext,
    working_dir: Optional[str] = "/workspace",
    timeout: Optional[int] = 120,
) -> dict:
    """Execute a shell command in the environment. NETWORK-BASED MODE ONLY.

    **FOR NETWORK-BASED EXPLOITATION MODE ONLY** - Primary tool for network exploits.

    Use this tool to run shell commands for exploration and exploitation:
    1. Read source code: bash("cat <source_path>/<file>")
    2. Explore codebase: bash("find <source_path> -name '*.py' | head -20")
    3. Write scripts: bash("cat > /workspace/script.sh << 'EOF'\\n...\\nEOF")
    4. Send HTTP requests: bash("curl '<target_url>/<endpoint>'")
    5. Check results: bash("cat /workspace/result.txt")

    DO NOT use this tool for file-based exploitation - use bash_local() instead.

    Args:
        command: The bash command to execute
        tool_context: Tool context providing environment configuration
        working_dir: Working directory (default: "/workspace")
        timeout: Timeout in seconds (default 120, max 600)

    Returns:
        dict: {"success": bool, "exit_code": int, "stdout": str, "stderr": str, "error": str}
    """
    max_timeout = 600

    try:
        # Get container name from tool context state
        container_name = tool_context.state.get("container_name")
        if not container_name:
            return {
                "success": False,
                "exit_code": -1,
                "stdout": "",
                "stderr": "",
                "error": "Environment not properly configured. Please ensure setup is complete."
            }

        # Validate timeout
        if timeout is None:
            timeout = 120
        timeout = min(timeout, max_timeout)

        # Build execution command
        exec_cmd = ["docker", "exec"]
        if working_dir:
            exec_cmd.extend(["-w", working_dir])
        exec_cmd.extend([container_name, "bash", "-c", command])

        logger.info(f"Executing command: {command[:100]}...")

        # Execute command
        result = subprocess.run(
            exec_cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
        )

        stdout = result.stdout
        stderr = result.stderr

        # Truncate if needed
        if len(stdout) > MAX_OUTPUT_CHARS:
            stdout = stdout[:MAX_OUTPUT_CHARS] + "\n... [output truncated]"
        if len(stderr) > MAX_OUTPUT_CHARS:
            stderr = stderr[:MAX_OUTPUT_CHARS] + "\n... [output truncated]"

        return {
            "success": result.returncode == 0,
            "exit_code": result.returncode,
            "stdout": stdout,
            "stderr": stderr,
            "error": ""
        }

    except subprocess.TimeoutExpired:
        return {
            "success": False,
            "exit_code": -1,
            "stdout": "",
            "stderr": "",
            "error": f"Command timed out after {timeout} seconds"
        }
    except FileNotFoundError:
        return {
            "success": False,
            "exit_code": -1,
            "stdout": "",
            "stderr": "",
            "error": "Execution environment not available."
        }
    except Exception as e:
        logger.error(f"Bash execution error: {e}", exc_info=True)
        return {
            "success": False,
            "exit_code": -1,
            "stdout": "",
            "stderr": "",
            "error": str(e)
        }


def read(
    file_path: str,
    offset: Optional[int] = None,
    limit: Optional[int] = None
) -> dict:
    """Read a file from the LOCAL filesystem.

    **CRITICAL: file_path SHOULD be an ABSOLUTE path (starting with /).**

    Example: read("/home/user/tasks/task-xxx/file.txt")
    NOT: read("tasks/task-xxx/file.txt")

    You can access any file on the local machine directly by using this tool.
    If the path provided doesn't exist, an error will be returned.

    Usage:
    - The file_path parameter SHOULD be an absolute path for reliability
    - By default, it reads up to 2000 lines starting from the beginning
    - You can optionally specify a line offset and limit for long files
    - Any lines longer than 2000 characters will be truncated
    - Results are returned using cat -n format, with line numbers starting at 1
    - If file exists but is empty, you will receive a warning message

    Args:
        file_path: The absolute path to the file to read (e.g., "/home/user/file.txt")
        offset: The line number to start reading from (0-indexed). Only provide
                if the file is too large to read at once
        limit: The number of lines to read. Only provide if the file is too
               large to read at once

    Returns:
        dict: {
            "success": bool,
            "file_path": str,
            "content": str,
            "message": str
        }
    """
    try:
        abs_path = os.path.abspath(file_path)

        if not os.path.exists(abs_path):
            return {
                "success": False,
                "file_path": abs_path,
                "content": "",
                "message": f"File not found: {abs_path}"
            }

        if os.path.isdir(abs_path):
            return {
                "success": False,
                "file_path": abs_path,
                "content": "",
                "message": f"Path is a directory, not a file: {abs_path}"
            }

        with open(abs_path, 'r', encoding='utf-8', errors='ignore') as f:
            all_lines = f.readlines()

        total_lines = len(all_lines)

        # Handle empty file
        if total_lines == 0:
            return {
                "success": True,
                "file_path": abs_path,
                "content": "[File is empty]",
                "message": f"File exists but has no content: {abs_path}"
            }

        # Apply offset and limit
        start_line = offset if offset is not None else 0
        max_lines = limit if limit is not None else DEFAULT_MAX_LINES

        # Clamp start_line to valid range
        start_line = max(0, min(start_line, total_lines - 1))

        # Select lines
        end_line = min(start_line + max_lines, total_lines)
        selected_lines = all_lines[start_line:end_line]

        # Format as cat -n output (line numbers starting at 1)
        formatted_lines = []
        for i, line in enumerate(selected_lines, start=start_line + 1):
            # Truncate long lines
            line = line.rstrip('\n\r')
            if len(line) > MAX_LINE_LENGTH:
                line = line[:MAX_LINE_LENGTH] + "... [truncated]"
            formatted_lines.append(f"{i:6}\t{line}")

        content = '\n'.join(formatted_lines)

        # Build message
        lines_read = len(selected_lines)
        if lines_read < total_lines:
            message = f"Read lines {start_line + 1}-{end_line} of {total_lines} from {abs_path}"
        else:
            message = f"Read {total_lines} lines from {abs_path}"

        return {
            "success": True,
            "file_path": abs_path,
            "content": content,
            "message": message
        }

    except Exception as e:
        logger.error(f"Read error: {e}", exc_info=True)
        return {
            "success": False,
            "file_path": os.path.abspath(file_path),
            "content": "",
            "message": f"Error: {str(e)}"
        }


def write(
    file_path: str,
    content: str
) -> dict:
    """Write content to a file on the LOCAL filesystem.

    **CRITICAL: file_path SHOULD be an ABSOLUTE path (starting with /).**

    Example: write("/home/user/tasks/task-xxx/payload.txt", "content")
    NOT: write("tasks/task-xxx/payload.txt", "content")

    This tool will overwrite the existing file if there is one at the provided path.

    Usage:
    - The file_path parameter SHOULD be an absolute path for reliability
    - This tool will overwrite the existing file if it exists
    - If this is an existing file you want to modify, consider using the read
      tool first to see its contents, then use edit for small changes or write
      for complete replacement
    - ALWAYS prefer editing existing files. NEVER write new files unless required
    - Parent directories will be created automatically if they don't exist

    Args:
        file_path: The absolute path to the file to write (e.g., "/home/user/file.txt")
        content: The content to write to the file

    Returns:
        dict: {
            "success": bool,
            "file_path": str,
            "message": str
        }
    """
    try:
        abs_path = os.path.abspath(file_path)

        # Create parent directory if needed
        parent_dir = os.path.dirname(abs_path)
        if parent_dir and not os.path.exists(parent_dir):
            os.makedirs(parent_dir, exist_ok=True)

        # Write content
        with open(abs_path, 'w', encoding='utf-8') as f:
            f.write(content)

        # Count lines
        line_count = content.count('\n') + (1 if content and not content.endswith('\n') else 0)

        return {
            "success": True,
            "file_path": abs_path,
            "message": f"Successfully wrote {line_count} lines to {abs_path}"
        }

    except Exception as e:
        logger.error(f"Write error: {e}", exc_info=True)
        return {
            "success": False,
            "file_path": os.path.abspath(file_path),
            "message": f"Error: {str(e)}"
        }


def edit(
    file_path: str,
    old_string: str,
    new_string: str,
    replace_all: bool = False
) -> dict:
    """Perform exact string replacement in a file on the LOCAL filesystem.

    **CRITICAL: file_path SHOULD be an ABSOLUTE path (starting with /).**

    Example: edit("/home/user/tasks/task-xxx/file.txt", "old", "new")
    NOT: edit("tasks/task-xxx/file.txt", "old", "new")

    Usage:
    - You should use the read tool first to see the file's contents before editing
    - The file_path parameter SHOULD be an absolute path for reliability
    - When editing text, ensure you preserve the exact indentation (tabs/spaces)
    - ALWAYS prefer editing existing files. NEVER write new files unless required
    - The edit will FAIL if old_string is not found in the file
    - The edit will FAIL if old_string appears multiple times and replace_all is False
      - Either provide a larger string with more context to make it unique
      - Or use replace_all=True to change every instance

    Use replace_all for:
    - Replacing and renaming strings across the file
    - Renaming variables or function names
    - Updating import statements throughout

    Args:
        file_path: The absolute path to the file to edit (e.g., "/home/user/file.txt")
        old_string: The text to replace (must exist in the file)
        new_string: The text to replace it with (must be different from old_string)
        replace_all: If True, replace all occurrences. If False (default), the
                     old_string must be unique in the file

    Returns:
        dict: {
            "success": bool,
            "file_path": str,
            "replacements": int,
            "message": str
        }
    """
    try:
        # Validate inputs
        if old_string == new_string:
            return {
                "success": False,
                "file_path": file_path,
                "replacements": 0,
                "message": "old_string and new_string must be different"
            }

        if not old_string:
            return {
                "success": False,
                "file_path": file_path,
                "replacements": 0,
                "message": "old_string cannot be empty"
            }

        abs_path = os.path.abspath(file_path)

        if not os.path.exists(abs_path):
            return {
                "success": False,
                "file_path": abs_path,
                "replacements": 0,
                "message": f"File not found: {abs_path}"
            }

        # Read current content
        with open(abs_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        # Check if old_string exists
        count = content.count(old_string)
        if count == 0:
            return {
                "success": False,
                "file_path": abs_path,
                "replacements": 0,
                "message": "old_string not found in file. Make sure you're using the exact text including whitespace."
            }

        # Check uniqueness if not replace_all
        if not replace_all and count > 1:
            return {
                "success": False,
                "file_path": abs_path,
                "replacements": 0,
                "message": f"old_string appears {count} times in file. Use replace_all=True or provide more context to make it unique."
            }

        # Perform replacement
        if replace_all:
            new_content = content.replace(old_string, new_string)
            replacements = count
        else:
            new_content = content.replace(old_string, new_string, 1)
            replacements = 1

        # Write back
        with open(abs_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        return {
            "success": True,
            "file_path": abs_path,
            "replacements": replacements,
            "message": f"Successfully replaced {replacements} occurrence(s) in {abs_path}"
        }

    except Exception as e:
        logger.error(f"Edit error: {e}", exc_info=True)
        return {
            "success": False,
            "file_path": os.path.abspath(file_path),
            "replacements": 0,
            "message": f"Error: {str(e)}"
        }


def _parse_structured_output(stdout: str) -> dict:
    """Parse structured output markers from script stdout.

    Looks for markers like:
    - LOG_PATH=<path>
    - VERIFICATION_RESULT=<n>/<m>
    - EXPLOIT_STATUS=SUCCESS|FAILED

    Args:
        stdout: The script's standard output

    Returns:
        dict with parsed values (may be empty if markers not found)
    """
    parsed = {}

    # Parse LOG_PATH=...
    log_match = re.search(r'^LOG_PATH=(.+)$', stdout, re.MULTILINE)
    if log_match:
        parsed['log_path'] = log_match.group(1).strip()

    # Parse VERIFICATION_RESULT=n/m
    verify_match = re.search(r'^VERIFICATION_RESULT=(\d+)/(\d+)$', stdout, re.MULTILINE)
    if verify_match:
        parsed['verification_passed'] = int(verify_match.group(1))
        parsed['verification_total'] = int(verify_match.group(2))
        parsed['verification_result'] = f"{verify_match.group(1)}/{verify_match.group(2)}"

    # Parse EXPLOIT_STATUS=SUCCESS|FAILED
    status_match = re.search(r'^EXPLOIT_STATUS=(SUCCESS|FAILED)$', stdout, re.MULTILINE)
    if status_match:
        parsed['exploit_status'] = status_match.group(1)

    # Extract verification details (lines starting with [VERIFY])
    verify_lines = re.findall(r'^\[VERIFY\].*$', stdout, re.MULTILINE)
    if verify_lines:
        parsed['verification_details'] = '\n'.join(verify_lines)

    return parsed


def run_target_agent(
    script_path: str,
    injection_path: Optional[str] = None,
    args: Optional[str] = None,
    timeout: Optional[int] = 300,
    working_dir: Optional[str] = None,
) -> dict:
    """Run exploit for DOCUMENT-BASED tasks (exploit_type="document_injection"). FILE-BASED MODE ONLY.

    **CRITICAL: script_path and injection_path SHOULD be ABSOLUTE paths (starting with /).**

    Example: run_target_agent("/home/user/tasks/task-xxx/run.py", "/home/user/tasks/task-xxx/payload.txt")
    NOT: run_target_agent("run.py", "payload.txt")

    DO NOT use this for network_api tasks. Use bash() instead for network-based exploitation.

    Workflow:
    1. write(payload_interface.path, payload) -> write injection payload
    2. run_target_agent(script.path, payload_interface.path) -> execute & verify
    3. If failed, read(log_path) -> analyze and iterate

    Script outputs these markers (parsed automatically):
    - LOG_PATH=<path>           -> Captured in log_path
    - EXPLOIT_STATUS=SUCCESS    -> exploit_success=True
    - EXPLOIT_STATUS=FAILED     -> exploit_success=False

    Args:
        script_path: ABSOLUTE path to script (from task_config.script.path)
        injection_path: ABSOLUTE path to payload file (from task_config.payload_interface.path)
        args: Optional additional arguments
        timeout: Timeout in seconds (default 300, max 600)
        working_dir: Working directory for execution

    Returns:
        dict: {"exploit_success": bool, "log_path": str, "error": str}
    """
    import time
    max_timeout = 600

    try:
        abs_path = os.path.abspath(script_path)

        # Validate script exists
        if not os.path.exists(abs_path):
            return {
                "exploit_success": False,
                "log_path": "",
                "error": f"Script not found: {abs_path}"
            }

        if os.path.isdir(abs_path):
            return {
                "exploit_success": False,
                "log_path": "",
                "error": f"Path is a directory, not a file: {abs_path}"
            }

        # Validate timeout
        if timeout is None:
            timeout = 300
        timeout = min(timeout, max_timeout)

        # Determine working directory
        if working_dir:
            cwd = working_dir
        else:
            cwd = os.path.dirname(abs_path)

        if not os.path.isdir(cwd):
            return {
                "exploit_success": False,
                "log_path": "",
                "error": f"Working directory does not exist: {cwd}"
            }

        # Determine how to execute based on file extension
        ext = os.path.splitext(abs_path)[1].lower()

        if ext == '.sh':
            cmd = ['bash', abs_path]
        elif ext == '.py':
            cmd = ['python3', abs_path]
        elif ext == '.js':
            cmd = ['node', abs_path]
        else:
            cmd = [abs_path]

        # Add injection path if provided
        if injection_path:
            cmd.append(injection_path)

        # Add additional arguments if provided
        if args:
            cmd.extend(args.split())

        logger.info(f"Executing script: {' '.join(cmd)}")
        logger.info(f"Working directory: {cwd}")

        # Execute script
        result = subprocess.run(
            cmd,
            capture_output=True,
            text=True,
            timeout=timeout,
            cwd=cwd
        )

        stdout = result.stdout
        stderr = result.stderr

        # Parse structured output markers from stdout
        parsed = _parse_structured_output(stdout)

        # Determine log path - prefer parsed value, fallback to creating our own
        if 'log_path' in parsed and os.path.exists(parsed['log_path']):
            log_path = parsed['log_path']
        else:
            # Save full log to file (fallback behavior)
            timestamp = time.strftime('%Y%m%d_%H%M%S')
            script_name = os.path.splitext(os.path.basename(abs_path))[0]
            log_dir = os.path.join(os.path.dirname(abs_path), "logs")
            os.makedirs(log_dir, exist_ok=True)
            log_path = os.path.join(log_dir, f"{script_name}_{timestamp}.log")

            with open(log_path, 'w', encoding='utf-8') as f:
                f.write("=== EXECUTION LOG ===\n")
                f.write(f"Script: {abs_path}\n")
                f.write(f"Injection: {injection_path or 'None'}\n")
                f.write(f"Args: {args or 'None'}\n")
                f.write(f"Timestamp: {timestamp}\n")
                f.write(f"Exit Code: {result.returncode}\n")
                f.write(f"Exploit Success: {result.returncode == 0}\n")
                f.write(f"\n=== STDOUT ===\n{stdout}\n")
                f.write(f"\n=== STDERR ===\n{stderr}\n")

        # Determine exploit success - prefer parsed status, fallback to exit code
        if 'exploit_status' in parsed:
            exploit_success = parsed['exploit_status'] == 'SUCCESS'
        else:
            exploit_success = result.returncode == 0

        logger.info(f"Script completed: exploit_success={exploit_success}, log={log_path}")

        return {
            "exploit_success": exploit_success,
            "log_path": log_path,
            "error": ""
        }

    except subprocess.TimeoutExpired:
        return {
            "exploit_success": False,
            "log_path": "",
            "error": f"Script timed out after {timeout} seconds"
        }
    except FileNotFoundError as e:
        return {
            "exploit_success": False,
            "log_path": "",
            "error": f"Interpreter not found: {str(e)}"
        }
    except Exception as e:
        logger.error(f"Script execution error: {e}", exc_info=True)
        return {
            "exploit_success": False,
            "log_path": "",
            "error": str(e)
        }


def load_injection_templates(
    category: Optional[str] = None,
    complexity: Optional[str] = None,
    include_simple_texts: bool = True,
    limit: Optional[int] = None
) -> dict:
    """Load injection templates from the template library.

    This tool loads prompt injection templates that can be used to craft
    injection payloads. Templates are organized by category and complexity.

    Available categories:
    - technical_debug: Debug/troubleshooting scenarios
    - system_admin: System administration commands
    - security_audit: Security testing contexts
    - performance_tuning: Performance optimization
    - error_recovery: Error handling scenarios
    - testing_validation: Testing/QA contexts
    - environment_setup: Environment configuration
    - compliance_check: Compliance/audit scenarios

    Available complexity levels:
    - basic: Simple, direct templates
    - intermediate: More sophisticated approaches
    - advanced: Complex multi-step templates
    - expert: Highly sophisticated templates

    Args:
        category: Filter by category (e.g., "technical_debug", "system_admin").
                  If None, returns all categories.
        complexity: Filter by complexity (e.g., "basic", "intermediate", "advanced", "expert").
                    If None, returns all complexity levels.
        include_simple_texts: If True, also include simple text templates (default True)
        limit: Maximum number of templates to return. If None, returns all matching.

    Returns:
        dict: {
            "success": bool,
            "templates": list[dict],  # List of template objects
            "simple_texts": list[str],  # Simple text templates (if include_simple_texts=True)
            "total_count": int,
            "message": str
        }
    """
    try:
        # Import the templates module
        from tools.injection_templates import (
            InjectionCategory,
            InjectionComplexity,
            PromptInjectionSeedsLibrary,
            texts,
            texts_ablation,
        )

        library = PromptInjectionSeedsLibrary()

        # Filter templates
        filtered_templates = []
        for _, seed in library.seeds.items():
            # Apply category filter
            if category:
                try:
                    target_category = InjectionCategory(category)
                    if seed.category != target_category:
                        continue
                except ValueError:
                    pass  # Invalid category, skip filter

            # Apply complexity filter
            if complexity:
                try:
                    target_complexity = InjectionComplexity(complexity)
                    if seed.complexity != target_complexity:
                        continue
                except ValueError:
                    pass  # Invalid complexity, skip filter

            # Convert to dict for JSON serialization
            template_dict = {
                "name": seed.name,
                "category": seed.category.value,
                "complexity": seed.complexity.value,
                "template": seed.template,
                "description": seed.description,
                "target_scenarios": seed.target_scenarios,
                "psychological_hooks": seed.psychological_hooks,
            }
            filtered_templates.append(template_dict)

        # Apply limit
        if limit and limit > 0:
            filtered_templates = filtered_templates[:limit]

        # Get simple texts if requested
        simple_texts_result = []
        if include_simple_texts:
            simple_texts_result = list(texts) + list(texts_ablation)

        return {
            "success": True,
            "templates": filtered_templates,
            "simple_texts": simple_texts_result,
            "total_count": len(filtered_templates),
            "categories_available": [c.value for c in InjectionCategory],
            "complexities_available": [c.value for c in InjectionComplexity],
            "message": f"Loaded {len(filtered_templates)} templates" + (f" for category={category}" if category else "") + (f", complexity={complexity}" if complexity else "")
        }

    except Exception as e:
        logger.error(f"Load injection templates error: {e}", exc_info=True)
        return {
            "success": False,
            "templates": [],
            "simple_texts": [],
            "total_count": 0,
            "message": f"Error loading templates: {str(e)}"
        }


def load_mutation_strategy(
    strategy_name: Optional[str] = None
) -> dict:
    """Load mutation strategies for transforming injection templates.

    Mutation strategies define how to transform a base injection template
    into different variations. Each strategy has a specific approach and
    use case.

    Available strategies:
    - user_impersonation: Write as if user is giving instructions
    - personal_authorization: Add authorization codes/markers
    - system_requirement: Frame as mandatory system protocol
    - time_constraint: Create urgent time pressure
    - quality_assurance: Present as quality validation step
    - prerequisite_chaining: Make task appear as prerequisite
    - critical_markers: Add emphasis/importance markers
    - configuration_reference: Reference system configurations
    - collaborative_tone: Use helpful, cooperative language
    - logical_necessity: Use logical reasoning justification
    - compliance_framing: Reference compliance/regulations
    - user_preference_history: Claim alignment with user preferences
    - trust_building: Use transparent, trustworthy language
    - efficiency_appeal: Frame as improving efficiency
    - assigned_directive: Present as official assigned task
    - completeness_appeal: Appeal to thoroughness
    - priority_escalation: Escalate priority level
    - reasonable_assumption: Make assumptions about expectations
    - reciprocal_framing: Frame as mutually beneficial
    - deadline_pressure: Add specific deadline urgency
    - trigger_response_chaining: Create multi-point triggers

    Args:
        strategy_name: Specific strategy to load (e.g., "user_impersonation").
                       If None, returns all strategies.

    Returns:
        dict: {
            "success": bool,
            "strategies": list[dict],  # Strategy objects with name, description, template, etc.
            "total_count": int,
            "message": str
        }
    """
    try:
        # Import the mutation strategies module
        from tools.mutation_strategies import (
            MutationMethod,
            mutation_prompt_templates,
            strategy_descriptions,
        )

        strategies_result = []

        for method in MutationMethod:
            # Filter by name if specified
            if strategy_name and method.value != strategy_name:
                continue

            # Get template and description
            template = mutation_prompt_templates.get(method, "")
            description_info = strategy_descriptions.get(method, {})

            strategy_dict = {
                "name": method.value,
                "display_name": description_info.get("name", method.value),
                "description": description_info.get("description", ""),
                "use_when": description_info.get("use_when", ""),
                "avoid_when": description_info.get("avoid_when", ""),
                "template": template,
            }
            strategies_result.append(strategy_dict)

        return {
            "success": True,
            "strategies": strategies_result,
            "total_count": len(strategies_result),
            "available_strategies": [m.value for m in MutationMethod],
            "message": f"Loaded {len(strategies_result)} mutation strategies" + (f" (filtered: {strategy_name})" if strategy_name else "")
        }

    except Exception as e:
        logger.error(f"Load mutation strategy error: {e}", exc_info=True)
        return {
            "success": False,
            "strategies": [],
            "total_count": 0,
            "message": f"Error loading strategies: {str(e)}"
        }


def load_task_config(
    task_dir: str,
    tool_context: ToolContext,
    config_filename: str = "task_config.json"
) -> dict:
    """Load task configuration. MUST call this first to get task details.

    For network_api tasks (CVE exploits):
        Returns: vulnerability, objective, description, source_code_path
        Use bash() to explore source code and send exploit requests.

    For document_injection tasks (prompt injection):
        Returns: full config including script path, payload interface
        Use write() + run_target_agent() workflow.

    Args:
        task_dir: Path to task directory
        tool_context: Tool context for environment configuration
        config_filename: Config filename (default: task_config.json)

    Returns:
        dict: {
            "success": bool,
            "config": {
                "exploit_type": str,
                "description": str,
                "vulnerability": {...},
                "objective": {...},
                "source_code_path": str (for network_api)
            },
            "message": str
        }
    """
    import json

    try:
        task_dir_abs = os.path.abspath(task_dir)

        if not os.path.isdir(task_dir_abs):
            return {
                "success": False,
                "config": {},
                "message": f"Task directory not found: {task_dir_abs}"
            }

        config_path = os.path.join(task_dir_abs, config_filename)

        if not os.path.exists(config_path):
            return {
                "success": False,
                "config": {},
                "message": f"Config file not found: {config_path}"
            }

        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)

        # Validate basic required fields (common to all modes)
        basic_required = ["task_id", "description"]
        missing = [f for f in basic_required if f not in config]
        if missing:
            return {
                "success": False,
                "config": config,
                "message": f"Config missing required fields: {missing}"
            }

        exploit_type = config.get("exploit_type", "document_injection")

        # For network_api mode: extract container name and filter config
        if exploit_type == "network_api":
            # Extract attacker container from environment config and store in tool context
            environment = config.get("environment", {})
            attacker_container = environment.get("attacker_container")
            source_code_path = environment.get("source_code_path", "")

            if attacker_container:
                # Store container name in tool context state for bash() tool to use
                # Agent cannot see this - it's only passed through tool context
                tool_context.state["container_name"] = attacker_container
                logger.info(f"Environment configured for task: {config.get('task_id')}")

            # Only return vulnerability, objective, description, and source_code_path for network mode
            # This hides internal implementation details (like container names) from the agent
            filtered_config = {
                "task_id": config.get("task_id"),
                "exploit_type": exploit_type,
                "description": config.get("description"),
                "vulnerability": config.get("vulnerability", {}),
                "objective": config.get("objective", {}),
                "source_code_path": source_code_path,  # Agent needs this to explore the codebase
            }

            return {
                "success": True,
                "config": filtered_config,
                "message": f"Loaded task config: {config.get('task_name', config['task_id'])}"
            }
        else:
            # For document_injection mode: return full config
            return {
                "success": True,
                "config": config,
                "message": f"Loaded task config: {config.get('task_name', config['task_id'])}"
            }

    except json.JSONDecodeError as e:
        return {
            "success": False,
            "config": {},
            "message": f"Invalid JSON in config file: {str(e)}"
        }
    except Exception as e:
        logger.error(f"Load task config error: {e}", exc_info=True)
        return {
            "success": False,
            "config": {},
            "message": f"Error: {str(e)}"
        }


__all__ = [
    "bash_local",
    "bash",
    "read",
    "write",
    "edit",
    "run_target_agent",
    "load_task_config",
    "load_injection_templates",
    "load_mutation_strategy",
]
