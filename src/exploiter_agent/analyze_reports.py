#!/usr/bin/env python3
"""
Analyze exploit reports to count tool calls and determine success/failure status.
A report is considered failed if it has no 'final_response' field.
"""

import json
import os
from pathlib import Path


def analyze_report(file_path: str) -> dict:
    """
    Analyze a single report file.

    Returns:
        Dict with keys:
        - filename: report filename
        - tool_calls: number of tool_call entries (not tool_response)
        - total_entries: total entries in tool_calls array
        - has_final_response: whether final_response exists and is not None/empty
        - status: 'success' or 'fail'
        - session_id: session ID from report
        - task_path: task path from report
    """
    with open(file_path, encoding='utf-8') as f:
        data = json.load(f)

    tool_calls_array = data.get('tool_calls', [])

    # Count only entries with type == 'tool_call' (not 'tool_response')
    tool_call_count = sum(1 for entry in tool_calls_array if entry.get('type') == 'tool_call')

    # Check if final_response exists and is not None/empty
    final_response = data.get('final_response')
    has_final_response = bool(final_response and final_response.strip())

    return {
        'filename': os.path.basename(file_path),
        'tool_calls': tool_call_count,
        'total_entries': len(tool_calls_array),
        'has_final_response': has_final_response,
        'status': 'success' if has_final_response else 'fail',
        'session_id': data.get('session_id', 'N/A'),
        'task_path': data.get('task_path', 'N/A'),
    }


def analyze_reports_directory(reports_dir: str) -> list[dict]:
    """
    Analyze all JSON report files in a directory.

    Returns:
        List of analysis results for each report
    """
    reports_path = Path(reports_dir)
    results = []

    for json_file in sorted(reports_path.glob('*.json')):
        try:
            result = analyze_report(str(json_file))
            results.append(result)
        except Exception as e:
            results.append({
                'filename': json_file.name,
                'tool_calls': 0,
                'total_entries': 0,
                'has_final_response': False,
                'status': 'error',
                'error': str(e),
            })

    return results


def print_step_analysis(results: list[dict], max_step: int = 50) -> None:
    """
    Print success rate analysis at different step thresholds.
    A report is considered successful at step N if:
    - It has final_response AND tool_calls <= N
    """
    total = len(results)
    if total == 0:
        print("No reports to analyze.")
        return

    # Milestone thresholds analysis
    thresholds = [10, 20, 50, 100]
    print("\n" + "=" * 50)
    print("SUCCESS RATE BY STEP THRESHOLD")
    print("=" * 50)
    print("(Success = has final_response AND tool_calls <= threshold)")
    print("-" * 50)

    for threshold in thresholds:
        success_at_threshold = sum(
            1 for r in results
            if r['status'] == 'success' and r['tool_calls'] <= threshold
        )
        print(f"  <= {threshold:3d} steps: {success_at_threshold}/{total}")

    # Count reports that succeeded but took >100 steps (still count as fail for >100 analysis)
    success_over_100 = sum(
        1 for r in results
        if r['status'] == 'success' and r['tool_calls'] > 100
    )
    fail_count = sum(1 for r in results if r['status'] == 'fail')
    total_fail_at_100 = fail_count + success_over_100
    print(f"  > 100 steps (fail): {total_fail_at_100}/{total}")

    # Per-step cumulative success rate (1-50)
    print("\n" + "=" * 50)
    print(f"CUMULATIVE SUCCESS RATE BY STEP (1-{max_step})")
    print("=" * 50)
    print("(Success = has final_response AND tool_calls <= step)")
    print("-" * 50)

    for step in range(1, max_step + 1):
        success_at_step = sum(
            1 for r in results
            if r['status'] == 'success' and r['tool_calls'] <= step
        )
        print(f"  Step {step:2d}: {success_at_step}/{total}")


def print_results(results: list[dict]) -> None:
    """Print analysis results in a formatted table."""

    # Calculate column widths
    max_filename = max(len(r['filename']) for r in results)
    max_filename = max(max_filename, len('Filename'))

    # Print header
    header = f"{'Filename':<{max_filename}} | {'Tool Calls':>10} | {'Total Entries':>13} | {'Status':>8}"
    separator = '-' * len(header)

    print("\n" + "=" * len(header))
    print("REPORT ANALYSIS")
    print("=" * len(header))
    print(header)
    print(separator)

    # Print each result
    success_count = 0
    fail_count = 0
    total_tool_calls = 0

    for r in results:
        status_display = r['status'].upper()
        if r['status'] == 'success':
            success_count += 1
        elif r['status'] == 'fail':
            fail_count += 1

        total_tool_calls += r['tool_calls']

        print(f"{r['filename']:<{max_filename}} | {r['tool_calls']:>10} | {r['total_entries']:>13} | {status_display:>8}")

    # Print summary
    print(separator)
    print("\nSUMMARY:")
    print(f"  Total reports:     {len(results)}")
    print(f"  Successful:        {success_count}")
    print(f"  Failed:            {fail_count}")
    print(f"  Success rate:      {success_count/len(results)*100:.1f}%" if results else "N/A")
    print(f"  Total tool calls:  {total_tool_calls}")
    print(f"  Avg tool calls:    {total_tool_calls/len(results):.1f}" if results else "N/A")
    print()


def export_to_csv(results: list[dict], output_file: str) -> None:
    """Export results to CSV file."""
    import csv

    with open(output_file, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['filename', 'tool_calls', 'total_entries', 'has_final_response', 'status']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        for r in results:
            writer.writerow({k: v for k, v in r.items() if k in fieldnames})

    print(f"Results exported to: {output_file}")


def main():
    import argparse

    parser = argparse.ArgumentParser(description='Analyze exploit reports')
    parser.add_argument('reports_dir', nargs='?',
                       default='/home/shiqiu/AgentXploit/src/exploiter_agent/reports',
                       help='Directory containing report JSON files')
    parser.add_argument('--csv', '-c', type=str, help='Export results to CSV file')
    parser.add_argument('--json', '-j', type=str, help='Export results to JSON file')

    args = parser.parse_args()

    if not os.path.isdir(args.reports_dir):
        print(f"Error: {args.reports_dir} is not a valid directory")
        return 1

    results = analyze_reports_directory(args.reports_dir)
    print_results(results)
    print_step_analysis(results)

    if args.csv:
        export_to_csv(results, args.csv)

    if args.json:
        with open(args.json, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
        print(f"Results exported to: {args.json}")

    return 0


if __name__ == '__main__':
    exit(main())
