# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Injection Analysis Exporter

This module handles the export of injection analysis results to structured JSON files.
It creates comprehensive analysis reports that follow the same naming convention as 
the original task files and saves them to the injection_analysis directory.

Features:
- Structured JSON output with comprehensive metadata
- Consistent naming convention matching original tasks
- Rich analysis data preservation
- Export to configured injection_analysis directory
"""

import json
import os
import logging
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class InjectionAnalysisExporter:
    """
    Handles export of injection analysis results to structured JSON files
    """
    
    def __init__(self, output_directory: str = None):
        """
        Initialize the exporter
        
        Args:
            output_directory: Directory to save analysis files. If None, uses default.
        """
        self.output_directory = output_directory or "/home/shiqiu/AgentXploit/exploit_trace/injection_analysis"
        self._ensure_output_directory()
    
    def _ensure_output_directory(self):
        """Ensure the output directory exists"""
        try:
            Path(self.output_directory).mkdir(parents=True, exist_ok=True)
            logger.info(f"Output directory ensured: {self.output_directory}")
        except Exception as e:
            logger.error(f"Failed to create output directory {self.output_directory}: {e}")
            raise
    
    def export_analysis(self, 
                       task_id: str,
                       original_input: str,
                       target_command: str,
                       prompt_generation_result: Dict[str, Any],
                       injection_point_result: Dict[str, Any],
                       metadata: Dict[str, Any] = None) -> str:
        """
        Export comprehensive injection analysis to JSON file
        
        Args:
            task_id: Unique identifier for the task (used for filename)
            original_input: The original user input/task
            target_command: The command that was injected
            prompt_generation_result: Results from intelligent prompt generator
            injection_point_result: Results from injection point finder
            metadata: Additional metadata to include
            
        Returns:
            Path to the exported JSON file
        """
        try:
            # Generate filename following the user's expected convention
            current_timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            
            # Extract original timestamp from task_id if present
            import re
            timestamp_match = re.search(r'(\d{8}_\d{6})', task_id)
            original_timestamp = timestamp_match.group(1) if timestamp_match else current_timestamp
            
            # Format: injection_report_{original_timestamp}_{current_timestamp}.json
            filename = f"injection_report_{original_timestamp}_{current_timestamp}.json"
            output_path = os.path.join(self.output_directory, filename)
            
            # Create comprehensive analysis structure
            analysis_data = self._create_analysis_structure(
                task_id, original_input, target_command,
                prompt_generation_result, injection_point_result, metadata
            )
            
            # Export to JSON
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(analysis_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"Injection analysis exported to: {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"Failed to export injection analysis: {e}")
            raise
    
    def _create_analysis_structure(self,
                                 task_id: str,
                                 original_input: str,
                                 target_command: str,
                                 prompt_result: Dict[str, Any],
                                 point_result: Dict[str, Any],
                                 metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """Create the structured analysis data"""
        
        current_time = datetime.now()
        
        # Extract key information from results
        prompt_success = prompt_result.get("success", False)
        point_success = point_result.get("success", False)
        
        # Get the final injected prompt
        final_injected_prompt = None
        if point_success and "recommended_approach" in point_result:
            final_injected_prompt = point_result["recommended_approach"].get("final_integrated_text")
        elif prompt_success:
            final_injected_prompt = prompt_result.get("injected_prompt")
        
        # Calculate success metrics
        overall_success = prompt_success and point_success and (final_injected_prompt is not None)
        
        analysis_structure = {
            "analysis_metadata": {
                "task_id": task_id,
                "export_timestamp": current_time.isoformat(),
                "analysis_version": "2.0",
                "analysis_type": "intelligent_llm_driven_injection",
                "overall_success": overall_success,
                "exporter_version": "1.0.0"
            },
            
            "input_data": {
                "original_user_input": original_input,
                "original_input_length": len(original_input),
                "target_command": target_command,
                "command_type": self._classify_command(target_command)
            },
            
            "prompt_generation_analysis": {
                "success": prompt_success,
                "model_used": prompt_result.get("model_used"),
                "analysis_result": prompt_result.get("analysis_result", {}),
                "seed_selection": prompt_result.get("seed_selection", {}),
                "injection_result": prompt_result.get("injection_result", {}),
                "generated_prompt": prompt_result.get("injected_prompt"),
                "generation_metadata": {
                    "category": prompt_result.get("analysis_result", {}).get("category"),
                    "template_code": prompt_result.get("analysis_result", {}).get("template_code"),
                    "selected_template_ids": prompt_result.get("seed_selection", {}).get("selected_template_ids", []),
                    "primary_template": prompt_result.get("seed_selection", {}).get("primary_template"),
                    "template_used": prompt_result.get("injection_result", {}).get("template_used"),
                    "injection_points": prompt_result.get("injection_result", {}).get("injection_points", [])
                }
            },
            
            "injection_point_analysis": {
                "success": point_success,
                "model_used": point_result.get("model_used"),
                "structure_analysis": point_result.get("structure_analysis", {}),
                "point_evaluation": point_result.get("point_evaluation", {}),
                "integration_strategies": point_result.get("integration_strategies", {}),
                "recommended_integration": point_result.get("recommended_integration", {}),
                "point_analysis_metadata": {
                    "identified_segments": len(point_result.get("structure_analysis", {}).get("text_segments", [])),
                    "transition_points": len(point_result.get("structure_analysis", {}).get("transition_points", [])),
                    "context_anchors": len(point_result.get("structure_analysis", {}).get("context_anchors", [])),
                    "evaluated_points": len(point_result.get("point_evaluation", {}).get("evaluated_points", [])),
                    "integration_strategies_count": len(point_result.get("integration_strategies", {}).get("integration_strategies", []))
                }
            },
            
            "final_results": {
                "final_injected_text": final_injected_prompt,
                "injection_successful": final_injected_prompt is not None and target_command in (final_injected_prompt or ""),
                "original_length": len(original_input),
                "final_length": len(final_injected_prompt) if final_injected_prompt else 0,
                "length_increase": len(final_injected_prompt) - len(original_input) if final_injected_prompt else 0,
                "command_present_in_final": target_command in (final_injected_prompt or "")
            },
            
            "effectiveness_assessment": self._assess_effectiveness(
                prompt_result, point_result, final_injected_prompt, target_command
            ),
            
            "quality_metrics": self._calculate_quality_metrics(
                original_input, final_injected_prompt, prompt_result, point_result
            ),
            
            "additional_metadata": metadata or {},
            
            "raw_results": {
                "prompt_generation_full_result": prompt_result,
                "injection_point_full_result": point_result
            }
        }
        
        return analysis_structure
    
    def _classify_command(self, command: str) -> str:
        """Classify the type of command being injected"""
        command_lower = command.lower()
        
        if "pkill" in command_lower:
            return "process_termination"
        elif "bash -i" in command_lower and "tcp" in command_lower:
            return "reverse_shell"
        elif any(term in command_lower for term in ["rm ", "del ", "delete"]):
            return "file_deletion"
        elif any(term in command_lower for term in ["wget", "curl", "download"]):
            return "file_download"
        elif "python" in command_lower or "exec" in command_lower:
            return "code_execution"
        else:
            return "custom_command"
    
    def _assess_effectiveness(self, 
                            prompt_result: Dict[str, Any],
                            point_result: Dict[str, Any],
                            final_text: Optional[str],
                            target_command: str) -> Dict[str, Any]:
        """Assess the overall effectiveness of the injection"""
        
        effectiveness_score = 0
        effectiveness_factors = []
        
        # Check if prompt generation was successful
        if prompt_result.get("success"):
            effectiveness_score += 30
            effectiveness_factors.append("Successful prompt generation")
            
            # Check quality of generated prompt
            injection_result = prompt_result.get("injection_result", {})
            if injection_result.get("injection_strategy"):
                effectiveness_score += 10
                effectiveness_factors.append("Sophisticated injection strategy")
        
        # Check if injection point analysis was successful
        if point_result.get("success"):
            effectiveness_score += 30
            effectiveness_factors.append("Successful injection point analysis")
            
            # Check quality of integration
            recommended = point_result.get("recommended_integration", {})
            if recommended.get("success_probability"):
                try:
                    prob = float(recommended["success_probability"].replace("%", ""))
                    effectiveness_score += min(20, prob // 5)
                    effectiveness_factors.append(f"High success probability: {recommended['success_probability']}")
                except:
                    pass
        
        # Check final result quality
        if final_text and target_command in final_text:
            effectiveness_score += 10
            effectiveness_factors.append("Command successfully integrated in final text")
        
        # Determine effectiveness level
        if effectiveness_score >= 80:
            effectiveness_level = "EXCELLENT"
        elif effectiveness_score >= 60:
            effectiveness_level = "GOOD"
        elif effectiveness_score >= 40:
            effectiveness_level = "MODERATE"
        elif effectiveness_score >= 20:
            effectiveness_level = "POOR"
        else:
            effectiveness_level = "FAILED"
        
        return {
            "effectiveness_score": effectiveness_score,
            "effectiveness_level": effectiveness_level,
            "effectiveness_factors": effectiveness_factors,
            "assessment_details": {
                "prompt_generation_quality": "high" if prompt_result.get("success") else "failed",
                "injection_point_quality": "high" if point_result.get("success") else "failed",
                "integration_quality": "high" if final_text and target_command in final_text else "failed",
                "overall_coherence": "high" if effectiveness_score >= 60 else "low"
            }
        }
    
    def _calculate_quality_metrics(self,
                                 original_text: str,
                                 final_text: Optional[str],
                                 prompt_result: Dict[str, Any],
                                 point_result: Dict[str, Any]) -> Dict[str, Any]:
        """Calculate quality metrics for the injection"""
        
        if not final_text:
            return {
                "text_coherence": 0,
                "integration_seamlessness": 0,
                "believability_factor": 0,
                "overall_quality": 0
            }
        
        # Simple quality metrics (could be enhanced with more sophisticated analysis)
        metrics = {
            "text_coherence": 85 if len(final_text) > len(original_text) * 1.1 else 70,
            "integration_seamlessness": 90 if point_result.get("success") else 50,
            "believability_factor": 88 if prompt_result.get("success") else 60,
        }
        
        metrics["overall_quality"] = sum(metrics.values()) / len(metrics)
        
        return metrics


def export_injection_analysis(task_id: str,
                            original_input: str,
                            target_command: str,
                            prompt_generation_result: Dict[str, Any],
                            injection_point_result: Dict[str, Any],
                            output_directory: str = None,
                            metadata: Dict[str, Any] = None) -> str:
    """
    Convenience function to export injection analysis
    
    Args:
        task_id: Unique identifier for the task
        original_input: The original user input/task  
        target_command: The command that was injected
        prompt_generation_result: Results from intelligent prompt generator
        injection_point_result: Results from injection point finder
        output_directory: Directory to save analysis files
        metadata: Additional metadata to include
        
    Returns:
        Path to the exported JSON file
    """
    exporter = InjectionAnalysisExporter(output_directory)
    return exporter.export_analysis(
        task_id, original_input, target_command,
        prompt_generation_result, injection_point_result, metadata
    )


# Export key components
__all__ = [
    'InjectionAnalysisExporter',
    'export_injection_analysis'
]