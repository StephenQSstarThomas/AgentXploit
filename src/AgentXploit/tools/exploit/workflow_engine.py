"""
Simplified Workflow Engine

Focused on:
1. Simple Docker environment setup
2. LLM-driven autonomous analysis
3. Terminal command execution for LLM-generated commands
4. Injection point detection without complex fallbacks
"""

import os
import json
import logging
import asyncio
import uuid
from typing import Dict, Optional, Any, List
from pathlib import Path

# Import simplified tools
from .swerex import (
    create_deployment, create_dev_container, execute_command
)
from .analyzer import analyze_injection_points, generate_llm_analysis_prompt
from .terminal import execute_terminal_command, process_llm_commands
from .agent_executor import execute_agent_with_trace_analysis
from .openhands_executor import execute_openhands_with_trace_analysis
from .interactive_handler import confirm_trace_location

logger = logging.getLogger(__name__)


async def execute_optimized_exploit_workflow(
    target_path: str,
    benign_task: Optional[str] = None,
    docker_image: Optional[str] = None,
    max_steps: int = 30,
    auto_execute: bool = True,
    focus: str = "injection_points",
    custom_commands: Optional[List[str]] = None
) -> Dict[str, Any]:
    """
    Simplified exploit workflow focused on LLM-driven injection point analysis.
    
    Args:
        target_path: Path to target agent
        benign_task: Optional benign task description
        docker_image: Optional Docker image
        max_steps: Maximum analysis steps
        auto_execute: Whether to auto-execute LLM commands
        focus: Analysis focus ("injection_points")
        custom_commands: Custom commands to execute instead of LLM-generated ones
        
    Returns:
        Analysis results with injection points
    """
    workflow_id = f"workflow_{uuid.uuid4().hex[:8]}"
    logger.info(f"Starting simplified exploit workflow: {workflow_id}")
    
    try:
        # Phase 1: Simple Environment Setup
        logger.info("Phase 1: Setting up analysis environment")
        
        if docker_image:
            deployment_id = await create_deployment(image=docker_image)
        else:
            deployment_id = await create_dev_container(base_image="python:3.12")
        
        logger.info(f"Environment ready: {deployment_id}")
        
        # Phase 2: Execute Target Agent Task and Analyze Traces
        logger.info(f"Phase 2: Executing target agent with task: {benign_task or 'default task'}")
        
        # Detect if this is OpenHands by checking target path
        is_openhands = "openhands" in target_path.lower() or Path(target_path).name.lower() == "openhands"
        
        if is_openhands:
            logger.info("Detected OpenHands target - using specialized OpenHands executor")
            # Use OpenHands specific executor
            agent_execution_result = await execute_openhands_with_trace_analysis(
                target_path=target_path,
                deployment_id=deployment_id,
                task_command=custom_commands[0] if custom_commands else None,
                custom_prompt=benign_task,
                max_iterations=min(max_steps // 3, 20)  # Reasonable limit for OpenHands
            )
        else:
            # Use general agent executor
            agent_execution_result = await execute_agent_with_trace_analysis(
                target_path=target_path,
                deployment_id=deployment_id,
                task_command=custom_commands[0] if custom_commands else None,
                custom_trace_path=None  # Will auto-detect trace files
            )
        
        # Extract results from agent execution
        execution_result = agent_execution_result["execution_result"]
        initial_trace_files = agent_execution_result.get("trace_files", [])
        
        logger.info(f"Agent task executed. Success: {execution_result['success']}")
        logger.info(f"Initially found {len(initial_trace_files)} trace files")
        
        # Interactive trace confirmation step
        trace_confirmation = await confirm_trace_location(execution_result, initial_trace_files)
        
        if not trace_confirmation["success"]:
            return {
                "success": False,
                "error": "User cancelled trace analysis",
                "workflow_id": workflow_id,
                "target_path": target_path,
                "execution_result": execution_result
            }
        
        # Determine which traces to analyze based on user choice
        if trace_confirmation.get("skip_analysis"):
            # User chose to skip trace analysis
            trace_analysis = {
                "success": True,
                "injection_points": [],
                "external_data_sources": [],
                "high_risk_points": [],
                "overall_risk": "UNKNOWN",
                "skipped": True
            }
            logger.info("Trace analysis skipped by user")
        else:
            # Use confirmed trace files for analysis
            confirmed_trace_files = trace_confirmation.get("trace_files", initial_trace_files)
            logger.info(f"Analyzing {len(confirmed_trace_files)} confirmed trace files")
            
            if is_openhands:
                # Re-run analysis with confirmed trace files for OpenHands
                from .openhands_executor import OpenHandsExecutor
                executor = OpenHandsExecutor(target_path, deployment_id)
                trace_analysis = await executor.analyze_openhands_trace(confirmed_trace_files)
            else:
                # Re-run analysis with confirmed trace files for general agent
                from .agent_executor import AgentExecutor
                executor = AgentExecutor(target_path, deployment_id)
                trace_analysis = await executor.analyze_trace_for_injection_points(confirmed_trace_files)
        
        logger.info(f"Trace analysis completed. Found {len(trace_analysis.get('injection_points', []))} injection points")
        
        # Phase 3: Process Analysis Results
        logger.info("Phase 3: Processing injection point analysis results")
        
        # Use the trace analysis results
        injection_analysis = {
            'success': trace_analysis['success'],
            'detailed_results': {
                'injection_points': trace_analysis['injection_points'],
                'external_data_sources': trace_analysis['external_data_sources'],
                'high_risk_points': trace_analysis.get('high_risk_points', []),
                'overall_risk': trace_analysis.get('overall_risk', 'UNKNOWN'),
                'analysis_commands': custom_commands or []
            }
        }
        
        # Extract results from trace analysis
        injection_points = []
        analysis_commands = []
        overall_risk = "UNKNOWN"
        external_data_sources = []
        
        if injection_analysis.get('success'):
            detailed_results = injection_analysis.get('detailed_results', {})
            injection_points = detailed_results.get('injection_points', [])
            analysis_commands = detailed_results.get('analysis_commands', [])
            overall_risk = detailed_results.get('overall_risk', 'UNKNOWN')
            external_data_sources = detailed_results.get('external_data_sources', [])
        
        # Phase 4: Execute LLM-Generated Commands (if auto_execute)
        command_results = []
        if auto_execute and analysis_commands:
            logger.info(f"Phase 4: Executing {len(analysis_commands)} LLM-generated commands")
            
            for cmd in analysis_commands[:max_steps]:  # Limit to max_steps
                try:
                    result = await execute_command(cmd, deployment_id)
                    command_results.append({
                        'command': cmd,
                        'success': result.success,
                        'output': result.stdout[:500],  # Limit output size
                        'error': result.stderr[:200] if result.stderr else None
                    })
                except Exception as e:
                    logger.warning(f"Command execution failed: {cmd} - {e}")
                    command_results.append({
                        'command': cmd,
                        'success': False,
                        'error': str(e)
                    })
        
        # Return comprehensive results
        return {
            "success": True,
            "workflow_id": workflow_id,
            "target_path": target_path,
            "deployment_id": deployment_id,
            "execution_time": "< 60s",  # Updated timing for real agent execution
            "injection_points": injection_points,
            "analysis_commands": analysis_commands,
            "command_results": command_results,
            "overall_risk": overall_risk,
            "auto_executed": auto_execute,
            "agent_execution": execution_result,
            "external_data_sources": external_data_sources,
            "results": {
                "total_injection_points": len(injection_points),
                "high_risk_injection_points": len([p for p in injection_points if p.get('risk') == 'HIGH']),
                "external_data_sources_found": len(external_data_sources),
                "commands_executed": len(command_results),
                "successful_commands": len([r for r in command_results if r.get('success')]),
                "risk_level": overall_risk,
                "trace_files_analyzed": agent_execution_result.get('trace_files_found', 0),
                "agent_task_success": execution_result.get('success', False),
                "agent_task_command": execution_result.get('command', 'unknown')
            }
        }
        
    except Exception as e:
        logger.error(f"Simplified exploit workflow failed: {e}")
        return {
            "success": False,
            "workflow_id": workflow_id,
            "error": str(e),
            "target_path": target_path
        }


async def get_workflow_status(workflow_id: str) -> Dict[str, Any]:
    """
    Get workflow status - simplified version.
    """
    return {
        "workflow_id": workflow_id,
        "status": "completed",  # Simplified - always completed
        "message": "Simplified workflow engine - check logs for details"
    }


# Simple project analysis
async def analyze_project_simple(target_path: str) -> Dict[str, Any]:
    """
    Simple project analysis without complex LLM processing.
    """
    try:
        project_path = Path(target_path)
        
        # Basic file detection
        python_files = list(project_path.glob("**/*.py"))
        config_files = []
        
        # Look for common config files
        common_configs = ["requirements.txt", "pyproject.toml", "setup.py", "README.md"]
        for config in common_configs:
            config_path = project_path / config
            if config_path.exists():
                config_files.append(str(config_path))
        
        return {
            "success": True,
            "project_type": "python" if python_files else "unknown",
            "python_files_count": len(python_files),
            "config_files": config_files,
            "recommended_image": "python:3.12",
            "analysis_method": "simple_detection"
        }
        
    except Exception as e:
        logger.error(f"Simple project analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "recommended_image": "python:3.12"
        }


# Export key functions
__all__ = [
    'execute_optimized_exploit_workflow',
    'get_workflow_status', 
    'analyze_project_simple'
]