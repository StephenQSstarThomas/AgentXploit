"""
Simplified Workflow Engine

Focused on:
1. Simple Docker environment setup
2. LLM-driven autonomous analysis
3. Terminal command execution for LLM-generated commands
4. Injection point detection without complex fallbacks
"""

import os
import json
import logging
import asyncio
import uuid
from typing import Dict, Optional, Any, List
from pathlib import Path

# Import simplified tools
from .swerex import (
    create_deployment, create_dev_container, execute_command
)
from .analyzer import analyze_injection_points, generate_llm_analysis_prompt
from .terminal import execute_terminal_command, process_llm_commands

logger = logging.getLogger(__name__)


async def execute_optimized_exploit_workflow(
    target_path: str,
    benign_task: Optional[str] = None,
    docker_image: Optional[str] = None,
    max_steps: int = 30,
    auto_execute: bool = True,
    focus: str = "injection_points"
) -> Dict[str, Any]:
    """
    Simplified exploit workflow focused on LLM-driven injection point analysis.
    
    Args:
        target_path: Path to target agent
        benign_task: Optional benign task description
        docker_image: Optional Docker image
        max_steps: Maximum analysis steps
        auto_execute: Whether to auto-execute LLM commands
        focus: Analysis focus ("injection_points")
        
    Returns:
        Analysis results with injection points
    """
    workflow_id = f"workflow_{uuid.uuid4().hex[:8]}"
    logger.info(f"Starting simplified exploit workflow: {workflow_id}")
    
    try:
        # Phase 1: Simple Environment Setup
        logger.info("Phase 1: Setting up analysis environment")
        
        if docker_image:
            deployment_id = await create_deployment(image=docker_image)
        else:
            deployment_id = await create_dev_container(base_image="python:3.12")
        
        logger.info(f"Environment ready: {deployment_id}")
        
        # Phase 2: Execute Benign Task (if provided)
        trace = []
        if benign_task:
            logger.info(f"Phase 2: Executing benign task: {benign_task}")
            
            # Simple task execution to generate trace
            task_commands = [
                f"echo 'Starting task: {benign_task}'",
                f"ls -la {target_path}",
                f"find {target_path} -name '*.py' | head -10"
            ]
            
            for cmd in task_commands:
                result = await execute_command(cmd, deployment_id)
                trace.append({
                    'command': cmd,
                    'success': result.success,
                    'stdout': result.stdout,
                    'stderr': result.stderr,
                    'timestamp': asyncio.get_event_loop().time()
                })
        
        # Phase 3: LLM-Driven Injection Analysis
        logger.info("Phase 3: LLM-driven injection point analysis")
        
        # Generate analysis prompt for LLM
        analysis_prompt = await generate_llm_analysis_prompt(
            target_path=target_path,
            context=f"Benign task: {benign_task or 'None'}, Focus: {focus}"
        )
        
        # Perform injection point analysis
        injection_analysis = await analyze_injection_points(
            trace=trace,
            llm_prompt=analysis_prompt
        )
        
        # Extract results
        injection_points = []
        analysis_commands = []
        overall_risk = "UNKNOWN"
        
        if injection_analysis.get('success'):
            detailed_results = injection_analysis.get('detailed_results', {})
            injection_points = detailed_results.get('injection_points', [])
            analysis_commands = detailed_results.get('analysis_commands', [])
            overall_risk = detailed_results.get('overall_risk', 'UNKNOWN')
        
        # Phase 4: Execute LLM-Generated Commands (if auto_execute)
        command_results = []
        if auto_execute and analysis_commands:
            logger.info(f"Phase 4: Executing {len(analysis_commands)} LLM-generated commands")
            
            for cmd in analysis_commands[:max_steps]:  # Limit to max_steps
                try:
                    result = await execute_command(cmd, deployment_id)
                    command_results.append({
                        'command': cmd,
                        'success': result.success,
                        'output': result.stdout[:500],  # Limit output size
                        'error': result.stderr[:200] if result.stderr else None
                    })
                except Exception as e:
                    logger.warning(f"Command execution failed: {cmd} - {e}")
                    command_results.append({
                        'command': cmd,
                        'success': False,
                        'error': str(e)
                    })
        
        # Return results
        return {
            "success": True,
            "workflow_id": workflow_id,
            "target_path": target_path,
            "deployment_id": deployment_id,
            "execution_time": "< 30s",  # Simplified timing
            "injection_points": injection_points,
            "analysis_commands": analysis_commands,
            "command_results": command_results,
            "overall_risk": overall_risk,
            "auto_executed": auto_execute,
            "results": {
                "total_injection_points": len(injection_points),
                "commands_executed": len(command_results),
                "successful_commands": len([r for r in command_results if r.get('success')]),
                "risk_level": overall_risk,
                "trace_entries": len(trace)
            }
        }
        
    except Exception as e:
        logger.error(f"Simplified exploit workflow failed: {e}")
        return {
            "success": False,
            "workflow_id": workflow_id,
            "error": str(e),
            "target_path": target_path
        }


async def get_workflow_status(workflow_id: str) -> Dict[str, Any]:
    """
    Get workflow status - simplified version.
    """
    return {
        "workflow_id": workflow_id,
        "status": "completed",  # Simplified - always completed
        "message": "Simplified workflow engine - check logs for details"
    }


# Simple project analysis
async def analyze_project_simple(target_path: str) -> Dict[str, Any]:
    """
    Simple project analysis without complex LLM processing.
    """
    try:
        project_path = Path(target_path)
        
        # Basic file detection
        python_files = list(project_path.glob("**/*.py"))
        config_files = []
        
        # Look for common config files
        common_configs = ["requirements.txt", "pyproject.toml", "setup.py", "README.md"]
        for config in common_configs:
            config_path = project_path / config
            if config_path.exists():
                config_files.append(str(config_path))
        
        return {
            "success": True,
            "project_type": "python" if python_files else "unknown",
            "python_files_count": len(python_files),
            "config_files": config_files,
            "recommended_image": "python:3.12",
            "analysis_method": "simple_detection"
        }
        
    except Exception as e:
        logger.error(f"Simple project analysis failed: {e}")
        return {
            "success": False,
            "error": str(e),
            "recommended_image": "python:3.12"
        }


# Export key functions
__all__ = [
    'execute_optimized_exploit_workflow',
    'get_workflow_status', 
    'analyze_project_simple'
]