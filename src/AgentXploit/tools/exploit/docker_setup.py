"""
Intelligent Docker Environment Setup

Process:
1. LLM reads README for Docker image information
2. If found: Create Docker → Direct to analysis (NO dependency check)  
3. If not found: Check pyproject/requirements → Create Python Docker → Run pip install → Analysis
"""

import os
import re
import json
import logging
import asyncio
import uuid
from typing import Dict, Optional, Any, List
from pathlib import Path
import toml

from .subprocess_docker import (
    run_docker_command,
    execute_command_in_container,
    create_docker_container,
    execute_container_command
)

# Import centralized LLM functionality will be imported when needed

logger = logging.getLogger(__name__)


class DockerEnvironmentManager:
    """
    Docker environment setup with LLM-driven README analysis using centralized LLM client
    """
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        if llm_client:
            logger.info("Initialized Docker Environment Manager with provided LLM client")
        else:
            logger.info("Initialized Docker Environment Manager with centralized LLM client")
    
    async def setup_docker_environment(
        self,
        target_path: str,
        require_confirmation: bool = True
    ) -> Dict[str, Any]:
        try:
            logger.info(f"Starting simplified Docker setup for: {target_path}")

            # Step 0: Check for DEFAULT_DOCKER_COMMAND in .env first
            from ...config import settings
            if settings.DEFAULT_DOCKER_COMMAND:
                logger.info("Found DEFAULT_DOCKER_COMMAND in .env, using it directly")
                return await self._deploy_with_env_command(settings.DEFAULT_DOCKER_COMMAND, require_confirmation)

            # Step 1: LLM读取README获取Docker信息 (only if no DEFAULT_DOCKER_COMMAND)
            docker_info = await self._llm_analyze_readme(target_path)

            if docker_info.get('has_docker_image'):
                # 找到Docker信息 → 用户确认流程
                logger.info("Found Docker image in project files")
                return await self._handle_found_docker_info(docker_info, require_confirmation)
            else:
                # 没找到Docker信息 → 直接人工输入
                logger.info("No Docker info found, proceeding to human input")
                return await self._setup_with_human_instruction(require_confirmation)
            
        except Exception as e:
            logger.error(f"Docker setup failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'target_path': target_path
            }
    
    async def _llm_analyze_readme(self, target_path: str) -> Dict[str, Any]:
        """
        Read README and Docker-related files to find complete docker run commands.
        """
        project_path = Path(target_path)
        all_content = ""
        files_checked = []
        
        # Check key files for Docker information
        docker_files = [
            'README.md', 'README.rst', 'README.txt', 'readme.md',
            'Dockerfile', 'docker-compose.yml', 'docker-compose.yaml'
        ]
        
        for file_name in docker_files:
            file_path = project_path / file_name
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8')
                    all_content += f"\n--- {file_name} ---\n{content}"
                    files_checked.append(file_name)
                    logger.info(f"Read {file_name} ({len(content)} chars)")
                except Exception as e:
                    logger.warning(f"Failed to read {file_name}: {e}")
        
        if not all_content:
            logger.info("No Docker-related files found")
            return {'has_docker_image': False}
        
        # Use provided LLM client or fallback to centralized LLM client
        try:
            if self.llm_client:
                # Use provided LLM client (from exploit agent)
                logger.info("Using provided LLM client for README analysis")
                
                prompt = f"""Find Docker run commands in these files:

{all_content}

Look for complete docker run commands, especially ones like:
docker run -it --rm --pull=always -e SANDBOX_RUNTIME_CONTAINER_IMAGE=... docker.all-hands.dev/all-hands-ai/openhands:0.49

Return only JSON:
{{
    "has_docker_image": true/false,
    "docker_image": "image_name_if_found",
    "complete_docker_command": "full_command_if_found"
}}"""

                # Use the Agent SDK LLM client approach
                from google.adk.models.llm_request import LlmRequest
                
                request = LlmRequest(
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                
                # Generate response asynchronously
                response_generator = self.llm_client.generate_content_async(request)
                response = None
                async for resp in response_generator:
                    response = resp.content
                    break  # Get first response
            else:
                # Fallback to centralized LLM client
                logger.info("Using centralized LLM client for README analysis")

                # Build LLM messages
                messages = [
                    {
                        "role": "system",
                        "content": "You are an expert at analyzing README files to extract Docker setup information. Return only valid JSON responses."
                    },
                    {
                        "role": "user",
                        "content": f"""Find Docker run commands in these files:

{all_content}

Look for complete docker run commands, especially ones like:
docker run -it --rm --pull=always -e SANDBOX_RUNTIME_CONTAINER_IMAGE=... docker.all-hands.dev/all-hands-ai/openhands:0.49

Return only JSON:
{{
    "has_docker_image": true/false,
    "docker_image": "image_name_if_found",
    "complete_docker_command": "full_command_if_found"
}}"""
                    }
                ]

                # Use centralized LLM client with proper error handling
                from ...tools.core.llm_client import LLMClient
                from ...config import settings

                # Setup API key if needed
                import os
                if not os.environ.get("OPENAI_API_KEY"):
                    api_key = settings.get_openai_api_key()
                    os.environ["OPENAI_API_KEY"] = api_key

                model = settings.EXPLOIT_AGENT_MODEL

                # Call LLM using centralized client
                response = LLMClient.call_llm(
                    model=model,
                    messages=messages,
                    max_tokens=500,
                    temperature=0.1,
                    timeout=30
                )
            
            if response:
                # Clean up response - remove markdown formatting
                cleaned_response = response.strip()
                
                # Remove markdown code blocks completely
                if cleaned_response.startswith('```json'):
                    cleaned_response = cleaned_response[7:]
                elif cleaned_response.startswith('```'):
                    cleaned_response = cleaned_response[3:]
                    
                if cleaned_response.endswith('```'):
                    cleaned_response = cleaned_response[:-3]
                    
                cleaned_response = cleaned_response.strip()
                
                # Fix common JSON issues
                # Handle unterminated strings by finding the last complete brace
                try:
                    result = json.loads(cleaned_response)
                except json.JSONDecodeError as e:
                    logger.warning(f"Initial JSON parse failed: {e}")
                    # Try to fix truncated JSON by finding last complete object
                    brace_count = 0
                    last_valid_pos = 0
                    for i, char in enumerate(cleaned_response):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                last_valid_pos = i + 1
                                break
                    
                    if last_valid_pos > 0:
                        fixed_json = cleaned_response[:last_valid_pos]
                        try:
                            result = json.loads(fixed_json)
                            logger.info("Successfully parsed fixed JSON")
                        except json.JSONDecodeError:
                            logger.warning("Failed to parse fixed JSON, using fallback")
                            result = {'has_docker_image': False}
                    else:
                        logger.warning("Could not fix JSON, using fallback")
                        result = {'has_docker_image': False}
                
                logger.info(f"LLM README analysis: {result.get('has_docker_image', False)}")
                return result
            else:
                logger.warning("LLM returned no response for README analysis")
                return {'has_docker_image': False}
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse LLM JSON response: {e}")
            logger.warning(f"Raw LLM response: {response}")
            
            # 检查响应中是否包含Docker信息，即使JSON解析失败
            if response and any(keyword in response.lower() for keyword in ['docker.all-hands.dev', 'openhands', 'docker run']):
                logger.info("Detected Docker information in LLM response despite JSON error")
                # 尝试手动提取基本信息
                manual_config = self._manual_extract_docker_info(response)
                if manual_config.get('has_docker_image'):
                    return manual_config
            
            return {'has_docker_image': False}
        except Exception as e:
            logger.warning(f"LLM README analysis failed: {e}")
            return {'has_docker_image': False}
    
    async def _handle_found_docker_info(
        self,
        docker_info: Dict[str, Any], 
        require_confirmation: bool
    ) -> Dict[str, Any]:
        docker_image = docker_info.get('docker_image', 'python:3.12')
        runtime_image = docker_info.get('runtime_image', '')
        complete_command = docker_info.get('complete_docker_command', '')
        reasoning = docker_info.get('reasoning', '')
        
        if require_confirmation:
            print(f"\n🐳 Found Docker Configuration:")
            print(f"Main Image: {docker_image}")
            if runtime_image:
                print(f"Runtime Image: {runtime_image}")
            if complete_command:
                print(f"Complete Command: {complete_command[:100]}...")
            if reasoning:
                print(f"Analysis: {reasoning[:200]}...")
            
            print(f"\nOptions:")
            print(f"  y/yes  - Use this configuration and deploy")
            print(f"  n/custom - Enter custom docker command")
            print(f"  q/quit - Exit setup")
            
            while True:
                choice = input(f"\nYour choice [y/n/q]: ").strip().lower()
                
                if choice in ['y', 'yes']:
                    # 直接使用找到的配置部署
                    return await self._deploy_with_found_config(docker_info)
                    
                elif choice in ['n', 'custom']:
                    # 进入自定义输入流程
                    return await self._setup_with_custom_input()
                    
                elif choice in ['q', 'quit']:
                    # 退出
                    return {
                        'success': False,
                        'cancelled': True,
                        'message': 'User cancelled Docker setup'
                    }
                else:
                    print("Please enter 'y' (yes), 'n' (custom), or 'q' (quit)")
        else:
            # 自动模式直接部署
            return await self._deploy_with_found_config(docker_info)
    
    async def _deploy_with_env_command(self, env_docker_command: str, require_confirmation: bool) -> Dict[str, Any]:
        """Deploy using DEFAULT_DOCKER_COMMAND from .env file - no confirmation needed"""
        try:
            # .env commands are automatically trusted and executed without confirmation
            print(f"\n🐳 Found DEFAULT_DOCKER_COMMAND in .env:")
            print(f"Command: {env_docker_command}")
            print(f"Automatically executing trusted .env command...")

            # Execute the env command directly without confirmation
            logger.info(f"Running DEFAULT_DOCKER_COMMAND: {env_docker_command}")
            deployment_id = await run_docker_command(env_docker_command)

            logger.info(f"Successfully deployed with env command: {deployment_id}")

            return {
                'success': True,
                'deployment_id': deployment_id,
                'docker_image': 'from_env_command',
                'setup_type': 'env_default_command',
                'ready_for_analysis': True,
                'source': 'env_default_docker_command',
                'original_command': env_docker_command
            }

        except Exception as e:
            logger.error(f"Failed to deploy env Docker command: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'env_command_failed'
            }

    async def _deploy_with_found_config(self, docker_info: Dict[str, Any]) -> Dict[str, Any]:
        """使用找到的配置直接部署"""
        try:
            complete_command = docker_info.get('complete_docker_command')
            
            if complete_command:
                # 直接运行完整的Docker命令
                logger.info(f"Running complete Docker command: {complete_command}")
                deployment_id = await run_docker_command(complete_command)
            else:
                # 使用简单的镜像创建
                image = docker_info.get('docker_image', 'python:3.12')
                logger.info(f"Creating simple container with image: {image}")
                deployment_id = await create_docker_container(image)
            
            logger.info(f"Successfully deployed Docker configuration: {deployment_id}")
            
            return {
                'success': True,
                'deployment_id': deployment_id,
                'docker_image': docker_info.get('docker_image'),
                'setup_type': 'readme_docker_auto',
                'ready_for_analysis': True,
                'llm_reasoning': docker_info.get('reasoning', ''),
                'source': 'readme_analysis',
                'original_command': complete_command
            }
            
        except Exception as e:
            logger.error(f"Failed to deploy found Docker config: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'readme_docker_failed'
            }
    
    async def _setup_with_custom_input(self) -> Dict[str, Any]:
        """Handle custom user input for Docker command"""
        print("\nEnter your Docker command (multi-line supported):")
        print("Press Enter twice when finished, or 'END' on a new line:")
        print()
        
        # Collect multi-line input
        lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                if not line.strip() and lines:  # Empty line after some content
                    break
                lines.append(line)
            except EOFError:
                break
        
        custom_command = '\n'.join(lines).strip()
        
        if not custom_command:
            print("No command entered, using default: python:3.12")
            try:
                deployment_id = await create_docker_container(image="python:3.12")
                return {
                    'success': True,
                    'deployment_id': deployment_id,
                    'docker_image': "python:3.12",
                    'setup_type': 'custom_default',
                    'ready_for_analysis': True,
                    'source': 'user_default'
                }
            except Exception as e:
                return {'success': False, 'error': str(e)}
        else:
            print(f"\n🚀 Running Docker command directly...")
            print(f"Command: {custom_command}")
        
        # 直接运行用户输入的命令
        try:
            deployment_id = await run_docker_command(custom_command)
            print(f"\n✅ Container deployed successfully: {deployment_id}")
            
            return {
                'success': True,
                'deployment_id': deployment_id,
                'setup_type': 'custom_user_input',
                'ready_for_analysis': True,
                'source': 'user_custom_command',
                'original_command': custom_command
            }
        except Exception as e:
            logger.error(f"Custom deployment failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'custom_deployment_failed'
            }
    
    
    async def _setup_with_human_instruction(self, require_confirmation: bool) -> Dict[str, Any]:
        """No Docker info found - offer default or custom input"""
        print("\nNo Docker configuration found in README")
        print("Using default: python:3.12")
        
        if not require_confirmation:
            # Auto-mode: Use default
            try:
                from .swerex import create_deployment
                deployment_id = await create_deployment(image="python:3.12")
                return {
                    'success': True,
                    'deployment_id': deployment_id,
                    'docker_image': "python:3.12",
                    'setup_type': 'auto_default',
                    'ready_for_analysis': True
                }
            except Exception as e:
                return {'success': False, 'error': str(e)}
        
        # Interactive mode: Offer choice
        print("\nChoose:")
        print("  y/yes - Use default python:3.12")
        print("  n/custom - Enter custom command")
        print("  q/quit - Exit")
        
        while True:
            choice = input("Your choice [y/n/q]: ").strip().lower()
            
            if choice in ['y', 'yes']:
                try:
                    deployment_id = await create_docker_container(image="python:3.12")
                    return {
                        'success': True,
                        'deployment_id': deployment_id,
                        'docker_image': "python:3.12",
                        'setup_type': 'default_confirmed',
                        'ready_for_analysis': True
                    }
                except Exception as e:
                    return {'success': False, 'error': str(e)}
            elif choice in ['n', 'custom']:
                return await self._setup_with_custom_input()
            elif choice in ['q', 'quit']:
                return {'success': False, 'cancelled': True, 'message': 'User quit'}
            else:
                print("Invalid choice. Please enter 'y', 'n', or 'q'.")
    
    
    
    # 移除复杂的Docker命令解析，改为直接执行
    
    # 移除复杂的配置部署方法，改为直接运行命令
    
    # 移除复杂的LLM解析方法，改为直接运行命令
    
    # 保留手动提取功能，但简化处理
    def _manual_extract_docker_info(self, llm_response: str) -> Dict[str, Any]:
        """简化的手动Docker信息提取"""
        try:
            import re
            
            # 查找完整的docker run命令
            docker_run_pattern = r'docker\s+run[^\n]+'
            docker_commands = re.findall(docker_run_pattern, llm_response)
            
            if docker_commands:
                complete_command = docker_commands[0]
                logger.info(f"Found Docker command: {complete_command}")
                return {
                    "has_docker_image": True,
                    "complete_docker_command": complete_command,
                    "reasoning": "Extracted complete docker run command"
                }
            
            # 查找Docker镜像名
            image_patterns = [
                r'docker\.all-hands\.dev/[^\s"]+',
                r'openhands:[^\s"]+',
                r'"docker_image":\s*"([^"]+)"'
            ]
            
            for pattern in image_patterns:
                match = re.search(pattern, llm_response)
                if match:
                    if pattern.startswith('"docker_image"'):
                        image = match.group(1)
                    else:
                        image = match.group(0)
                    
                    return {
                        "has_docker_image": True,
                        "docker_image": image,
                        "reasoning": f"Found Docker image: {image}"
                    }
            
            return {"has_docker_image": False}
            
        except Exception as e:
            logger.error(f"Manual extraction failed: {e}")
            return {"has_docker_image": False}


# Global manager instance (will be updated with LLM client when needed)
_docker_manager = None


# Main function for AgentXploit integration
async def setup_intelligent_docker_environment(
    target_path: str,
    llm_client=None,  # LLM client from exploit agent
    require_confirmation: bool = True
) -> Dict[str, Any]:
    """
    Main Docker environment setup function.
    
    Process:
    1. LLM reads README for Docker image using provided LLM client
    2. If found: Create Docker → Skip dependency check → Ready for analysis
    3. If not: Check pyproject/requirements → Create Python Docker → pip install → Ready for analysis
    
    POLICY: Always creates NEW containers, never reuses existing deployments.
    
    Args:
        target_path: Path to target project
        llm_client: LLM client from exploit agent (preferred) or None for centralized client
        require_confirmation: Whether to require user confirmation
        
    Returns:
        Environment setup results
        
    Note:
        This function now enforces the no-reuse policy by calling create_docker_container()
        which automatically ensures unique container creation.
    """
    global _docker_manager
    
    # SPECIAL HANDLING: Check if this is GPT-Research and use predefined command
    target_path_lower = target_path.lower()
    path_name_lower = Path(target_path).name.lower()
    
    is_research = (
        "gpt-researcher" in target_path_lower or
        "gptresearcher" in target_path_lower or
        path_name_lower == "gpt-researcher" or
        "gpt_researcher" in target_path_lower
    )
    
    if is_research:
        logger.info("SPECIAL HANDLING: GPT-Research detected - using DEFAULT_GPTR_DOCKER_COMMAND")
        
        # Read GPT-Research Docker command from environment
        gptr_docker_command = os.getenv("DEFAULT_GPTR_DOCKER_COMMAND")
        if not gptr_docker_command:
            logger.error("DEFAULT_GPTR_DOCKER_COMMAND not found in environment")
            return {
                "success": False,
                "error": "DEFAULT_GPTR_DOCKER_COMMAND not found in environment variables",
                "setup_type": "gptr_failed"
            }
        
        logger.info(f"Using predefined GPT-Research command: {gptr_docker_command}")
        
        # Execute the GPT-Research Docker command directly with unique naming
        try:
            # Generate unique container name to prevent conflicts
            import datetime
            timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
            unique_suffix = uuid.uuid4().hex[:8]
            unique_container_name = f"gpt-researcher-{timestamp}-{unique_suffix}"
            
            # Replace the fixed container name with unique name
            import re
            modified_command = re.sub(
                r'--name\s+gpt-researcher\b',
                f'--name {unique_container_name}',
                gptr_docker_command
            )
            
            logger.info(f"Modified GPT-Research command with unique name: {unique_container_name}")
            print(f"📋 Using modified command: {modified_command}")
            
            deployment_id = await run_docker_command(modified_command)
            logger.info(f"GPT-Research container created successfully: {deployment_id}")
            
            return {
                "success": True,
                "deployment_id": deployment_id,
                "docker_image": "gptresearcher/gpt-researcher",
                "setup_type": "gptr_predefined",
                "setup_method": "predefined_command",
                "docker_command_used": modified_command,
                "original_command": gptr_docker_command,
                "unique_container_name": unique_container_name,
                "target_path": target_path
            }
        except Exception as e:
            logger.error(f"Failed to create GPT-Research container: {e}")
            return {
                "success": False,
                "error": f"Failed to create GPT-Research container: {e}",
                "setup_type": "gptr_failed"
            }
    
    # For non-research workflows, use standard intelligent setup
    # Create or update manager with LLM client
    if llm_client:
        _docker_manager = DockerEnvironmentManager(llm_client=llm_client)
    elif _docker_manager is None:
        _docker_manager = DockerEnvironmentManager()
    
    return await _docker_manager.setup_docker_environment(
        target_path=target_path,
        require_confirmation=require_confirmation
    )


async def quick_python_setup(python_version: str = "3.12") -> Dict[str, Any]:
    """
    Quick Python environment setup without analysis.
    
    Args:
        python_version: Python version to use
        
    Returns:
        Environment setup results
    """
    try:
        python_image = f"python:{python_version}"
        deployment_id = await create_docker_container(image=python_image)
        
        logger.info(f"Created quick Python environment: {deployment_id}")
        
        return {
            'success': True,
            'deployment_id': deployment_id,
            'docker_image': python_image,
            'setup_type': 'quick_python'
        }
        
    except Exception as e:
        logger.error(f"Quick Python setup failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }