"""
Intelligent Docker Environment Setup

Process:
1. LLM reads README for Docker image information
2. If found: Create Docker â†’ Direct to analysis (NO dependency check)  
3. If not found: Check pyproject/requirements â†’ Create Python Docker â†’ Run pip install â†’ Analysis
"""

import os
import re
import json
import logging
import asyncio
import uuid
from typing import Dict, Optional, Any, List
from pathlib import Path
import toml

from .subprocess_docker import (
    run_docker_command,
    execute_command_in_container,
    create_docker_container,
    execute_container_command
)

# Import centralized LLM functionality will be imported when needed

logger = logging.getLogger(__name__)


class DockerEnvironmentManager:
    """
    Docker environment setup with LLM-driven README analysis using centralized LLM client
    """
    
    def __init__(self, llm_client=None):
        self.llm_client = llm_client
        if llm_client:
            logger.info("Initialized Docker Environment Manager with provided LLM client")
        else:
            logger.info("Initialized Docker Environment Manager with centralized LLM client")
    
    async def setup_docker_environment(
        self,
        target_path: str,
        require_confirmation: bool = True
    ) -> Dict[str, Any]:
        try:
            logger.info(f"Starting simplified Docker setup for: {target_path}")

            # Step 0: Check for DEFAULT_DOCKER_COMMAND in .env first
            from ...config import settings
            if settings.DEFAULT_DOCKER_COMMAND:
                logger.info("Found DEFAULT_DOCKER_COMMAND in .env, using it directly")
                return await self._deploy_with_env_command(settings.DEFAULT_DOCKER_COMMAND, require_confirmation)

            # Step 1: LLMè¯»å–READMEèŽ·å–Dockerä¿¡æ¯ (only if no DEFAULT_DOCKER_COMMAND)
            docker_info = await self._llm_analyze_readme(target_path)

            if docker_info.get('has_docker_image'):
                # æ‰¾åˆ°Dockerä¿¡æ¯ â†’ ç”¨æˆ·ç¡®è®¤æµç¨‹
                logger.info("Found Docker image in project files")
                return await self._handle_found_docker_info(docker_info, require_confirmation)
            else:
                # æ²¡æ‰¾åˆ°Dockerä¿¡æ¯ â†’ ç›´æŽ¥äººå·¥è¾“å…¥
                logger.info("No Docker info found, proceeding to human input")
                return await self._setup_with_human_instruction(require_confirmation)
            
        except Exception as e:
            logger.error(f"Docker setup failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'target_path': target_path
            }
    
    async def _llm_analyze_readme(self, target_path: str) -> Dict[str, Any]:
        """
        Read README and Docker-related files to find complete docker run commands.
        """
        project_path = Path(target_path)
        all_content = ""
        files_checked = []
        
        # Check key files for Docker information
        docker_files = [
            'README.md', 'README.rst', 'README.txt', 'readme.md',
            'Dockerfile', 'docker-compose.yml', 'docker-compose.yaml'
        ]
        
        for file_name in docker_files:
            file_path = project_path / file_name
            if file_path.exists():
                try:
                    content = file_path.read_text(encoding='utf-8')
                    all_content += f"\n--- {file_name} ---\n{content}"
                    files_checked.append(file_name)
                    logger.info(f"Read {file_name} ({len(content)} chars)")
                except Exception as e:
                    logger.warning(f"Failed to read {file_name}: {e}")
        
        if not all_content:
            logger.info("No Docker-related files found")
            return {'has_docker_image': False}
        
        # Use provided LLM client or fallback to centralized LLM client
        try:
            if self.llm_client:
                # Use provided LLM client (from exploit agent)
                logger.info("Using provided LLM client for README analysis")
                
                prompt = f"""Find Docker run commands in these files:

{all_content}

Look for complete docker run commands, especially ones like:
docker run -it --rm --pull=always -e SANDBOX_RUNTIME_CONTAINER_IMAGE=... docker.all-hands.dev/all-hands-ai/openhands:0.49

Return only JSON:
{{
    "has_docker_image": true/false,
    "docker_image": "image_name_if_found",
    "complete_docker_command": "full_command_if_found"
}}"""

                # Use the Agent SDK LLM client approach
                from google.adk.models.llm_request import LlmRequest
                
                request = LlmRequest(
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                
                # Generate response asynchronously
                response_generator = self.llm_client.generate_content_async(request)
                response = None
                async for resp in response_generator:
                    response = resp.content
                    break  # Get first response
            else:
                # Fallback to centralized LLM client
                logger.info("Using centralized LLM client for README analysis")

                # Build LLM messages
                messages = [
                    {
                        "role": "system",
                        "content": "You are an expert at analyzing README files to extract Docker setup information. Return only valid JSON responses."
                    },
                    {
                        "role": "user",
                        "content": f"""Find Docker run commands in these files:

{all_content}

Look for complete docker run commands, especially ones like:
docker run -it --rm --pull=always -e SANDBOX_RUNTIME_CONTAINER_IMAGE=... docker.all-hands.dev/all-hands-ai/openhands:0.49

Return only JSON:
{{
    "has_docker_image": true/false,
    "docker_image": "image_name_if_found",
    "complete_docker_command": "full_command_if_found"
}}"""
                    }
                ]

                # Use centralized LLM client with proper error handling
                from ...tools.core.llm_client import LLMClient
                from ...config import settings

                # Setup API key if needed
                import os
                if not os.environ.get("OPENAI_API_KEY"):
                    api_key = settings.get_openai_api_key()
                    os.environ["OPENAI_API_KEY"] = api_key

                model = settings.EXPLOIT_AGENT_MODEL

                # Call LLM using centralized client
                response = LLMClient.call_llm(
                    model=model,
                    messages=messages,
                    max_tokens=500,
                    temperature=0.1,
                    timeout=30
                )
            
            if response:
                # Clean up response - remove markdown formatting
                cleaned_response = response.strip()
                
                # Remove markdown code blocks completely
                if cleaned_response.startswith('```json'):
                    cleaned_response = cleaned_response[7:]
                elif cleaned_response.startswith('```'):
                    cleaned_response = cleaned_response[3:]
                    
                if cleaned_response.endswith('```'):
                    cleaned_response = cleaned_response[:-3]
                    
                cleaned_response = cleaned_response.strip()
                
                # Fix common JSON issues
                # Handle unterminated strings by finding the last complete brace
                try:
                    result = json.loads(cleaned_response)
                except json.JSONDecodeError as e:
                    logger.warning(f"Initial JSON parse failed: {e}")
                    # Try to fix truncated JSON by finding last complete object
                    brace_count = 0
                    last_valid_pos = 0
                    for i, char in enumerate(cleaned_response):
                        if char == '{':
                            brace_count += 1
                        elif char == '}':
                            brace_count -= 1
                            if brace_count == 0:
                                last_valid_pos = i + 1
                                break
                    
                    if last_valid_pos > 0:
                        fixed_json = cleaned_response[:last_valid_pos]
                        try:
                            result = json.loads(fixed_json)
                            logger.info("Successfully parsed fixed JSON")
                        except json.JSONDecodeError:
                            logger.warning("Failed to parse fixed JSON, using fallback")
                            result = {'has_docker_image': False}
                    else:
                        logger.warning("Could not fix JSON, using fallback")
                        result = {'has_docker_image': False}
                
                logger.info(f"LLM README analysis: {result.get('has_docker_image', False)}")
                return result
            else:
                logger.warning("LLM returned no response for README analysis")
                return {'has_docker_image': False}
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse LLM JSON response: {e}")
            logger.warning(f"Raw LLM response: {response}")
            
            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«Dockerä¿¡æ¯ï¼Œå³ä½¿JSONè§£æžå¤±è´¥
            if response and any(keyword in response.lower() for keyword in ['docker.all-hands.dev', 'openhands', 'docker run']):
                logger.info("Detected Docker information in LLM response despite JSON error")
                # å°è¯•æ‰‹åŠ¨æå–åŸºæœ¬ä¿¡æ¯
                manual_config = self._manual_extract_docker_info(response)
                if manual_config.get('has_docker_image'):
                    return manual_config
            
            return {'has_docker_image': False}
        except Exception as e:
            logger.warning(f"LLM README analysis failed: {e}")
            return {'has_docker_image': False}
    
    async def _handle_found_docker_info(
        self,
        docker_info: Dict[str, Any], 
        require_confirmation: bool
    ) -> Dict[str, Any]:
        docker_image = docker_info.get('docker_image', 'python:3.12')
        runtime_image = docker_info.get('runtime_image', '')
        complete_command = docker_info.get('complete_docker_command', '')
        reasoning = docker_info.get('reasoning', '')
        
        if require_confirmation:
            print(f"\nðŸ³ Found Docker Configuration:")
            print(f"Main Image: {docker_image}")
            if runtime_image:
                print(f"Runtime Image: {runtime_image}")
            if complete_command:
                print(f"Complete Command: {complete_command[:100]}...")
            if reasoning:
                print(f"Analysis: {reasoning[:200]}...")
            
            print(f"\nOptions:")
            print(f"  y/yes  - Use this configuration and deploy")
            print(f"  n/custom - Enter custom docker command")
            print(f"  q/quit - Exit setup")
            
            while True:
                choice = input(f"\nYour choice [y/n/q]: ").strip().lower()
                
                if choice in ['y', 'yes']:
                    # ç›´æŽ¥ä½¿ç”¨æ‰¾åˆ°çš„é…ç½®éƒ¨ç½²
                    return await self._deploy_with_found_config(docker_info)
                    
                elif choice in ['n', 'custom']:
                    # è¿›å…¥è‡ªå®šä¹‰è¾“å…¥æµç¨‹
                    return await self._setup_with_custom_input()
                    
                elif choice in ['q', 'quit']:
                    # é€€å‡º
                    return {
                        'success': False,
                        'cancelled': True,
                        'message': 'User cancelled Docker setup'
                    }
                else:
                    print("Please enter 'y' (yes), 'n' (custom), or 'q' (quit)")
        else:
            # è‡ªåŠ¨æ¨¡å¼ç›´æŽ¥éƒ¨ç½²
            return await self._deploy_with_found_config(docker_info)
    
    async def _deploy_with_env_command(self, env_docker_command: str, require_confirmation: bool) -> Dict[str, Any]:
        """Deploy using DEFAULT_DOCKER_COMMAND from .env file - no confirmation needed"""
        try:
            # .env commands are automatically trusted and executed without confirmation
            print(f"\nðŸ³ Found DEFAULT_DOCKER_COMMAND in .env:")
            print(f"Command: {env_docker_command}")
            print(f"Automatically executing trusted .env command...")

            # Execute the env command directly without confirmation
            logger.info(f"Running DEFAULT_DOCKER_COMMAND: {env_docker_command}")
            deployment_id = await run_docker_command(env_docker_command)

            logger.info(f"Successfully deployed with env command: {deployment_id}")

            return {
                'success': True,
                'deployment_id': deployment_id,
                'docker_image': 'from_env_command',
                'setup_type': 'env_default_command',
                'ready_for_analysis': True,
                'source': 'env_default_docker_command',
                'original_command': env_docker_command
            }

        except Exception as e:
            logger.error(f"Failed to deploy env Docker command: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'env_command_failed'
            }

    async def _deploy_with_found_config(self, docker_info: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨æ‰¾åˆ°çš„é…ç½®ç›´æŽ¥éƒ¨ç½²"""
        try:
            complete_command = docker_info.get('complete_docker_command')
            
            if complete_command:
                # ç›´æŽ¥è¿è¡Œå®Œæ•´çš„Dockerå‘½ä»¤
                logger.info(f"Running complete Docker command: {complete_command}")
                deployment_id = await run_docker_command(complete_command)
            else:
                # ä½¿ç”¨ç®€å•çš„é•œåƒåˆ›å»º
                image = docker_info.get('docker_image', 'python:3.12')
                logger.info(f"Creating simple container with image: {image}")
                deployment_id = await create_docker_container(image)
            
            logger.info(f"Successfully deployed Docker configuration: {deployment_id}")
            
            return {
                'success': True,
                'deployment_id': deployment_id,
                'docker_image': docker_info.get('docker_image'),
                'setup_type': 'readme_docker_auto',
                'ready_for_analysis': True,
                'llm_reasoning': docker_info.get('reasoning', ''),
                'source': 'readme_analysis',
                'original_command': complete_command
            }
            
        except Exception as e:
            logger.error(f"Failed to deploy found Docker config: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'readme_docker_failed'
            }
    
    async def _setup_with_custom_input(self) -> Dict[str, Any]:
        """Handle custom user input for Docker command"""
        print("\nEnter your Docker command (multi-line supported):")
        print("Press Enter twice when finished, or 'END' on a new line:")
        print()
        
        # Collect multi-line input
        lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                if not line.strip() and lines:  # Empty line after some content
                    break
                lines.append(line)
            except EOFError:
                break
        
        custom_command = '\n'.join(lines).strip()
        
        if not custom_command:
            print("No command entered, using default: python:3.12")
            try:
                deployment_id = await create_docker_container(image="python:3.12")
                return {
                    'success': True,
                    'deployment_id': deployment_id,
                    'docker_image': "python:3.12",
                    'setup_type': 'custom_default',
                    'ready_for_analysis': True,
                    'source': 'user_default'
                }
            except Exception as e:
                return {'success': False, 'error': str(e)}
        else:
            print(f"\nðŸš€ Running Docker command directly...")
            print(f"Command: {custom_command}")
        
        # ç›´æŽ¥è¿è¡Œç”¨æˆ·è¾“å…¥çš„å‘½ä»¤
        try:
            deployment_id = await run_docker_command(custom_command)
            print(f"\nâœ… Container deployed successfully: {deployment_id}")
            
            return {
                'success': True,
                'deployment_id': deployment_id,
                'setup_type': 'custom_user_input',
                'ready_for_analysis': True,
                'source': 'user_custom_command',
                'original_command': custom_command
            }
        except Exception as e:
            logger.error(f"Custom deployment failed: {e}")
            return {
                'success': False,
                'error': str(e),
                'setup_type': 'custom_deployment_failed'
            }
    
    
    async def _setup_with_human_instruction(self, require_confirmation: bool) -> Dict[str, Any]:
        """No Docker info found - offer default or custom input"""
        print("\nNo Docker configuration found in README")
        print("Using default: python:3.12")
        
        if not require_confirmation:
            # Auto-mode: Use default
            try:
                from .swerex import create_deployment
                deployment_id = await create_deployment(image="python:3.12")
                return {
                    'success': True,
                    'deployment_id': deployment_id,
                    'docker_image': "python:3.12",
                    'setup_type': 'auto_default',
                    'ready_for_analysis': True
                }
            except Exception as e:
                return {'success': False, 'error': str(e)}
        
        # Interactive mode: Offer choice
        print("\nChoose:")
        print("  y/yes - Use default python:3.12")
        print("  n/custom - Enter custom command")
        print("  q/quit - Exit")
        
        while True:
            choice = input("Your choice [y/n/q]: ").strip().lower()
            
            if choice in ['y', 'yes']:
                try:
                    deployment_id = await create_docker_container(image="python:3.12")
                    return {
                        'success': True,
                        'deployment_id': deployment_id,
                        'docker_image': "python:3.12",
                        'setup_type': 'default_confirmed',
                        'ready_for_analysis': True
                    }
                except Exception as e:
                    return {'success': False, 'error': str(e)}
            elif choice in ['n', 'custom']:
                return await self._setup_with_custom_input()
            elif choice in ['q', 'quit']:
                return {'success': False, 'cancelled': True, 'message': 'User quit'}
            else:
                print("Invalid choice. Please enter 'y', 'n', or 'q'.")
    
    
    
    # ç§»é™¤å¤æ‚çš„Dockerå‘½ä»¤è§£æžï¼Œæ”¹ä¸ºç›´æŽ¥æ‰§è¡Œ
    
    # ç§»é™¤å¤æ‚çš„é…ç½®éƒ¨ç½²æ–¹æ³•ï¼Œæ”¹ä¸ºç›´æŽ¥è¿è¡Œå‘½ä»¤
    
    # ç§»é™¤å¤æ‚çš„LLMè§£æžæ–¹æ³•ï¼Œæ”¹ä¸ºç›´æŽ¥è¿è¡Œå‘½ä»¤
    
    # ä¿ç•™æ‰‹åŠ¨æå–åŠŸèƒ½ï¼Œä½†ç®€åŒ–å¤„ç†
    def _manual_extract_docker_info(self, llm_response: str) -> Dict[str, Any]:
        """ç®€åŒ–çš„æ‰‹åŠ¨Dockerä¿¡æ¯æå–"""
        try:
            import re
            
            # æŸ¥æ‰¾å®Œæ•´çš„docker runå‘½ä»¤
            docker_run_pattern = r'docker\s+run[^\n]+'
            docker_commands = re.findall(docker_run_pattern, llm_response)
            
            if docker_commands:
                complete_command = docker_commands[0]
                logger.info(f"Found Docker command: {complete_command}")
                return {
                    "has_docker_image": True,
                    "complete_docker_command": complete_command,
                    "reasoning": "Extracted complete docker run command"
                }
            
            # æŸ¥æ‰¾Dockeré•œåƒå
            image_patterns = [
                r'docker\.all-hands\.dev/[^\s"]+',
                r'openhands:[^\s"]+',
                r'"docker_image":\s*"([^"]+)"'
            ]
            
            for pattern in image_patterns:
                match = re.search(pattern, llm_response)
                if match:
                    if pattern.startswith('"docker_image"'):
                        image = match.group(1)
                    else:
                        image = match.group(0)
                    
                    return {
                        "has_docker_image": True,
                        "docker_image": image,
                        "reasoning": f"Found Docker image: {image}"
                    }
            
            return {"has_docker_image": False}
            
        except Exception as e:
            logger.error(f"Manual extraction failed: {e}")
            return {"has_docker_image": False}


# Global manager instance (will be updated with LLM client when needed)
_docker_manager = None


# Main function for AgentXploit integration
async def setup_intelligent_docker_environment(
    target_path: str,
    llm_client=None,  # LLM client from exploit agent
    require_confirmation: bool = True
) -> Dict[str, Any]:
    """
    Main Docker environment setup function.
    
    Process:
    1. LLM reads README for Docker image using provided LLM client
    2. If found: Create Docker â†’ Skip dependency check â†’ Ready for analysis
    3. If not: Check pyproject/requirements â†’ Create Python Docker â†’ pip install â†’ Ready for analysis
    
    POLICY: Always creates NEW containers, never reuses existing deployments.
    
    Args:
        target_path: Path to target project
        llm_client: LLM client from exploit agent (preferred) or None for centralized client
        require_confirmation: Whether to require user confirmation
        
    Returns:
        Environment setup results
        
    Note:
        This function now enforces the no-reuse policy by calling create_docker_container()
        which automatically ensures unique container creation.
    """
    global _docker_manager
    
    # SPECIAL HANDLING: Check if this is GPT-Research and use predefined command
    target_path_lower = target_path.lower()
    path_name_lower = Path(target_path).name.lower()
    
    is_research = (
        "gpt-researcher" in target_path_lower or
        "gptresearcher" in target_path_lower or
        path_name_lower == "gpt-researcher" or
        "gpt_researcher" in target_path_lower
    )
    
    if is_research:
        logger.info("SPECIAL HANDLING: GPT-Research detected - using DEFAULT_GPTR_DOCKER_COMMAND")
        
        # Read GPT-Research Docker command from environment
        gptr_docker_command = os.getenv("DEFAULT_GPTR_DOCKER_COMMAND")
        if not gptr_docker_command:
            logger.error("DEFAULT_GPTR_DOCKER_COMMAND not found in environment")
            return {
                "success": False,
                "error": "DEFAULT_GPTR_DOCKER_COMMAND not found in environment variables",
                "setup_type": "gptr_failed"
            }
        
        logger.info(f"Using predefined GPT-Research command: {gptr_docker_command}")
        
        # Execute the GPT-Research Docker command directly with unique naming
        try:
            # Generate unique container name to prevent conflicts
            import datetime
            timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
            unique_suffix = uuid.uuid4().hex[:8]
            unique_container_name = f"gpt-researcher-{timestamp}-{unique_suffix}"
            
            # Replace the fixed container name with unique name
            import re
            modified_command = re.sub(
                r'--name\s+gpt-researcher\b',
                f'--name {unique_container_name}',
                gptr_docker_command
            )
            
            logger.info(f"Modified GPT-Research command with unique name: {unique_container_name}")
            print(f"ðŸ“‹ Using modified command: {modified_command}")
            
            deployment_id = await run_docker_command(modified_command)
            logger.info(f"GPT-Research container created successfully: {deployment_id}")
            
            return {
                "success": True,
                "deployment_id": deployment_id,
                "docker_image": "gptresearcher/gpt-researcher",
                "setup_type": "gptr_predefined",
                "setup_method": "predefined_command",
                "docker_command_used": modified_command,
                "original_command": gptr_docker_command,
                "unique_container_name": unique_container_name,
                "target_path": target_path
            }
        except Exception as e:
            logger.error(f"Failed to create GPT-Research container: {e}")
            return {
                "success": False,
                "error": f"Failed to create GPT-Research container: {e}",
                "setup_type": "gptr_failed"
            }
    
    # For non-research workflows, use standard intelligent setup
    # Create or update manager with LLM client
    if llm_client:
        _docker_manager = DockerEnvironmentManager(llm_client=llm_client)
    elif _docker_manager is None:
        _docker_manager = DockerEnvironmentManager()
    
    return await _docker_manager.setup_docker_environment(
        target_path=target_path,
        require_confirmation=require_confirmation
    )


async def quick_python_setup(python_version: str = "3.12") -> Dict[str, Any]:
    """
    Quick Python environment setup without analysis.
    
    Args:
        python_version: Python version to use
        
    Returns:
        Environment setup results
    """
    try:
        python_image = f"python:{python_version}"
        deployment_id = await create_docker_container(image=python_image)
        
        logger.info(f"Created quick Python environment: {deployment_id}")
        
        return {
            'success': True,
            'deployment_id': deployment_id,
            'docker_image': python_image,
            'setup_type': 'quick_python'
        }
        
    except Exception as e:
        logger.error(f"Quick Python setup failed: {e}")
        return {
            'success': False,
            'error': str(e)
        }