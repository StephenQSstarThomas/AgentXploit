"""
Simplified OpenHands Specialized Executor
Minimal implementation focused on core task execution and trace collection
"""

import asyncio
import json
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional

import logging

# Setup logger
logger = logging.getLogger(__name__)
if not logger.handlers:
    handler = logging.StreamHandler()
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    logger.setLevel(logging.INFO)


@dataclass
class OpenHandsConfig:
    """Configuration for OpenHands execution"""
    workspace_dir: str = "/workspace"
    openhands_dir: str = "/workspace"  # Run directly in /workspace
    shared_dir: str = "/shared"  # Use root-level /shared to match config.toml
    trajectories_path: str = "/shared/trajectories"  # Final trajectory file location (no extension)


class OpenHandsSpecializedExecutor:
    """
    Simplified OpenHands executor with minimal command execution
    Only executes user-provided or model-generated task commands
    """
    
    def __init__(self, deployment_id: str, deployment_config: Dict[str, Any] = None):
        """Initialize with deployment configuration"""
        self.deployment_id = deployment_id
        self.deployment_config = deployment_config or {}
        self.config = OpenHandsConfig()
        
        # Store target path if provided in config
        self.target_path = Path(deployment_config.get('target_path', '.')) if deployment_config else Path('.')
        
        logger.info(f"Initialized OpenHands executor for deployment: {deployment_id}")
        logger.info(f"Target path: {self.target_path}")
        logger.info(f"Trajectories will be saved to: {self.config.trajectories_path}")
    
    async def setup_minimal_environment(self) -> bool:
        """
        Minimal environment setup - only create essential files and directories
        No redundant command execution
        """
        try:
            from .subprocess_docker import execute_in_container_session
            
            session_id = "openhands_session"
            
            # Only create workspace directory, let OpenHands handle /shared
            setup_cmd = f"""
mkdir -p {self.config.workspace_dir} && \\
echo "Workspace directory created successfully"
"""
            
            result = await execute_in_container_session(
                command=setup_cmd.strip(),
                session_name=session_id,
                deployment_id=self.deployment_id,
                timeout=30.0
            )
            
            if not result.success:
                logger.error(f"Failed to create directories: {result.stderr}")
                return False
            
            # Copy essential files if they don't exist
            copy_ok = await self._copy_essential_files(session_id)
            if not copy_ok:
                logger.error("Aborting environment setup due to test_run.py copy failure")
                return False
            
            logger.info("Minimal environment setup completed")
            return True
            
        except Exception as e:
            logger.error(f"Environment setup failed: {e}")
            return False
    
    async def _copy_essential_files(self, session_id: str) -> bool:
        """Copy essential files - check local files first, then create defaults.
        Returns True on success, False if critical file copy fails.
        """
        from .subprocess_docker import execute_in_container_session
        
        # Essential files to check and copy (order matters!)
        essential_files = ["test_run.py", "config.toml", "test.json"]
        files_copied = 0
        
        logger.info(f"Copying essential files from {self.target_path} to container...")
        
        for filename in essential_files:
            container_path = f"{self.config.openhands_dir}/{filename}"
            
            # test_run.py MUST be copied from local, no fallback allowed
            if filename == "test_run.py":
                logger.info(f"📁 REQUIRED: Copying local {filename} (no fallback allowed)")
                local_test_run = self.target_path / filename
                if not local_test_run.exists():
                    logger.error(f"❌ CRITICAL: Local {filename} not found at {local_test_run}")
                    logger.error(f"❌ Cannot proceed without local test_run.py - ABORTING")
                    return False  # Abort the entire copy process
                
                try:
                    # Read local test_run.py content
                    local_content = local_test_run.read_text(encoding='utf-8', errors='ignore')
                    
                    # Copy to container
                    create_cmd = f"""cat > {container_path} << 'EOF'
{local_content}
EOF"""
                    
                    copy_result = await execute_in_container_session(
                        command=create_cmd,
                        session_name=session_id,
                        deployment_id=self.deployment_id,
                        timeout=30.0
                    )
                    
                    if copy_result.success:
                        logger.info(f"✅ Successfully copied local {filename}")
                        files_copied += 1
                    else:
                        logger.error(f"❌ CRITICAL: Failed to copy local {filename}: {copy_result.stderr}")
                        logger.error(f"❌ Cannot proceed without test_run.py - ABORTING")
                        return False  # Abort the entire copy process
                        
                except Exception as e:
                    logger.error(f"❌ CRITICAL: Error reading local {filename}: {e}")
                    logger.error(f"❌ Cannot proceed without test_run.py - ABORTING")
                    return False  # Abort the entire copy process
                
                # Always add chmod for test_run.py
                chmod_result = await execute_in_container_session(
                    command=f"chmod +x {container_path}",
                    session_name=session_id,
                    deployment_id=self.deployment_id,
                    timeout=10.0
                )
                
                if chmod_result.success:
                    logger.info(f"✅ Added execute permissions to {filename}")
                else:
                    logger.warning(f"⚠️ Failed to add execute permissions: {chmod_result.stderr}")
                
                continue
            
            # Check if other files exist in container
            check_cmd = f"ls -la {container_path}"
            check_result = await execute_in_container_session(
                command=check_cmd,
                session_name=session_id,
                deployment_id=self.deployment_id,
                timeout=10.0
            )
            
            if check_result.success:
                logger.info(f"✅ {filename} already exists in container")
                files_copied += 1
                continue
            
            # For other files, check local file first
            local_file = self.target_path / filename
            
            if local_file.exists():
                logger.info(f"📁 Copying local {filename} to container")
                try:
                    # Read local file content
                    local_content = local_file.read_text(encoding='utf-8', errors='ignore')
                    
                    # Copy to container
                    create_cmd = f"""cat > {container_path} << 'EOF'
{local_content}
EOF"""
                    
                    copy_result = await execute_in_container_session(
                        command=create_cmd,
                        session_name=session_id,
                        deployment_id=self.deployment_id,
                        timeout=30.0
                    )
                    
                    if copy_result.success:
                        logger.info(f"✅ Successfully copied local {filename}")
                        files_copied += 1
                    else:
                        logger.warning(f"⚠️ Failed to copy local {filename}: {copy_result.stderr}")
                        # Create default version
                        await self._create_default_file(filename, container_path, session_id)
                        
                except Exception as e:
                    logger.warning(f"⚠️ Error reading local {filename}: {e}")
                    # Create default version
                    await self._create_default_file(filename, container_path, session_id)
            else:
                logger.info(f"📝 Creating default {filename} (local file not found)")
                await self._create_default_file(filename, container_path, session_id)
                
        # Note: chmod is now handled in the execution command and during file copy
        
        logger.info(f"Essential files setup completed: {files_copied}/{len(essential_files)} files ready")
        
        # Verify files are accessible
        await self._verify_files_in_container(session_id)

        return True
    
    async def _create_default_file(self, filename: str, container_path: str, session_id: str):
        """Create default version of essential file"""
        from .subprocess_docker import execute_in_container_session
        
        content = ""
        if filename == "test_run.py":
            # This should never happen as we require local copy
            raise RuntimeError("test_run.py must be copied from local file, not generated")
        elif filename == "config.toml":
            content = self._generate_config_toml()
        elif filename == "test.json":
            content = json.dumps({"task": "security_analysis", "status": "ready"}, indent=2)
        
        create_cmd = f"""cat > {container_path} << 'EOF'
{content}
EOF"""
        
        result = await execute_in_container_session(
            command=create_cmd,
            session_name=session_id,
            deployment_id=self.deployment_id,
            timeout=30.0
        )
        
        if result.success:
            logger.info(f"✅ Created default {filename}")
        else:
            logger.error(f"❌ Failed to create default {filename}: {result.stderr}")
    
    async def _verify_files_in_container(self, session_id: str):
        """Verify that essential files exist and are readable in container"""
        from .subprocess_docker import execute_in_container_session
        
        verify_cmd = f"ls -la {self.config.openhands_dir}/"
        result = await execute_in_container_session(
            command=verify_cmd,
            session_name=session_id,
            deployment_id=self.deployment_id,
            timeout=10.0
        )
        
        if result.success:
            logger.info(f"📋 Container files verification:")
            logger.info(result.stdout)
        else:
            logger.warning(f"⚠️ Could not verify container files: {result.stderr}")
    
    def _generate_test_run_script(self) -> str:
        """This function should never be called as test_run.py must be copied from local"""
        raise RuntimeError("test_run.py must be copied from local file, not generated")
    
    def _generate_config_toml(self) -> str:
        """Generate minimal config.toml"""
        return '''[core]
workspace_dir = "/workspace"
traces_dir = "/workspace/shared/traces"

[agent]
name = "CodeActAgent"
max_iterations = 10

[runtime]
container_image = "python:3.12"
'''
    
    async def execute_task(
        self,
        task_description: str = "Analyze repository for security vulnerabilities",
        max_iterations: int = 10,
        custom_command: str = None
    ) -> Dict[str, Any]:
        """
        Execute OpenHands task - runs test_run.py or custom command
        """
        try:
            from .subprocess_docker import execute_in_container_session
            
            session_id = "openhands_session"
            
            # Use custom command or default
            if custom_command:
                logger.info(f"Executing custom command: {custom_command}")
                full_command = custom_command
            else:
                logger.info("Executing default OpenHands test_run.py")
                full_command = "cd /workspace && chmod +x test_run.py && python3 test_run.py"
            
            # Execute the main command
            result = await execute_in_container_session(
                command=full_command,
                session_name=session_id,
                deployment_id=self.deployment_id,
                timeout=600.0
            )
            
            logger.info(f"Task execution completed. Success: {result.success}")
            
            # Print command results to terminal for user visibility
            print(f"\n🔧 OpenHands Command Execution:")
            print(f"Command: {full_command}")
            print(f"Success: {'✅' if result.success else '❌'}")
            
            if result.stdout:
                print(f"\n📤 Output:")
                print(result.stdout)
            
            if result.stderr:
                print(f"\n⚠️ Errors/Warnings:")
                print(result.stderr)
            
            if not result.success:
                print(f"\n❌ Command failed with return code: {getattr(result, 'return_code', 'unknown')}")
            
            # Collect traces from fixed location
            traces = await self._collect_traces()
            
            return {
                "success": result.success,
                "command": full_command,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "task_description": task_description,
                "traces_found": len(traces),
                "trace_files": traces,
                "trajectories_path": self.config.trajectories_path
            }
            
        except Exception as e:
            logger.error(f"Task execution failed: {e}")
            
            # Print error to terminal for user visibility
            print(f"\n❌ OpenHands Task Execution Failed:")
            print(f"Error: {str(e)}")
            print(f"Command: {custom_command or 'unknown'}")
            print(f"Task: {task_description}")
            
            return {
                "success": False,
                "error": str(e),
                "command": custom_command or "unknown",
                "task_description": task_description,
                "traces_found": 0,
                "trace_files": []
            }
    
    async def _collect_traces(self) -> List[str]:
        """
        Collect trace files - look for /shared/trajectories (whatever it is)
        """
        try:
            from .subprocess_docker import execute_in_container_session
            
            session_id = "openhands_session"
            all_traces = []
            
            # Check if /shared/trajectories exists (could be file or directory)
            logger.info(f"🔍 Looking for OpenHands trajectories at: {self.config.trajectories_path}")
            check_cmd = f"test -e {self.config.trajectories_path} && echo 'EXISTS' || echo 'NOT_FOUND'"
            
            result = await execute_in_container_session(
                command=check_cmd,
                session_name=session_id,
                deployment_id=self.deployment_id,
                timeout=10.0
            )
            
            if result.success and "EXISTS" in result.stdout:
                logger.info(f"✅ Found trajectories at: {self.config.trajectories_path}")
                all_traces.append(self.config.trajectories_path)
                
                # Check if it's a file or directory
                type_cmd = f"test -f {self.config.trajectories_path} && echo 'FILE' || (test -d {self.config.trajectories_path} && echo 'DIRECTORY' || echo 'OTHER')"
                type_result = await execute_in_container_session(
                    command=type_cmd,
                    session_name=session_id,
                    deployment_id=self.deployment_id,
                    timeout=10.0
                )
                if type_result.success:
                    trace_type = type_result.stdout.strip()
                    logger.info(f"📄 Trajectories type: {trace_type}")
                    
                    # If it's a directory, list its contents
                    if "DIRECTORY" in trace_type:
                        list_cmd = f"ls -la {self.config.trajectories_path}/ 2>/dev/null | head -10"
                        list_result = await execute_in_container_session(
                            command=list_cmd,
                            session_name=session_id,
                            deployment_id=self.deployment_id,
                            timeout=10.0
                        )
                        if list_result.success:
                            logger.info(f"📂 Directory contents:\n{list_result.stdout}")
                            
                            # Find JSON files in the directory
                            find_cmd = f"find {self.config.trajectories_path} -name '*.json' -type f 2>/dev/null"
                            find_result = await execute_in_container_session(
                                command=find_cmd,
                                session_name=session_id,
                                deployment_id=self.deployment_id,
                                timeout=10.0
                            )
                            if find_result.success and find_result.stdout.strip():
                                json_files = [f.strip() for f in find_result.stdout.strip().split('\n') if f.strip()]
                                all_traces.extend(json_files)
                                logger.info(f"📋 Found {len(json_files)} JSON files in trajectories directory")
            else:
                logger.warning(f"⚠️ Trajectories not found at: {self.config.trajectories_path}")
            
            # Also check for any other trajectory files in /shared
            logger.info("🔍 Checking for other trajectory files in /shared...")
            find_shared_cmd = f"find /shared -maxdepth 2 -name '*trajectory*' -o -name '*.json' 2>/dev/null | grep -v '^/shared/trajectories$'"
            
            result = await execute_in_container_session(
                command=find_shared_cmd,
                session_name=session_id,
                deployment_id=self.deployment_id,
                timeout=10.0
            )
            
            if result.success and result.stdout.strip():
                shared_files = [f.strip() for f in result.stdout.strip().split('\n') if f.strip()]
                logger.info(f"📂 Found {len(shared_files)} additional files in /shared")
                for shared_file in shared_files:
                    if shared_file not in all_traces:
                        all_traces.append(shared_file)
            
            # If no traces found, show what's in /shared directory
            if not all_traces:
                logger.warning("❌ No trajectory files found")
                debug_cmd = "ls -la /shared/ 2>/dev/null || echo 'No /shared directory'"
                debug_result = await execute_in_container_session(
                    command=debug_cmd,
                    session_name=session_id,
                    deployment_id=self.deployment_id,
                    timeout=10.0
                )
                if debug_result.success:
                    logger.info(f"📂 /shared directory contents:\n{debug_result.stdout}")
            else:
                logger.info(f"📋 Total trace files found: {len(all_traces)}")
                for i, trace_file in enumerate(all_traces, 1):
                    logger.info(f"  {i}. {trace_file}")
            
            return all_traces
            
        except Exception as e:
            logger.error(f"Failed to collect traces: {e}")
            return []
    
    async def analyze_traces(self, trace_files: List[str]) -> Dict[str, Any]:
        """
        Simplified trace analysis with minimal file operations
        Only reads essential content for analysis
        """
        logger.info(f"Analyzing {len(trace_files)} trace files")
        
        injection_points = []
        external_sources = []
        
        try:
            from .subprocess_docker import execute_in_container_session
            
            session_id = "openhands_session"
            
            # Analyze maximum 3 files to avoid overhead
            for trace_file in trace_files[:3]:
                try:
                    # Read only first 50 lines for analysis
                    read_cmd = f"head -50 '{trace_file}'"
                    
                    result = await execute_in_container_session(
                        command=read_cmd,
                        session_name=session_id,
                        deployment_id=self.deployment_id,
                        timeout=10.0
                    )
                    
                    if result.success and result.stdout:
                        content = result.stdout.lower()
                        
                        # Simple pattern matching for injection detection
                        if any(pattern in content for pattern in ['command', 'exec', 'api', 'github']):
                            injection_points.append({
                                "type": "openhands_execution",
                                "location": trace_file,
                                "description": "OpenHands execution trace",
                                "risk": "MEDIUM",
                                "agent_type": "openhands"
                            })
                        
                        # Detect external input sources
                        if any(pattern in content for pattern in ['task', 'prompt', 'input']):
                            external_sources.append({
                                "source": "task_input",
                                "location": trace_file,
                                "content": f"Trace: {os.path.basename(trace_file)}",
                                "risk": "MEDIUM"
                            })
                            
                except Exception as e:
                    logger.warning(f"Failed to analyze {trace_file}: {e}")
            
            return {
                "success": True,
                "total_traces": len(trace_files),
                "injection_points": injection_points,
                "external_data_sources": external_sources,
                "high_risk_points": [p for p in injection_points if p.get("risk") == "HIGH"],
                "overall_risk": "HIGH" if any(p.get("risk") == "HIGH" for p in injection_points) else "MEDIUM"
            }
            
        except Exception as e:
            logger.error(f"Trace analysis failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "injection_points": [],
                "external_data_sources": []
            }
    
    async def cleanup(self):
        """
        Minimal cleanup - only remove temporary files if needed
        """
        try:
            logger.info("Cleanup completed")
        except Exception as e:
            logger.error(f"Cleanup failed: {e}")


# Global instance for backward compatibility
_openhands_executor = None

def get_openhands_executor(deployment_id: str, config: Dict[str, Any] = None) -> OpenHandsSpecializedExecutor:
    """Get or create OpenHands executor instance"""
    global _openhands_executor
    
    if _openhands_executor is None or _openhands_executor.deployment_id != deployment_id:
        _openhands_executor = OpenHandsSpecializedExecutor(deployment_id, config)
    
    return _openhands_executor


# Backward compatibility functions
async def setup_openhands_environment(deployment_id: str, config: Dict[str, Any] = None) -> bool:
    """Setup OpenHands environment with minimal configuration"""
    executor = get_openhands_executor(deployment_id, config)
    return await executor.setup_minimal_environment()


async def execute_openhands_task(
    deployment_id: str,
    task_description: str = "Analyze repository for security vulnerabilities",
    max_iterations: int = 10,
    custom_command: str = None
) -> Dict[str, Any]:
    """Execute OpenHands task with simplified logic"""
    executor = get_openhands_executor(deployment_id)
    return await executor.execute_task(task_description, max_iterations, custom_command)


async def analyze_openhands_traces(deployment_id: str, trace_files: List[str] = None) -> Dict[str, Any]:
    """Analyze OpenHands traces with minimal operations"""
    executor = get_openhands_executor(deployment_id)
    
    if trace_files is None:
        trace_files = await executor._collect_traces()
    
    return await executor.analyze_traces(trace_files)