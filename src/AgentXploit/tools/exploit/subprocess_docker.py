"""
Subprocess-based Docker and Command Execution Tool

直接运行Docker命令和容器内命令，无复杂解析。

=== CONTAINER REUSE POLICY ===
CRITICAL POLICY: All container creation functions now PROHIBIT reusing existing containers.
Every call to create_docker_container() or create_development_container() will:
1. Generate unique deployment IDs to prevent conflicts
2. Force cleanup any existing containers with similar names
3. Create completely fresh containers from scratch
4. Never reuse or reconnect to existing containers

This ensures clean, reproducible environments for all workflows.
"""

import asyncio
import logging
import subprocess
import uuid
import time
import shlex
import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, Union
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class ExecutionResult:
    """Result of command execution."""
    command: str
    success: bool
    stdout: str
    stderr: str
    return_code: int
    execution_time: float
    session_id: Optional[str] = None


@dataclass
class ContainerInfo:
    """Information about a running Docker container."""
    deployment_id: str
    container_id: str
    image: str
    created_at: float
    original_command: str  # 原始Docker命令
    has_rm_flag: bool  # 是否包含--rm标志


class DirectDockerRunner:
    """
    直接运行Docker命令的执行器。
    
    核心理念：
    1. 用户输入什么命令就运行什么命令
    2. 从README解析到什么命令就运行什么命令
    3. 不进行复杂的参数解析和重组
    """
    
    def __init__(self):
        self.containers: Dict[str, ContainerInfo] = {}
        logger.info("Initialized direct Docker runner")
    
    async def run_docker_command_directly(self, docker_command: str) -> str:
        """
        直接运行完整的Docker命令，正确处理环境变量展开。
        
        Args:
            docker_command: 完整的docker run命令（用户输入或README中的）
            
        Returns:
            deployment_id: 生成的部署ID用于后续操作
        """
        try:
            # === POLICY ENFORCEMENT: PROHIBIT CONTAINER REUSE ===
            # Generate unique deployment ID to ensure new container creation
            import datetime
            timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
            unique_suffix = uuid.uuid4().hex[:8]  # Add unique suffix to prevent conflicts
            deployment_id = f"direct_{timestamp}_{unique_suffix}"
            
            # CRITICAL: Check if any container with similar name exists and force cleanup
            await self._ensure_no_existing_containers(deployment_id)
            
            # 预处理命令：展开环境变量
            processed_command = docker_command
            
            # 处理$UID变量
            if '$UID' in processed_command:
                uid = os.getuid()
                processed_command = processed_command.replace('$UID', str(uid))
                logger.info(f"Expanded $UID to {uid}")
            
            # 处理其他常见的环境变量
            import re
            env_vars = re.findall(r'\$([A-Z_][A-Z0-9_]*)', processed_command)
            for var in env_vars:
                if var in os.environ:
                    processed_command = processed_command.replace(f'${var}', os.environ[var])
                    logger.info(f"Expanded ${var} to {os.environ[var]}")
            
            # 检查是否有--rm标志（用于后续清理判断）
            has_rm_flag = '--rm' in processed_command
            
            # 保持原始的-it和--rm参数不变
            logger.info(f"Preserving original flags: -it and --rm as specified in command")
            logger.info(f"Container will auto-cleanup: {has_rm_flag}")
            
            logger.info(f"Original command: {docker_command}")
            logger.info(f"Processed command: {processed_command}")
            
            # 检查命令是否包含docker run
            if 'docker run' not in processed_command:
                raise ValueError("Command must contain 'docker run'")

            
            # 使用shell执行完整命令，确保环境变量正确展开
            result = await asyncio.create_subprocess_shell(
                processed_command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()  # 传递完整的环境变量
            )
            stdout, stderr = await result.communicate()
            
            if result.returncode != 0:
                error_msg = f"Docker command failed: {stderr.decode()}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # 获取容器ID
            container_id = stdout.decode().strip()
            if not container_id:
                # 如果没有返回容器ID，尝试从docker ps获取最新的容器
                ps_result = await asyncio.create_subprocess_shell(
                    "docker ps -l -q",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                ps_stdout, _ = await ps_result.communicate()
                container_id = ps_stdout.decode().strip()
            
            # 尝试从命令中提取镜像名
            image = "unknown"
            try:
                # 简单提取最后一个看起来像镜像名的部分
                parts = processed_command.split()
                for part in reversed(parts):
                    if ':' in part and not part.startswith('-') and '/' in part:
                        image = part
                        break
                    elif not part.startswith('-') and not '=' in part and len(part) > 3:
                        # 可能是简单的镜像名
                        if part not in ['bash', 'sh', 'tail', '/dev/null']:
                            image = part
            except:
                pass
            
            # 存储容器信息
            container_info = ContainerInfo(
                deployment_id=deployment_id,
                container_id=container_id,
                image=image,
                created_at=time.time(),
                original_command=docker_command,
                has_rm_flag=has_rm_flag
            )
            
            self.containers[deployment_id] = container_info
            
            logger.info(f"Docker command executed successfully: {deployment_id} -> {container_id}")
            logger.info(f"Detected image: {image}")
            
            return deployment_id
            
        except Exception as e:
            logger.error(f"Failed to run Docker command directly: {e}")
            raise
    
    async def execute_in_container(
        self,
        command: str,
        deployment_id: str,
        timeout: Optional[float] = None,
        live_output: bool = True
    ) -> ExecutionResult:
        """
        在指定容器中执行命令。

        Args:
            command: 要执行的命令
            deployment_id: 容器部署ID
            timeout: 超时时间

        Returns:
            ExecutionResult: 执行结果
        """
        start_time = time.time()

        try:
            if deployment_id not in self.containers:
                raise ValueError(f"Container not found: {deployment_id}")

            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # Check container health and restart if needed
            await self._ensure_container_running(deployment_id)

            # Update container_id after potential restart
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # 构建docker exec命令
            docker_exec_cmd = f"docker exec {container_id} bash -c {shlex.quote(command)}"

            logger.info(f"Executing in container {container_id}: {command}")

            # 执行命令
            process = await asyncio.create_subprocess_shell(
                docker_exec_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            if timeout:
                try:
                    # 实时输出流监控
                    stdout_data, stderr_data = await asyncio.wait_for(
                        self._stream_output(process, command, live_output), timeout=timeout
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"Command timed out after {timeout} seconds: {command}")
                    process.terminate()
                    try:
                        await asyncio.wait_for(process.wait(), timeout=10)
                    except asyncio.TimeoutError:
                        process.kill()
                        await process.wait()
                    raise
            else:
                # 对于无超时的情况，也使用流式输出
                stdout_data, stderr_data = await self._stream_output(process, command, live_output)

            execution_time = time.time() - start_time
            success = process.returncode == 0

            stdout_str = stdout_data
            stderr_str = stderr_data

            # 立即检测常见的失败模式
            if not success:
                logger.error(f"Command failed with return code {process.returncode}: {command}")
                if stderr_str:
                    logger.error(f"Error output: {stderr_str}")

                # 检测常见的错误模式
                if "No such file or directory" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: File or directory not found")
                elif "Permission denied" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Permission denied")
                elif "Command not found" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Command not found")
                elif "ModuleNotFoundError" in stderr_str or "ImportError" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Python module/import error")
                elif "SyntaxError" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Python syntax error")
                elif "docker: Error" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Docker error")

            # 即使成功也检查stderr中的警告
            elif stderr_str and ("error" in stderr_str.lower() or "warning" in stderr_str.lower()):
                logger.warning(f"Command succeeded but has warnings/errors in stderr: {stderr_str}")

            return ExecutionResult(
                command=command,
                success=success,
                stdout=stdout_str,
                stderr=stderr_str,
                return_code=process.returncode or 0,
                execution_time=execution_time
            )
            
        except asyncio.TimeoutError:
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=f"Command timed out after {timeout} seconds",
                return_code=-1,
                execution_time=time.time() - start_time
            )
        except Exception as e:
            logger.error(f"Command execution failed: {e}")
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=str(e),
                return_code=-1,
                execution_time=time.time() - start_time
            )

    async def _stream_output(self, process, command: str, live_output: bool = True):
        """实时流式读取并显示进程输出"""
        stdout_data = []
        stderr_data = []

        async def read_stdout():
            """读取stdout流"""
            while True:
                try:
                    line = await process.stdout.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='replace')
                    stdout_data.append(line_str)
                    # 实时显示输出（移除末尾换行符避免双换行）
                    if live_output:
                        print(f"[STDOUT] {line_str.rstrip()}", flush=True)
                except Exception as e:
                    logger.debug(f"Error reading stdout: {e}")
                    break

        async def read_stderr():
            """读取stderr流并检测退出信号"""
            while True:
                try:
                    line = await process.stderr.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='replace')
                    stderr_data.append(line_str)

                    # 实时显示错误输出
                    if live_output:
                        print(f"[STDERR] {line_str.rstrip()}", flush=True)

                    # 检测 OpenHands 退出信号
                    line_lower = line_str.lower()
                    if ("connection refused" in line_lower or
                        "connecterror" in line_lower or
                        "errno 111" in line_lower or
                        ("session was interrupted" in line_lower and "openhands" in line_lower) or
                        ("sys.exit" in line_lower) or
                        ("system exit" in line_lower)):

                        if live_output:
                            print(f"\n🚨 [EARLY_TERMINATION] Detected OpenHands exit signal in stderr!", flush=True)
                            print(f"🚨 [EARLY_TERMINATION] Terminating process early to avoid timeout wait!", flush=True)

                        logger.warning(f"Early termination detected: {line_str.strip()}")

                        # 立即终止进程
                        try:
                            process.terminate()
                            # 给进程2秒时间优雅退出
                            await asyncio.wait_for(process.wait(), timeout=2.0)
                        except asyncio.TimeoutError:
                            # 如果优雅退出失败，强制杀死
                            process.kill()
                            await process.wait()

                        if live_output:
                            print(f"✅ [EARLY_TERMINATION] Process terminated successfully!", flush=True)
                        break

                except Exception as e:
                    logger.debug(f"Error reading stderr: {e}")
                    break

        async def monitor_progress():
            """监控执行进度"""
            start_time = time.time()
            while process.returncode is None:
                try:
                    await asyncio.sleep(30)  # 每30秒报告一次进度

                    # 如果进程已经终止，停止监控
                    if process.returncode is not None:
                        if live_output:
                            print(f"\n[PROGRESS] Process terminated, stopping progress monitoring.\n", flush=True)
                        break

                    current_time = time.time()
                    elapsed = current_time - start_time
                    logger.info(f"Progress: Command still running after {elapsed:.1f}s")
                    if live_output:
                        print(f"\n[PROGRESS] Command running for {elapsed:.1f}s...\n", flush=True)
                except asyncio.CancelledError:
                    if live_output:
                        print(f"\n[PROGRESS] Progress monitoring cancelled.\n", flush=True)
                    break
                except Exception as e:
                    logger.debug(f"Progress monitoring error: {e}")
                    break

        # 启动所有任务
        tasks = [
            asyncio.create_task(read_stdout()),
            asyncio.create_task(read_stderr()),
            asyncio.create_task(monitor_progress())
        ]

        try:
            # 等待进程完成
            await process.wait()
        finally:
            # 取消所有任务
            for task in tasks:
                if not task.done():
                    task.cancel()

            # 等待任务完成或被取消
            await asyncio.gather(*tasks, return_exceptions=True)

        # 返回累积的输出
        return ''.join(stdout_data), ''.join(stderr_data)

    async def _ensure_no_existing_containers(self, deployment_id: str) -> None:
        """
        POLICY ENFORCEMENT: Ensure no existing containers can be reused.
        Force cleanup of any containers that might conflict with new deployment.
        
        Args:
            deployment_id: Proposed deployment ID for new container
        """
        try:
            logger.info(f"POLICY: Ensuring no existing containers for {deployment_id}")
            
            # Check if deployment_id already exists in our registry
            if deployment_id in self.containers:
                logger.warning(f"POLICY VIOLATION: deployment_id {deployment_id} already exists in registry")
                old_container_info = self.containers[deployment_id]
                
                # Force stop and remove the old container
                logger.warning(f"FORCE CLEANUP: Removing old container {old_container_info.container_id}")
                try:
                    # Stop container
                    stop_cmd = f"docker stop {old_container_info.container_id}"
                    stop_result = await asyncio.create_subprocess_shell(
                        stop_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    await stop_result.communicate()
                    
                    # Remove container
                    rm_cmd = f"docker rm {old_container_info.container_id}"
                    rm_result = await asyncio.create_subprocess_shell(
                        rm_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    await rm_result.communicate()
                    
                    logger.info(f"FORCE CLEANUP: Successfully removed old container")
                except Exception as cleanup_e:
                    logger.warning(f"FORCE CLEANUP: Failed to remove old container: {cleanup_e}")
                
                # Remove from registry
                del self.containers[deployment_id]
                logger.info(f"POLICY: Removed {deployment_id} from container registry")
            
            # Check for any containers with similar names and force cleanup
            try:
                # Search for containers with similar deployment_id pattern
                base_name = deployment_id.split('_')[0] if '_' in deployment_id else deployment_id
                
                # Special handling for gpt-researcher containers
                search_patterns = [base_name]
                if 'gpt-researcher' in deployment_id or 'gpt-researcher' in base_name:
                    search_patterns.extend(['gpt-researcher', 'gptresearcher'])
                
                existing_containers = []
                for pattern in search_patterns:
                    search_cmd = f"docker ps -a --filter name={pattern} --format '{{{{.Names}}}}'"
                    
                    search_result = await asyncio.create_subprocess_shell(
                        search_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    stdout, stderr = await search_result.communicate()
                    
                    if search_result.returncode == 0 and stdout.strip():
                        pattern_containers = stdout.decode().strip().split('\n')
                        pattern_containers = [c.strip() for c in pattern_containers if c.strip()]
                        existing_containers.extend(pattern_containers)
                
                # Remove duplicates
                existing_containers = list(set(existing_containers))
                
                if existing_containers:
                    logger.warning(f"POLICY: Found {len(existing_containers)} existing containers to cleanup: {existing_containers}")
                    for container_name in existing_containers:
                        logger.warning(f"FORCE CLEANUP: Removing container {container_name}")
                        try:
                            # Force stop and remove
                            cleanup_cmd = f"docker stop {container_name} && docker rm {container_name}"
                            cleanup_result = await asyncio.create_subprocess_shell(
                                cleanup_cmd,
                                stdout=asyncio.subprocess.PIPE,
                                stderr=asyncio.subprocess.PIPE
                            )
                            await cleanup_result.communicate()
                            logger.info(f"FORCE CLEANUP: Removed container {container_name}")
                        except Exception as e:
                            logger.warning(f"FORCE CLEANUP: Failed to remove {container_name}: {e}")
                
            except Exception as search_e:
                logger.debug(f"POLICY: Container search failed (acceptable): {search_e}")
            
            logger.info(f"POLICY: Container environment clean for {deployment_id}")
            
        except Exception as e:
            logger.error(f"POLICY ENFORCEMENT ERROR: {e}")
            # Don't fail the entire process, just log the error
            logger.warning(f"POLICY: Continuing with container creation despite cleanup errors")

    async def _ensure_container_running(self, deployment_id: str) -> bool:
        """
        确保容器正在运行，如果不运行则尝试重启。

        Args:
            deployment_id: 容器部署ID

        Returns:
            bool: 容器是否运行成功
        """
        try:
            if deployment_id not in self.containers:
                logger.error(f"Container info not found for deployment: {deployment_id}")
                return False

            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # 检查容器状态
            check_cmd = f"docker inspect --format='{{{{.State.Running}}}}' {container_id}"
            result = await asyncio.create_subprocess_shell(
                check_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await result.communicate()

            if result.returncode == 0 and stdout.decode().strip() == "true":
                logger.debug(f"Container {container_id} is running")
                return True

            logger.warning(f"Container {container_id} is not running, attempting to restart...")

            # 尝试重启容器
            return await self._restart_container(deployment_id)

        except Exception as e:
            logger.error(f"Error checking container status: {e}")
            return False

    async def _restart_container(self, deployment_id: str) -> bool:
        """
        重启已停止的容器。

        Args:
            deployment_id: 容器部署ID

        Returns:
            bool: 重启是否成功
        """
        try:
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id
            original_command = container_info.original_command

            logger.info(f"Restarting container {container_id} using original command")

            # 停止并删除现有容器（如果存在）
            stop_cmd = f"docker stop {container_id} 2>/dev/null || true"
            await asyncio.create_subprocess_shell(
                stop_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            rm_cmd = f"docker rm {container_id} 2>/dev/null || true"
            await asyncio.create_subprocess_shell(
                rm_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            # 使用原始命令重新创建容器，但添加 sleep infinity 确保持续运行
            restart_command = original_command

            # 检查是否需要添加 keep-alive 命令
            if not any(cmd in restart_command for cmd in ['sleep', 'tail', '/dev/null', 'bash', 'sh']):
                # 如果原始命令没有保持运行的机制，添加 sleep infinity
                restart_command += " sleep infinity"
                logger.info("Added 'sleep infinity' to ensure container stays running")

            logger.info(f"Restart command: {restart_command}")

            # 重新运行容器
            result = await asyncio.create_subprocess_shell(
                restart_command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()
            )
            stdout, stderr = await result.communicate()

            if result.returncode != 0:
                logger.error(f"Container restart failed: {stderr.decode()}")
                return False

            # 获取新的容器ID
            new_container_id = stdout.decode().strip()
            if not new_container_id:
                # 如果没有返回容器ID，尝试从docker ps获取
                ps_result = await asyncio.create_subprocess_shell(
                    "docker ps -l -q",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                ps_stdout, _ = await ps_result.communicate()
                new_container_id = ps_stdout.decode().strip()

            if new_container_id:
                # 更新容器信息
                container_info.container_id = new_container_id
                container_info.created_at = time.time()
                logger.info(f"Container restarted successfully: {deployment_id} -> {new_container_id}")
                return True
            else:
                logger.error("Failed to get new container ID after restart")
                return False

        except Exception as e:
            logger.error(f"Container restart failed: {e}")
            return False
    
    async def stop_container(self, deployment_id: str) -> bool:
        """
        停止并删除容器。
        如果容器有--rm标志，则容器停止时会自动清理，无需手动删除。
        
        Args:
            deployment_id: 容器部署ID
            
        Returns:
            bool: 是否成功
        """
        try:
            if deployment_id not in self.containers:
                logger.warning(f"Container not found: {deployment_id}")
                return False
            
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id
            has_rm_flag = container_info.has_rm_flag
            
            if has_rm_flag:
                logger.info(f"Container has --rm flag, will auto-cleanup on stop: {deployment_id}")
                # 只需停止容器，--rm会自动删除
                stop_cmd = f"docker stop {container_id}"
                result = await asyncio.create_subprocess_shell(
                    stop_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                logger.info(f"Stopped container (auto-cleanup): {deployment_id} ({container_id})")
            else:
                logger.info(f"Container has no --rm flag, manual cleanup required: {deployment_id}")
                # 停止容器
                stop_cmd = f"docker stop {container_id}"
                result = await asyncio.create_subprocess_shell(
                    stop_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                
                # 手动删除容器
                rm_cmd = f"docker rm {container_id}"
                result = await asyncio.create_subprocess_shell(
                    rm_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                logger.info(f"Stopped and manually removed container: {deployment_id} ({container_id})")
            
            # 从记录中删除
            del self.containers[deployment_id]
            return True
            
        except Exception as e:
            logger.error(f"Failed to stop container {deployment_id}: {e}")
            return False
    
    def get_container_info(self, deployment_id: str) -> Optional[Dict[str, Any]]:
        """获取容器信息。"""
        if deployment_id not in self.containers:
            return None
        
        info = self.containers[deployment_id]
        return {
            "deployment_id": info.deployment_id,
            "container_id": info.container_id,
            "image": info.image,
            "created_at": info.created_at,
            "original_command": info.original_command,
            "has_rm_flag": info.has_rm_flag
        }
    
    def list_containers(self) -> List[Dict[str, Any]]:
        """列出所有容器。"""
        return [
            self.get_container_info(deployment_id)
            for deployment_id in self.containers.keys()
        ]
    
    async def execute_raw_command(self, command: str) -> ExecutionResult:
        """
        直接在主机上执行命令（非容器内）。
        
        Args:
            command: 要执行的命令
            
        Returns:
            ExecutionResult: 执行结果
        """
        start_time = time.time()
        
        try:
            logger.info(f"Executing raw command: {command}")
            
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()
            
            execution_time = time.time() - start_time
            success = process.returncode == 0
            
            return ExecutionResult(
                command=command,
                success=success,
                stdout=stdout.decode('utf-8', errors='replace'),
                stderr=stderr.decode('utf-8', errors='replace'),
                return_code=process.returncode or 0,
                execution_time=execution_time
            )
            
        except Exception as e:
            logger.error(f"Raw command execution failed: {e}")
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=str(e),
                return_code=-1,
                execution_time=time.time() - start_time
            )


# 全局实例
_docker_runner = DirectDockerRunner()


# 简化的API函数
async def run_docker_command(docker_command: str) -> str:
    """
    直接运行Docker命令。
    
    Args:
        docker_command: 完整的docker run命令
        
    Returns:
        str: 部署ID
    """
    return await _docker_runner.run_docker_command_directly(docker_command)


async def execute_command_in_container(
    command: str,
    deployment_id: str,
    timeout: Optional[float] = None,
    live_output: bool = True
) -> ExecutionResult:
    """
    在容器中执行命令。
    
    Args:
        command: 要执行的命令
        deployment_id: 容器部署ID
        timeout: 超时时间
        
    Returns:
        ExecutionResult: 执行结果
    """
    return await _docker_runner.execute_in_container(command, deployment_id, timeout, live_output)


async def stop_docker_container(deployment_id: str) -> bool:
    """
    停止Docker容器。
    
    Args:
        deployment_id: 容器部署ID
        
    Returns:
        bool: 是否成功
    """
    return await _docker_runner.stop_container(deployment_id)


def get_container_status(deployment_id: str) -> Optional[Dict[str, Any]]:
    """
    获取容器状态。
    
    Args:
        deployment_id: 容器部署ID
        
    Returns:
        容器信息字典或None
    """
    return _docker_runner.get_container_info(deployment_id)


def list_running_containers() -> List[Dict[str, Any]]:
    """
    列出所有运行中的容器。
    
    Returns:
        容器信息列表
    """
    return _docker_runner.list_containers()


async def execute_raw_command(command: str) -> ExecutionResult:
    """
    在主机上直接执行命令。
    
    Args:
        command: 要执行的命令
        
    Returns:
        ExecutionResult: 执行结果
    """
    return await _docker_runner.execute_raw_command(command)


# 为了向后兼容，保留一些旧的函数名
async def create_docker_container(
    image: str = "python:3.12",
    deployment_id: Optional[str] = None
) -> str:
    """
    创建简单的Docker容器（向后兼容）。
    POLICY: Always creates NEW containers, never reuses existing ones.
    """
    import datetime
    if not deployment_id:
        timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
        unique_suffix = uuid.uuid4().hex[:8]  # Ensure uniqueness
        deployment_id = f"simple_{timestamp}_{unique_suffix}"
    else:
        # Even if deployment_id is provided, make it unique to prevent reuse
        unique_suffix = uuid.uuid4().hex[:8]
        deployment_id = f"{deployment_id}_{unique_suffix}"
        logger.warning(f"POLICY: Modified provided deployment_id to ensure uniqueness: {deployment_id}")
    
    # POLICY ENFORCEMENT: Ensure no existing containers
    await _docker_runner._ensure_no_existing_containers(deployment_id)
    
    docker_command = f"docker run -d --name {deployment_id} {image} tail -f /dev/null"
    logger.info(f"POLICY: Creating NEW container with unique ID: {deployment_id}")
    return await run_docker_command(docker_command)


async def execute_container_command(
    command: Union[str, List[str]],
    deployment_id: str,
    timeout: Optional[float] = None,
    shell: bool = True,
    live_output: bool = True
) -> ExecutionResult:
    """在容器中执行命令（向后兼容）。"""
    if isinstance(command, list):
        command = " ".join(shlex.quote(str(c)) for c in command)
    return await execute_command_in_container(command, deployment_id, timeout, live_output)


async def stop_container(deployment_id: str) -> bool:
    """停止容器（向后兼容）。"""
    return await stop_docker_container(deployment_id)


def list_containers() -> List[Dict[str, Any]]:
    """列出容器（向后兼容）。"""
    return list_running_containers()


# 其他向后兼容的函数
async def create_docker_container_with_config(config: Dict[str, Any]) -> str:
    """使用配置创建容器（简化版）。"""
    image = config.get("image", "python:3.12")
    return await create_docker_container(image)


async def create_development_container(base_image: str = "python:3.12") -> str:
    """
    创建开发容器（简化版）。
    POLICY: Always creates NEW containers, never reuses existing ones.
    """
    logger.info(f"POLICY: Creating NEW development container with image: {base_image}")
    return await create_docker_container(base_image)


async def create_container_session(deployment_id: str, session_name: str = "default") -> str:
    """创建容器会话（简化版）。"""
    # 简化版本，直接返回session名称
    return session_name


async def execute_in_container_session(
    command: str,
    session_name: str,
    deployment_id: str,
    timeout: Optional[float] = None
) -> ExecutionResult:
    """在容器会话中执行命令（简化版）。"""
    return await execute_command_in_container(command, deployment_id, timeout)