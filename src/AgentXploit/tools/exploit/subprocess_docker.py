"""
Subprocess-based Docker and Command Execution Tool

ç›´æ¥è¿è¡ŒDockerå‘½ä»¤å’Œå®¹å™¨å†…å‘½ä»¤ï¼Œæ— å¤æ‚è§£æã€‚

=== CONTAINER REUSE POLICY ===
CRITICAL POLICY: All container creation functions now PROHIBIT reusing existing containers.
Every call to create_docker_container() or create_development_container() will:
1. Generate unique deployment IDs to prevent conflicts
2. Force cleanup any existing containers with similar names
3. Create completely fresh containers from scratch
4. Never reuse or reconnect to existing containers

This ensures clean, reproducible environments for all workflows.
"""

import asyncio
import logging
import subprocess
import uuid
import time
import shlex
import os
from dataclasses import dataclass
from typing import Dict, List, Optional, Any, Union
from pathlib import Path

logger = logging.getLogger(__name__)


@dataclass
class ExecutionResult:
    """Result of command execution."""
    command: str
    success: bool
    stdout: str
    stderr: str
    return_code: int
    execution_time: float
    session_id: Optional[str] = None


@dataclass
class ContainerInfo:
    """Information about a running Docker container."""
    deployment_id: str
    container_id: str
    image: str
    created_at: float
    original_command: str  # åŸå§‹Dockerå‘½ä»¤
    has_rm_flag: bool  # æ˜¯å¦åŒ…å«--rmæ ‡å¿—


class DirectDockerRunner:
    """
    ç›´æ¥è¿è¡ŒDockerå‘½ä»¤çš„æ‰§è¡Œå™¨ã€‚
    
    æ ¸å¿ƒç†å¿µï¼š
    1. ç”¨æˆ·è¾“å…¥ä»€ä¹ˆå‘½ä»¤å°±è¿è¡Œä»€ä¹ˆå‘½ä»¤
    2. ä»READMEè§£æåˆ°ä»€ä¹ˆå‘½ä»¤å°±è¿è¡Œä»€ä¹ˆå‘½ä»¤
    3. ä¸è¿›è¡Œå¤æ‚çš„å‚æ•°è§£æå’Œé‡ç»„
    """
    
    def __init__(self):
        self.containers: Dict[str, ContainerInfo] = {}
        logger.info("Initialized direct Docker runner")
    
    async def run_docker_command_directly(self, docker_command: str) -> str:
        """
        ç›´æ¥è¿è¡Œå®Œæ•´çš„Dockerå‘½ä»¤ï¼Œæ­£ç¡®å¤„ç†ç¯å¢ƒå˜é‡å±•å¼€ã€‚
        
        Args:
            docker_command: å®Œæ•´çš„docker runå‘½ä»¤ï¼ˆç”¨æˆ·è¾“å…¥æˆ–READMEä¸­çš„ï¼‰
            
        Returns:
            deployment_id: ç”Ÿæˆçš„éƒ¨ç½²IDç”¨äºåç»­æ“ä½œ
        """
        try:
            # === POLICY ENFORCEMENT: PROHIBIT CONTAINER REUSE ===
            # Generate unique deployment ID to ensure new container creation
            import datetime
            timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
            unique_suffix = uuid.uuid4().hex[:8]  # Add unique suffix to prevent conflicts
            deployment_id = f"direct_{timestamp}_{unique_suffix}"
            
            # CRITICAL: Check if any container with similar name exists and force cleanup
            await self._ensure_no_existing_containers(deployment_id)
            
            # é¢„å¤„ç†å‘½ä»¤ï¼šå±•å¼€ç¯å¢ƒå˜é‡
            processed_command = docker_command
            
            # å¤„ç†$UIDå˜é‡
            if '$UID' in processed_command:
                uid = os.getuid()
                processed_command = processed_command.replace('$UID', str(uid))
                logger.info(f"Expanded $UID to {uid}")
            
            # å¤„ç†å…¶ä»–å¸¸è§çš„ç¯å¢ƒå˜é‡
            import re
            env_vars = re.findall(r'\$([A-Z_][A-Z0-9_]*)', processed_command)
            for var in env_vars:
                if var in os.environ:
                    processed_command = processed_command.replace(f'${var}', os.environ[var])
                    logger.info(f"Expanded ${var} to {os.environ[var]}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰--rmæ ‡å¿—ï¼ˆç”¨äºåç»­æ¸…ç†åˆ¤æ–­ï¼‰
            has_rm_flag = '--rm' in processed_command
            
            # ä¿æŒåŸå§‹çš„-itå’Œ--rmå‚æ•°ä¸å˜
            logger.info(f"Preserving original flags: -it and --rm as specified in command")
            logger.info(f"Container will auto-cleanup: {has_rm_flag}")
            
            logger.info(f"Original command: {docker_command}")
            logger.info(f"Processed command: {processed_command}")
            
            # æ£€æŸ¥å‘½ä»¤æ˜¯å¦åŒ…å«docker run
            if 'docker run' not in processed_command:
                raise ValueError("Command must contain 'docker run'")

            
            # ä½¿ç”¨shellæ‰§è¡Œå®Œæ•´å‘½ä»¤ï¼Œç¡®ä¿ç¯å¢ƒå˜é‡æ­£ç¡®å±•å¼€
            result = await asyncio.create_subprocess_shell(
                processed_command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()  # ä¼ é€’å®Œæ•´çš„ç¯å¢ƒå˜é‡
            )
            stdout, stderr = await result.communicate()
            
            if result.returncode != 0:
                error_msg = f"Docker command failed: {stderr.decode()}"
                logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # è·å–å®¹å™¨ID
            container_id = stdout.decode().strip()
            if not container_id:
                # å¦‚æœæ²¡æœ‰è¿”å›å®¹å™¨IDï¼Œå°è¯•ä»docker psè·å–æœ€æ–°çš„å®¹å™¨
                ps_result = await asyncio.create_subprocess_shell(
                    "docker ps -l -q",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                ps_stdout, _ = await ps_result.communicate()
                container_id = ps_stdout.decode().strip()
            
            # å°è¯•ä»å‘½ä»¤ä¸­æå–é•œåƒå
            image = "unknown"
            try:
                # ç®€å•æå–æœ€åä¸€ä¸ªçœ‹èµ·æ¥åƒé•œåƒåçš„éƒ¨åˆ†
                parts = processed_command.split()
                for part in reversed(parts):
                    if ':' in part and not part.startswith('-') and '/' in part:
                        image = part
                        break
                    elif not part.startswith('-') and not '=' in part and len(part) > 3:
                        # å¯èƒ½æ˜¯ç®€å•çš„é•œåƒå
                        if part not in ['bash', 'sh', 'tail', '/dev/null']:
                            image = part
            except:
                pass
            
            # å­˜å‚¨å®¹å™¨ä¿¡æ¯
            container_info = ContainerInfo(
                deployment_id=deployment_id,
                container_id=container_id,
                image=image,
                created_at=time.time(),
                original_command=docker_command,
                has_rm_flag=has_rm_flag
            )
            
            self.containers[deployment_id] = container_info
            
            logger.info(f"Docker command executed successfully: {deployment_id} -> {container_id}")
            logger.info(f"Detected image: {image}")
            
            return deployment_id
            
        except Exception as e:
            logger.error(f"Failed to run Docker command directly: {e}")
            raise
    
    async def execute_in_container(
        self,
        command: str,
        deployment_id: str,
        timeout: Optional[float] = None,
        live_output: bool = True
    ) -> ExecutionResult:
        """
        åœ¨æŒ‡å®šå®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤ã€‚

        Args:
            command: è¦æ‰§è¡Œçš„å‘½ä»¤
            deployment_id: å®¹å™¨éƒ¨ç½²ID
            timeout: è¶…æ—¶æ—¶é—´

        Returns:
            ExecutionResult: æ‰§è¡Œç»“æœ
        """
        start_time = time.time()

        try:
            if deployment_id not in self.containers:
                raise ValueError(f"Container not found: {deployment_id}")

            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # Check container health and restart if needed
            await self._ensure_container_running(deployment_id)

            # Update container_id after potential restart
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # æ„å»ºdocker execå‘½ä»¤
            docker_exec_cmd = f"docker exec {container_id} bash -c {shlex.quote(command)}"

            logger.info(f"Executing in container {container_id}: {command}")

            # æ‰§è¡Œå‘½ä»¤
            process = await asyncio.create_subprocess_shell(
                docker_exec_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            if timeout:
                try:
                    # å®æ—¶è¾“å‡ºæµç›‘æ§
                    stdout_data, stderr_data = await asyncio.wait_for(
                        self._stream_output(process, command, live_output), timeout=timeout
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"Command timed out after {timeout} seconds: {command}")
                    process.terminate()
                    try:
                        await asyncio.wait_for(process.wait(), timeout=10)
                    except asyncio.TimeoutError:
                        process.kill()
                        await process.wait()
                    raise
            else:
                # å¯¹äºæ— è¶…æ—¶çš„æƒ…å†µï¼Œä¹Ÿä½¿ç”¨æµå¼è¾“å‡º
                stdout_data, stderr_data = await self._stream_output(process, command, live_output)

            execution_time = time.time() - start_time
            success = process.returncode == 0

            stdout_str = stdout_data
            stderr_str = stderr_data

            # ç«‹å³æ£€æµ‹å¸¸è§çš„å¤±è´¥æ¨¡å¼
            if not success:
                logger.error(f"Command failed with return code {process.returncode}: {command}")
                if stderr_str:
                    logger.error(f"Error output: {stderr_str}")

                # æ£€æµ‹å¸¸è§çš„é”™è¯¯æ¨¡å¼
                if "No such file or directory" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: File or directory not found")
                elif "Permission denied" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Permission denied")
                elif "Command not found" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Command not found")
                elif "ModuleNotFoundError" in stderr_str or "ImportError" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Python module/import error")
                elif "SyntaxError" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Python syntax error")
                elif "docker: Error" in stderr_str:
                    logger.error("IMMEDIATE_FAILURE: Docker error")

            # å³ä½¿æˆåŠŸä¹Ÿæ£€æŸ¥stderrä¸­çš„è­¦å‘Š
            elif stderr_str and ("error" in stderr_str.lower() or "warning" in stderr_str.lower()):
                logger.warning(f"Command succeeded but has warnings/errors in stderr: {stderr_str}")

            return ExecutionResult(
                command=command,
                success=success,
                stdout=stdout_str,
                stderr=stderr_str,
                return_code=process.returncode or 0,
                execution_time=execution_time
            )
            
        except asyncio.TimeoutError:
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=f"Command timed out after {timeout} seconds",
                return_code=-1,
                execution_time=time.time() - start_time
            )
        except Exception as e:
            logger.error(f"Command execution failed: {e}")
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=str(e),
                return_code=-1,
                execution_time=time.time() - start_time
            )

    async def _stream_output(self, process, command: str, live_output: bool = True):
        """å®æ—¶æµå¼è¯»å–å¹¶æ˜¾ç¤ºè¿›ç¨‹è¾“å‡º"""
        stdout_data = []
        stderr_data = []

        async def read_stdout():
            """è¯»å–stdoutæµ"""
            while True:
                try:
                    line = await process.stdout.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='replace')
                    stdout_data.append(line_str)
                    # å®æ—¶æ˜¾ç¤ºè¾“å‡ºï¼ˆç§»é™¤æœ«å°¾æ¢è¡Œç¬¦é¿å…åŒæ¢è¡Œï¼‰
                    if live_output:
                        print(f"[STDOUT] {line_str.rstrip()}", flush=True)
                except Exception as e:
                    logger.debug(f"Error reading stdout: {e}")
                    break

        async def read_stderr():
            """è¯»å–stderræµå¹¶æ£€æµ‹é€€å‡ºä¿¡å·"""
            while True:
                try:
                    line = await process.stderr.readline()
                    if not line:
                        break
                    line_str = line.decode('utf-8', errors='replace')
                    stderr_data.append(line_str)

                    # å®æ—¶æ˜¾ç¤ºé”™è¯¯è¾“å‡º
                    if live_output:
                        print(f"[STDERR] {line_str.rstrip()}", flush=True)

                    # æ£€æµ‹ OpenHands é€€å‡ºä¿¡å·
                    line_lower = line_str.lower()
                    if ("connection refused" in line_lower or
                        "connecterror" in line_lower or
                        "errno 111" in line_lower or
                        ("session was interrupted" in line_lower and "openhands" in line_lower) or
                        ("sys.exit" in line_lower) or
                        ("system exit" in line_lower)):

                        if live_output:
                            print(f"\nğŸš¨ [EARLY_TERMINATION] Detected OpenHands exit signal in stderr!", flush=True)
                            print(f"ğŸš¨ [EARLY_TERMINATION] Terminating process early to avoid timeout wait!", flush=True)

                        logger.warning(f"Early termination detected: {line_str.strip()}")

                        # ç«‹å³ç»ˆæ­¢è¿›ç¨‹
                        try:
                            process.terminate()
                            # ç»™è¿›ç¨‹2ç§’æ—¶é—´ä¼˜é›…é€€å‡º
                            await asyncio.wait_for(process.wait(), timeout=2.0)
                        except asyncio.TimeoutError:
                            # å¦‚æœä¼˜é›…é€€å‡ºå¤±è´¥ï¼Œå¼ºåˆ¶æ€æ­»
                            process.kill()
                            await process.wait()

                        if live_output:
                            print(f"âœ… [EARLY_TERMINATION] Process terminated successfully!", flush=True)
                        break

                except Exception as e:
                    logger.debug(f"Error reading stderr: {e}")
                    break

        async def monitor_progress():
            """ç›‘æ§æ‰§è¡Œè¿›åº¦"""
            start_time = time.time()
            while process.returncode is None:
                try:
                    await asyncio.sleep(30)  # æ¯30ç§’æŠ¥å‘Šä¸€æ¬¡è¿›åº¦

                    # å¦‚æœè¿›ç¨‹å·²ç»ç»ˆæ­¢ï¼Œåœæ­¢ç›‘æ§
                    if process.returncode is not None:
                        if live_output:
                            print(f"\n[PROGRESS] Process terminated, stopping progress monitoring.\n", flush=True)
                        break

                    current_time = time.time()
                    elapsed = current_time - start_time
                    logger.info(f"Progress: Command still running after {elapsed:.1f}s")
                    if live_output:
                        print(f"\n[PROGRESS] Command running for {elapsed:.1f}s...\n", flush=True)
                except asyncio.CancelledError:
                    if live_output:
                        print(f"\n[PROGRESS] Progress monitoring cancelled.\n", flush=True)
                    break
                except Exception as e:
                    logger.debug(f"Progress monitoring error: {e}")
                    break

        # å¯åŠ¨æ‰€æœ‰ä»»åŠ¡
        tasks = [
            asyncio.create_task(read_stdout()),
            asyncio.create_task(read_stderr()),
            asyncio.create_task(monitor_progress())
        ]

        try:
            # ç­‰å¾…è¿›ç¨‹å®Œæˆ
            await process.wait()
        finally:
            # å–æ¶ˆæ‰€æœ‰ä»»åŠ¡
            for task in tasks:
                if not task.done():
                    task.cancel()

            # ç­‰å¾…ä»»åŠ¡å®Œæˆæˆ–è¢«å–æ¶ˆ
            await asyncio.gather(*tasks, return_exceptions=True)

        # è¿”å›ç´¯ç§¯çš„è¾“å‡º
        return ''.join(stdout_data), ''.join(stderr_data)

    async def _ensure_no_existing_containers(self, deployment_id: str) -> None:
        """
        POLICY ENFORCEMENT: Ensure no existing containers can be reused.
        Force cleanup of any containers that might conflict with new deployment.
        
        Args:
            deployment_id: Proposed deployment ID for new container
        """
        try:
            logger.info(f"POLICY: Ensuring no existing containers for {deployment_id}")
            
            # Check if deployment_id already exists in our registry
            if deployment_id in self.containers:
                logger.warning(f"POLICY VIOLATION: deployment_id {deployment_id} already exists in registry")
                old_container_info = self.containers[deployment_id]
                
                # Force stop and remove the old container
                logger.warning(f"FORCE CLEANUP: Removing old container {old_container_info.container_id}")
                try:
                    # Stop container
                    stop_cmd = f"docker stop {old_container_info.container_id}"
                    stop_result = await asyncio.create_subprocess_shell(
                        stop_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    await stop_result.communicate()
                    
                    # Remove container
                    rm_cmd = f"docker rm {old_container_info.container_id}"
                    rm_result = await asyncio.create_subprocess_shell(
                        rm_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    await rm_result.communicate()
                    
                    logger.info(f"FORCE CLEANUP: Successfully removed old container")
                except Exception as cleanup_e:
                    logger.warning(f"FORCE CLEANUP: Failed to remove old container: {cleanup_e}")
                
                # Remove from registry
                del self.containers[deployment_id]
                logger.info(f"POLICY: Removed {deployment_id} from container registry")
            
            # Check for any containers with similar names and force cleanup
            try:
                # Search for containers with similar deployment_id pattern
                base_name = deployment_id.split('_')[0] if '_' in deployment_id else deployment_id
                
                # Special handling for gpt-researcher containers
                search_patterns = [base_name]
                if 'gpt-researcher' in deployment_id or 'gpt-researcher' in base_name:
                    search_patterns.extend(['gpt-researcher', 'gptresearcher'])
                
                existing_containers = []
                for pattern in search_patterns:
                    search_cmd = f"docker ps -a --filter name={pattern} --format '{{{{.Names}}}}'"
                    
                    search_result = await asyncio.create_subprocess_shell(
                        search_cmd,
                        stdout=asyncio.subprocess.PIPE,
                        stderr=asyncio.subprocess.PIPE
                    )
                    stdout, stderr = await search_result.communicate()
                    
                    if search_result.returncode == 0 and stdout.strip():
                        pattern_containers = stdout.decode().strip().split('\n')
                        pattern_containers = [c.strip() for c in pattern_containers if c.strip()]
                        existing_containers.extend(pattern_containers)
                
                # Remove duplicates
                existing_containers = list(set(existing_containers))
                
                if existing_containers:
                    logger.warning(f"POLICY: Found {len(existing_containers)} existing containers to cleanup: {existing_containers}")
                    for container_name in existing_containers:
                        logger.warning(f"FORCE CLEANUP: Removing container {container_name}")
                        try:
                            # Force stop and remove
                            cleanup_cmd = f"docker stop {container_name} && docker rm {container_name}"
                            cleanup_result = await asyncio.create_subprocess_shell(
                                cleanup_cmd,
                                stdout=asyncio.subprocess.PIPE,
                                stderr=asyncio.subprocess.PIPE
                            )
                            await cleanup_result.communicate()
                            logger.info(f"FORCE CLEANUP: Removed container {container_name}")
                        except Exception as e:
                            logger.warning(f"FORCE CLEANUP: Failed to remove {container_name}: {e}")
                
            except Exception as search_e:
                logger.debug(f"POLICY: Container search failed (acceptable): {search_e}")
            
            logger.info(f"POLICY: Container environment clean for {deployment_id}")
            
        except Exception as e:
            logger.error(f"POLICY ENFORCEMENT ERROR: {e}")
            # Don't fail the entire process, just log the error
            logger.warning(f"POLICY: Continuing with container creation despite cleanup errors")

    async def _ensure_container_running(self, deployment_id: str) -> bool:
        """
        ç¡®ä¿å®¹å™¨æ­£åœ¨è¿è¡Œï¼Œå¦‚æœä¸è¿è¡Œåˆ™å°è¯•é‡å¯ã€‚

        Args:
            deployment_id: å®¹å™¨éƒ¨ç½²ID

        Returns:
            bool: å®¹å™¨æ˜¯å¦è¿è¡ŒæˆåŠŸ
        """
        try:
            if deployment_id not in self.containers:
                logger.error(f"Container info not found for deployment: {deployment_id}")
                return False

            container_info = self.containers[deployment_id]
            container_id = container_info.container_id

            # æ£€æŸ¥å®¹å™¨çŠ¶æ€
            check_cmd = f"docker inspect --format='{{{{.State.Running}}}}' {container_id}"
            result = await asyncio.create_subprocess_shell(
                check_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await result.communicate()

            if result.returncode == 0 and stdout.decode().strip() == "true":
                logger.debug(f"Container {container_id} is running")
                return True

            logger.warning(f"Container {container_id} is not running, attempting to restart...")

            # å°è¯•é‡å¯å®¹å™¨
            return await self._restart_container(deployment_id)

        except Exception as e:
            logger.error(f"Error checking container status: {e}")
            return False

    async def _restart_container(self, deployment_id: str) -> bool:
        """
        é‡å¯å·²åœæ­¢çš„å®¹å™¨ã€‚

        Args:
            deployment_id: å®¹å™¨éƒ¨ç½²ID

        Returns:
            bool: é‡å¯æ˜¯å¦æˆåŠŸ
        """
        try:
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id
            original_command = container_info.original_command

            logger.info(f"Restarting container {container_id} using original command")

            # åœæ­¢å¹¶åˆ é™¤ç°æœ‰å®¹å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            stop_cmd = f"docker stop {container_id} 2>/dev/null || true"
            await asyncio.create_subprocess_shell(
                stop_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            rm_cmd = f"docker rm {container_id} 2>/dev/null || true"
            await asyncio.create_subprocess_shell(
                rm_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )

            # ä½¿ç”¨åŸå§‹å‘½ä»¤é‡æ–°åˆ›å»ºå®¹å™¨ï¼Œä½†æ·»åŠ  sleep infinity ç¡®ä¿æŒç»­è¿è¡Œ
            restart_command = original_command

            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ·»åŠ  keep-alive å‘½ä»¤
            if not any(cmd in restart_command for cmd in ['sleep', 'tail', '/dev/null', 'bash', 'sh']):
                # å¦‚æœåŸå§‹å‘½ä»¤æ²¡æœ‰ä¿æŒè¿è¡Œçš„æœºåˆ¶ï¼Œæ·»åŠ  sleep infinity
                restart_command += " sleep infinity"
                logger.info("Added 'sleep infinity' to ensure container stays running")

            logger.info(f"Restart command: {restart_command}")

            # é‡æ–°è¿è¡Œå®¹å™¨
            result = await asyncio.create_subprocess_shell(
                restart_command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE,
                env=os.environ.copy()
            )
            stdout, stderr = await result.communicate()

            if result.returncode != 0:
                logger.error(f"Container restart failed: {stderr.decode()}")
                return False

            # è·å–æ–°çš„å®¹å™¨ID
            new_container_id = stdout.decode().strip()
            if not new_container_id:
                # å¦‚æœæ²¡æœ‰è¿”å›å®¹å™¨IDï¼Œå°è¯•ä»docker psè·å–
                ps_result = await asyncio.create_subprocess_shell(
                    "docker ps -l -q",
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                ps_stdout, _ = await ps_result.communicate()
                new_container_id = ps_stdout.decode().strip()

            if new_container_id:
                # æ›´æ–°å®¹å™¨ä¿¡æ¯
                container_info.container_id = new_container_id
                container_info.created_at = time.time()
                logger.info(f"Container restarted successfully: {deployment_id} -> {new_container_id}")
                return True
            else:
                logger.error("Failed to get new container ID after restart")
                return False

        except Exception as e:
            logger.error(f"Container restart failed: {e}")
            return False
    
    async def stop_container(self, deployment_id: str) -> bool:
        """
        åœæ­¢å¹¶åˆ é™¤å®¹å™¨ã€‚
        å¦‚æœå®¹å™¨æœ‰--rmæ ‡å¿—ï¼Œåˆ™å®¹å™¨åœæ­¢æ—¶ä¼šè‡ªåŠ¨æ¸…ç†ï¼Œæ— éœ€æ‰‹åŠ¨åˆ é™¤ã€‚
        
        Args:
            deployment_id: å®¹å™¨éƒ¨ç½²ID
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸ
        """
        try:
            if deployment_id not in self.containers:
                logger.warning(f"Container not found: {deployment_id}")
                return False
            
            container_info = self.containers[deployment_id]
            container_id = container_info.container_id
            has_rm_flag = container_info.has_rm_flag
            
            if has_rm_flag:
                logger.info(f"Container has --rm flag, will auto-cleanup on stop: {deployment_id}")
                # åªéœ€åœæ­¢å®¹å™¨ï¼Œ--rmä¼šè‡ªåŠ¨åˆ é™¤
                stop_cmd = f"docker stop {container_id}"
                result = await asyncio.create_subprocess_shell(
                    stop_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                logger.info(f"Stopped container (auto-cleanup): {deployment_id} ({container_id})")
            else:
                logger.info(f"Container has no --rm flag, manual cleanup required: {deployment_id}")
                # åœæ­¢å®¹å™¨
                stop_cmd = f"docker stop {container_id}"
                result = await asyncio.create_subprocess_shell(
                    stop_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                
                # æ‰‹åŠ¨åˆ é™¤å®¹å™¨
                rm_cmd = f"docker rm {container_id}"
                result = await asyncio.create_subprocess_shell(
                    rm_cmd,
                    stdout=asyncio.subprocess.PIPE,
                    stderr=asyncio.subprocess.PIPE
                )
                await result.communicate()
                logger.info(f"Stopped and manually removed container: {deployment_id} ({container_id})")
            
            # ä»è®°å½•ä¸­åˆ é™¤
            del self.containers[deployment_id]
            return True
            
        except Exception as e:
            logger.error(f"Failed to stop container {deployment_id}: {e}")
            return False
    
    def get_container_info(self, deployment_id: str) -> Optional[Dict[str, Any]]:
        """è·å–å®¹å™¨ä¿¡æ¯ã€‚"""
        if deployment_id not in self.containers:
            return None
        
        info = self.containers[deployment_id]
        return {
            "deployment_id": info.deployment_id,
            "container_id": info.container_id,
            "image": info.image,
            "created_at": info.created_at,
            "original_command": info.original_command,
            "has_rm_flag": info.has_rm_flag
        }
    
    def list_containers(self) -> List[Dict[str, Any]]:
        """åˆ—å‡ºæ‰€æœ‰å®¹å™¨ã€‚"""
        return [
            self.get_container_info(deployment_id)
            for deployment_id in self.containers.keys()
        ]
    
    async def execute_raw_command(self, command: str) -> ExecutionResult:
        """
        ç›´æ¥åœ¨ä¸»æœºä¸Šæ‰§è¡Œå‘½ä»¤ï¼ˆéå®¹å™¨å†…ï¼‰ã€‚
        
        Args:
            command: è¦æ‰§è¡Œçš„å‘½ä»¤
            
        Returns:
            ExecutionResult: æ‰§è¡Œç»“æœ
        """
        start_time = time.time()
        
        try:
            logger.info(f"Executing raw command: {command}")
            
            process = await asyncio.create_subprocess_shell(
                command,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await process.communicate()
            
            execution_time = time.time() - start_time
            success = process.returncode == 0
            
            return ExecutionResult(
                command=command,
                success=success,
                stdout=stdout.decode('utf-8', errors='replace'),
                stderr=stderr.decode('utf-8', errors='replace'),
                return_code=process.returncode or 0,
                execution_time=execution_time
            )
            
        except Exception as e:
            logger.error(f"Raw command execution failed: {e}")
            return ExecutionResult(
                command=command,
                success=False,
                stdout="",
                stderr=str(e),
                return_code=-1,
                execution_time=time.time() - start_time
            )


# å…¨å±€å®ä¾‹
_docker_runner = DirectDockerRunner()


# ç®€åŒ–çš„APIå‡½æ•°
async def run_docker_command(docker_command: str) -> str:
    """
    ç›´æ¥è¿è¡ŒDockerå‘½ä»¤ã€‚
    
    Args:
        docker_command: å®Œæ•´çš„docker runå‘½ä»¤
        
    Returns:
        str: éƒ¨ç½²ID
    """
    return await _docker_runner.run_docker_command_directly(docker_command)


async def execute_command_in_container(
    command: str,
    deployment_id: str,
    timeout: Optional[float] = None,
    live_output: bool = True
) -> ExecutionResult:
    """
    åœ¨å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤ã€‚
    
    Args:
        command: è¦æ‰§è¡Œçš„å‘½ä»¤
        deployment_id: å®¹å™¨éƒ¨ç½²ID
        timeout: è¶…æ—¶æ—¶é—´
        
    Returns:
        ExecutionResult: æ‰§è¡Œç»“æœ
    """
    return await _docker_runner.execute_in_container(command, deployment_id, timeout, live_output)


async def stop_docker_container(deployment_id: str) -> bool:
    """
    åœæ­¢Dockerå®¹å™¨ã€‚
    
    Args:
        deployment_id: å®¹å™¨éƒ¨ç½²ID
        
    Returns:
        bool: æ˜¯å¦æˆåŠŸ
    """
    return await _docker_runner.stop_container(deployment_id)


def get_container_status(deployment_id: str) -> Optional[Dict[str, Any]]:
    """
    è·å–å®¹å™¨çŠ¶æ€ã€‚
    
    Args:
        deployment_id: å®¹å™¨éƒ¨ç½²ID
        
    Returns:
        å®¹å™¨ä¿¡æ¯å­—å…¸æˆ–None
    """
    return _docker_runner.get_container_info(deployment_id)


def list_running_containers() -> List[Dict[str, Any]]:
    """
    åˆ—å‡ºæ‰€æœ‰è¿è¡Œä¸­çš„å®¹å™¨ã€‚
    
    Returns:
        å®¹å™¨ä¿¡æ¯åˆ—è¡¨
    """
    return _docker_runner.list_containers()


async def execute_raw_command(command: str) -> ExecutionResult:
    """
    åœ¨ä¸»æœºä¸Šç›´æ¥æ‰§è¡Œå‘½ä»¤ã€‚
    
    Args:
        command: è¦æ‰§è¡Œçš„å‘½ä»¤
        
    Returns:
        ExecutionResult: æ‰§è¡Œç»“æœ
    """
    return await _docker_runner.execute_raw_command(command)


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™ä¸€äº›æ—§çš„å‡½æ•°å
async def create_docker_container(
    image: str = "python:3.12",
    deployment_id: Optional[str] = None
) -> str:
    """
    åˆ›å»ºç®€å•çš„Dockerå®¹å™¨ï¼ˆå‘åå…¼å®¹ï¼‰ã€‚
    POLICY: Always creates NEW containers, never reuses existing ones.
    """
    import datetime
    if not deployment_id:
        timestamp = datetime.datetime.now().strftime("%m%d_%H%M%S")
        unique_suffix = uuid.uuid4().hex[:8]  # Ensure uniqueness
        deployment_id = f"simple_{timestamp}_{unique_suffix}"
    else:
        # Even if deployment_id is provided, make it unique to prevent reuse
        unique_suffix = uuid.uuid4().hex[:8]
        deployment_id = f"{deployment_id}_{unique_suffix}"
        logger.warning(f"POLICY: Modified provided deployment_id to ensure uniqueness: {deployment_id}")
    
    # POLICY ENFORCEMENT: Ensure no existing containers
    await _docker_runner._ensure_no_existing_containers(deployment_id)
    
    docker_command = f"docker run -d --name {deployment_id} {image} tail -f /dev/null"
    logger.info(f"POLICY: Creating NEW container with unique ID: {deployment_id}")
    return await run_docker_command(docker_command)


async def execute_container_command(
    command: Union[str, List[str]],
    deployment_id: str,
    timeout: Optional[float] = None,
    shell: bool = True,
    live_output: bool = True
) -> ExecutionResult:
    """åœ¨å®¹å™¨ä¸­æ‰§è¡Œå‘½ä»¤ï¼ˆå‘åå…¼å®¹ï¼‰ã€‚"""
    if isinstance(command, list):
        command = " ".join(shlex.quote(str(c)) for c in command)
    return await execute_command_in_container(command, deployment_id, timeout, live_output)


async def stop_container(deployment_id: str) -> bool:
    """åœæ­¢å®¹å™¨ï¼ˆå‘åå…¼å®¹ï¼‰ã€‚"""
    return await stop_docker_container(deployment_id)


def list_containers() -> List[Dict[str, Any]]:
    """åˆ—å‡ºå®¹å™¨ï¼ˆå‘åå…¼å®¹ï¼‰ã€‚"""
    return list_running_containers()


# å…¶ä»–å‘åå…¼å®¹çš„å‡½æ•°
async def create_docker_container_with_config(config: Dict[str, Any]) -> str:
    """ä½¿ç”¨é…ç½®åˆ›å»ºå®¹å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚"""
    image = config.get("image", "python:3.12")
    return await create_docker_container(image)


async def create_development_container(base_image: str = "python:3.12") -> str:
    """
    åˆ›å»ºå¼€å‘å®¹å™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚
    POLICY: Always creates NEW containers, never reuses existing ones.
    """
    logger.info(f"POLICY: Creating NEW development container with image: {base_image}")
    return await create_docker_container(base_image)


async def create_container_session(deployment_id: str, session_name: str = "default") -> str:
    """åˆ›å»ºå®¹å™¨ä¼šè¯ï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚"""
    # ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›sessionåç§°
    return session_name


async def execute_in_container_session(
    command: str,
    session_name: str,
    deployment_id: str,
    timeout: Optional[float] = None
) -> ExecutionResult:
    """åœ¨å®¹å™¨ä¼šè¯ä¸­æ‰§è¡Œå‘½ä»¤ï¼ˆç®€åŒ–ç‰ˆï¼‰ã€‚"""
    return await execute_command_in_container(command, deployment_id, timeout)