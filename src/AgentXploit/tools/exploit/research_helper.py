"""
GPT-Researcher Helper - Server management and workflow support
Handles server startup, file stability waiting, and document extraction.
"""

import os
import logging
import asyncio
import time
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


async def start_research_server(deployment_id: str) -> bool:
    """
    Start GPT-Researcher server in container.
    Server runs on internal port 8000 (container port).
    
    Args:
        deployment_id: Docker deployment ID
        
    Returns:
        True if server started successfully
    """
    from .docker_manager import execute_container_command
    
    logger.info("Starting Research server on internal port 8000")
    print("Starting Research server: uvicorn main:app --host 0.0.0.0 --port 8000")
    
    start_cmd = "nohup uvicorn main:app --host 0.0.0.0 --port 8000 --workers 1 > server.log 2>&1 &"
    
    result = await execute_container_command(
        command=start_cmd,
        deployment_id=deployment_id,
        workspace="/usr/src/app",
        timeout=10,
        live_output=False,
        raise_on_failure=False
    )
    
    if result.get("success"):
        print("✓ Server start command executed")
        print("Waiting 15 seconds for server startup...")
        await asyncio.sleep(15)
        
        # Verify server is running
        check_cmd = "ps aux | grep uvicorn | grep -v grep || echo 'not_running'"
        check_result = await execute_container_command(
            command=check_cmd,
            deployment_id=deployment_id,
            workspace="/",
            timeout=5,
            live_output=False,
            raise_on_failure=False
        )
        
        if "not_running" in check_result.get("stdout", ""):
            logger.warning("Server process not found")
            print("Warning: Server process not detected")
            return False
        else:
            print("✓ Server confirmed running")
            return True
    else:
        logger.warning(f"Server start failed: {result.get('stderr')}")
        print(f"Warning: Server start failed")
        return False


async def wait_for_research_file_stability(
    deployment_id: str,
    file_path: str,
    timeout: int = 120
) -> bool:
    """
    Wait for research JSON file to become stable (stop changing).
    
    Args:
        deployment_id: Docker deployment ID
        file_path: Path to JSON file in container
        timeout: Maximum wait time in seconds
        
    Returns:
        True if file is stable
    """
    from .docker_manager import execute_container_command
    
    print(f"Waiting for file stability: {file_path}")
    print(f"Initial wait: 60 seconds for file generation...")
    
    start_time = time.time()
    
    # Initial wait of 60 seconds
    await asyncio.sleep(60)
    print("Initial wait completed, starting stability checks...")
    
    previous_size = -1
    stable_count = 0
    required_stable_count = 3  # Must be stable for 3 checks (30 seconds)
    
    while time.time() - start_time < timeout:
        # Check file size
        check_cmd = f"wc -c {file_path} 2>/dev/null | cut -d' ' -f1 || echo '0'"
        
        check_result = await execute_container_command(
            command=check_cmd,
            deployment_id=deployment_id,
            workspace="/",
            timeout=10,
            live_output=False,
            raise_on_failure=False
        )
        
        if check_result.get("success"):
            try:
                current_size = int(check_result.get("stdout", "0").strip())
                
                if current_size == previous_size and current_size > 0:
                    stable_count += 1
                    print(f"File stable for {stable_count}/{required_stable_count} checks (size: {current_size} bytes)")
                    
                    if stable_count >= required_stable_count:
                        print(f"✓ File is stable after {time.time() - start_time:.1f}s")
                        return True
                else:
                    if current_size != previous_size:
                        print(f"File size changed: {previous_size} -> {current_size} bytes")
                    stable_count = 0
                    previous_size = current_size
                    
            except ValueError:
                print(f"Warning: Could not parse file size")
        
        await asyncio.sleep(10)  # Check every 10 seconds
    
    print(f"Warning: File stability timeout after {timeout}s, proceeding anyway")
    return False


async def find_latest_research_json(deployment_id: str, output_dir: str = "/usr/src/app/outputs/") -> Optional[str]:
    """
    Find the latest JSON file in research output directory.
    
    Args:
        deployment_id: Docker deployment ID
        output_dir: Output directory path in container
        
    Returns:
        Path to latest JSON file or None
    """
    from .docker_manager import execute_container_command
    
    find_cmd = f"find {output_dir} -type f -name '*.json' -printf '%T@ %p\\n' | sort -n | tail -1 | cut -d' ' -f2-"
    
    result = await execute_container_command(
        command=find_cmd,
        deployment_id=deployment_id,
        workspace="/",
        timeout=10,
        live_output=False,
        raise_on_failure=False
    )
    
    if result.get("success") and result.get("stdout", "").strip():
        json_path = result["stdout"].strip()
        logger.info(f"Found latest JSON: {json_path}")
        return json_path
    
    return None


async def find_and_wait_for_stable_json(
    deployment_id: str,
    output_dir: str = "/usr/src/app/outputs/",
    timeout: int = 120
) -> Optional[str]:
    """
    Find latest research JSON and wait for it to be stable.
    Combined helper for Phase 2 and Phase 4.
    
    Args:
        deployment_id: Docker deployment ID
        output_dir: Output directory in container
        timeout: Maximum wait time for stability
        
    Returns:
        Path to stable JSON file in container, or None
    """
    # Find latest JSON
    json_path = await find_latest_research_json(deployment_id, output_dir)
    
    if not json_path:
        logger.warning(f"No JSON file found in {output_dir}")
        return None
    
    logger.info(f"Found JSON: {json_path}, waiting for stability...")
    
    # Wait for file to be stable
    is_stable = await wait_for_research_file_stability(deployment_id, json_path, timeout)
    
    if is_stable:
        return json_path
    else:
        logger.warning("File stability check timed out")
        return json_path  # Return anyway, file might still be usable


async def copy_research_results(
    deployment_id: str,
    output_dir: str = "/usr/src/app/outputs/",
    results_dir: str = None
) -> None:
    """
    Copy Research results after waiting for file stability.
    Includes JSON, DOCX, and PDF files.
    
    Args:
        deployment_id: Docker deployment ID
        output_dir: Container output directory
        results_dir: Local directory to save results
    """
    import time
    from .docker_manager import get_container_info
    
    # Use default if not provided
    if not results_dir:
        results_dir = os.getenv("RESULTS_DIR", "/home/shiqiu/AgentXploit/local_reports/research")
    
    os.makedirs(results_dir, exist_ok=True)
    
    logger.info("Research: Finding and waiting for file stability (Phase 4)")
    
    # Find latest JSON and wait for stability
    json_path = await find_and_wait_for_stable_json(deployment_id, output_dir, timeout=120)
    
    if not json_path:
        logger.warning("No stable JSON file found for Research")
        return
    
    # Get container info
    container_info = get_container_info(deployment_id)
    if not container_info:
        logger.warning("Container not found for Research file copy")
        return
    
    container_id = container_info.container_id
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    
    # Copy JSON file
    original_filename = os.path.basename(json_path)
    local_filename = f"research_{timestamp}_{original_filename}"
    local_path = os.path.join(results_dir, local_filename)
    
    copy_cmd = f"docker cp {container_id}:{json_path} {local_path}"
    
    process = await asyncio.create_subprocess_shell(
        copy_cmd,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE
    )
    
    stdout, stderr = await process.communicate()
    
    if process.returncode == 0:
        logger.info(f"Research results copied to: {local_path}")
        print(f"\n✓ Research JSON saved to: {local_path}")
    else:
        logger.warning(f"Failed to copy research results: {stderr.decode()}")
    
    # Copy docx and pdf files
    await _copy_research_documents(deployment_id, container_id, output_dir, results_dir, timestamp)


async def _copy_research_documents(
    deployment_id: str,
    container_id: str,
    output_dir: str,
    results_dir: str,
    timestamp: str
) -> None:
    """Copy generated docx and pdf documents from Research container."""
    from .docker_manager import execute_container_command
    
    for file_type in ["*.docx", "*.pdf"]:
        # Find latest file of this type
        find_cmd = f"find {output_dir} -type f -name '{file_type}' -printf '%T@ %p\\n' | sort -n | tail -1 | cut -d' ' -f2-"
        
        find_result = await execute_container_command(
            command=find_cmd,
            deployment_id=deployment_id,
            workspace="/",
            timeout=10,
            live_output=False,
            raise_on_failure=False
        )
        
        if find_result.get("success") and find_result.get("stdout", "").strip():
            doc_path = find_result["stdout"].strip()
            original_filename = os.path.basename(doc_path)
            local_filename = f"research_{timestamp}_{original_filename}"
            local_path = os.path.join(results_dir, local_filename)
            
            # Copy document
            copy_cmd = f"docker cp {container_id}:{doc_path} {local_path}"
            
            process = await asyncio.create_subprocess_shell(
                copy_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            stdout, stderr = await process.communicate()
            
            if process.returncode == 0:
                logger.info(f"Research document copied: {local_path}")
                print(f"✓ Research {file_type.replace('*', '')} saved to: {local_filename}")
            else:
                logger.warning(f"Failed to copy {file_type}: {stderr.decode()}")

