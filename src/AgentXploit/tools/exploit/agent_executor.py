"""
Agent Executor - Execute target agent tasks and analyze trace files

Handles:
1. Running target agent tasks based on config files
2. Reading trace logs from configured paths  
3. Analyzing traces for injection points
4. Focus on external data sources (GitHub issues, file content, API responses)
"""

import os
import json
import logging
import asyncio
from typing import Dict, List, Optional, Any, Union
from pathlib import Path
import toml

from .swerex import execute_command

logger = logging.getLogger(__name__)


class AgentExecutor:
    """Execute target agent tasks and analyze results."""
    
    def __init__(self, target_path: str, deployment_id: str):
        self.target_path = Path(target_path)
        self.deployment_id = deployment_id
        self.config_data = None
        self.trace_path = None
        
    async def detect_agent_config(self) -> Dict[str, Any]:
        """Detect agent configuration and execution setup."""
        
        logger.info(f"Detecting agent configuration in {self.target_path}")
        
        config_info = {
            "config_files": [],
            "run_commands": [],
            "trace_config": {},
            "agent_type": "unknown"
        }
        
        # Check for common config files
        config_files = [
            "config.json", "config.toml", "config.yaml", "config.py",
            "pyproject.toml", "package.json", "requirements.txt",
            "README.md", "run.py", "main.py", "app.py"
        ]
        
        for config_file in config_files:
            config_path = self.target_path / config_file
            if config_path.exists():
                config_info["config_files"].append(str(config_path))
                logger.info(f"Found config file: {config_file}")
        
        # Try to read and parse config files
        await self._parse_config_files(config_info)
        
        return config_info
    
    async def _parse_config_files(self, config_info: Dict[str, Any]):
        """Parse configuration files to extract run commands and trace settings."""
        
        for config_file in config_info["config_files"]:
            try:
                config_path = Path(config_file)
                
                if config_path.name == "config.json":
                    with open(config_path, 'r') as f:
                        data = json.load(f)
                        self._extract_from_json_config(data, config_info)
                
                elif config_path.name.endswith('.toml') or config_path.name == "pyproject.toml":
                    with open(config_path, 'r') as f:
                        data = toml.load(f)
                        self._extract_from_toml_config(data, config_info)
                
                elif config_path.name == "README.md":
                    with open(config_path, 'r') as f:
                        content = f.read()
                        self._extract_from_readme(content, config_info)
                
                elif config_path.name.endswith('.py'):
                    with open(config_path, 'r') as f:
                        content = f.read()
                        self._extract_from_python_file(content, config_info)
                        
            except Exception as e:
                logger.warning(f"Failed to parse {config_file}: {e}")
    
    def _extract_from_json_config(self, data: Dict, config_info: Dict):
        """Extract configuration from JSON file."""
        
        # Look for trace/logging configuration
        if "logging" in data:
            config_info["trace_config"].update(data["logging"])
        
        if "trace" in data:
            config_info["trace_config"].update(data["trace"])
            
        # Look for run commands
        if "run_command" in data:
            config_info["run_commands"].append(data["run_command"])
        
        if "commands" in data:
            config_info["run_commands"].extend(data["commands"])
    
    def _extract_from_toml_config(self, data: Dict, config_info: Dict):
        """Extract configuration from TOML file."""
        
        # Check for tool-specific configurations
        if "tool" in data:
            for tool_name, tool_config in data["tool"].items():
                if "logging" in tool_config:
                    config_info["trace_config"].update(tool_config["logging"])
                
                if "trace" in tool_config:
                    config_info["trace_config"].update(tool_config["trace"])
        
        # Check for scripts in pyproject.toml
        if "project" in data and "scripts" in data["project"]:
            for script_name, script_cmd in data["project"]["scripts"].items():
                config_info["run_commands"].append(script_cmd)
    
    def _extract_from_readme(self, content: str, config_info: Dict):
        """Extract run commands from README file."""
        
        lines = content.lower().split('\n')
        for line in lines:
            # Look for common run patterns
            if any(pattern in line for pattern in ["python", "run", "start", "execute"]):
                if any(cmd in line for cmd in ["python ", "npm ", "docker ", "./", "bash "]):
                    # Extract potential command
                    if '```' not in line and '#' not in line.strip()[:1]:
                        potential_cmd = line.strip('*-+ ').strip()
                        if len(potential_cmd) > 5 and len(potential_cmd) < 200:
                            config_info["run_commands"].append(potential_cmd)
    
    def _extract_from_python_file(self, content: str, config_info: Dict):
        """Extract information from Python files."""
        
        # Look for main execution patterns
        lines = content.split('\n')
        for line in lines:
            if 'logging' in line.lower() and ('file' in line or 'path' in line):
                # Try to extract logging configuration
                if '=' in line and ('"' in line or "'" in line):
                    config_info["trace_config"]["potential_log_path"] = line.strip()
    
    async def find_trace_files(self, custom_trace_path: str = None) -> List[str]:
        """Find trace files in the target directory."""
        
        if custom_trace_path:
            if os.path.exists(custom_trace_path):
                return [custom_trace_path]
            else:
                logger.warning(f"Custom trace path not found: {custom_trace_path}")
        
        trace_files = []
        
        # Common trace file patterns
        patterns = [
            "**/*trace*.json", "**/*log*.json", "**/*execution*.json",
            "**/*trace*.md", "**/*log*.md", "**/*execution*.md",
            "**/*trajectory*.json", "**/*session*.json", "**/*run*.json"
        ]
        
        for pattern in patterns:
            for file_path in self.target_path.glob(pattern):
                if file_path.is_file():
                    trace_files.append(str(file_path))
        
        # Also check common directories
        common_dirs = ["logs", "traces", "output", "results", "data"]
        for dir_name in common_dirs:
            dir_path = self.target_path / dir_name
            if dir_path.exists() and dir_path.is_dir():
                for file_path in dir_path.glob("*.json"):
                    trace_files.append(str(file_path))
                for file_path in dir_path.glob("*.md"):
                    trace_files.append(str(file_path))
        
        logger.info(f"Found {len(trace_files)} potential trace files")
        return trace_files
    
    async def execute_target_agent_task(
        self, 
        task_command: str = None,
        use_config: bool = True
    ) -> Dict[str, Any]:
        """Execute the target agent with a specific task."""
        
        logger.info("Executing target agent task")
        
        if use_config and not task_command:
            # Try to get command from config
            config_info = await self.detect_agent_config()
            if config_info["run_commands"]:
                task_command = config_info["run_commands"][0]
                logger.info(f"Using command from config: {task_command}")
        
        if not task_command:
            # Default commands to try
            default_commands = [
                "python main.py",
                "python app.py", 
                "python run.py",
                "python -m src",
                "npm start",
                "./run.sh"
            ]
            
            for cmd in default_commands:
                # Check if the referenced file exists
                main_file = cmd.split()[1] if len(cmd.split()) > 1 else None
                if main_file and (self.target_path / main_file).exists():
                    task_command = cmd
                    break
        
        if not task_command:
            task_command = "python --help"  # Fallback
            
        logger.info(f"Executing task command: {task_command}")
        
        # Execute in the target directory
        full_command = f"cd {self.target_path} && {task_command}"
        
        result = await execute_command(
            command=full_command,
            deployment_id=self.deployment_id,
            timeout=60.0  # Allow up to 1 minute for task execution
        )
        
        execution_result = {
            "command": task_command,
            "success": result.success,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "execution_time": "unknown"
        }
        
        logger.info(f"Task execution completed. Success: {result.success}")
        
        return execution_result
    
    async def analyze_trace_for_injection_points(
        self, 
        trace_files: List[str],
        llm_client = None
    ) -> Dict[str, Any]:
        """Analyze trace files to identify injection points."""
        
        logger.info(f"Analyzing {len(trace_files)} trace files for injection points")
        
        injection_points = []
        external_data_sources = []
        
        for trace_file in trace_files:
            try:
                with open(trace_file, 'r', encoding='utf-8', errors='ignore') as f:
                    if trace_file.endswith('.json'):
                        trace_data = json.load(f)
                    else:
                        trace_data = {"content": f.read()}
                
                file_analysis = await self._analyze_single_trace(trace_data, trace_file)
                injection_points.extend(file_analysis["injection_points"])
                external_data_sources.extend(file_analysis["external_sources"])
                
            except Exception as e:
                logger.warning(f"Failed to analyze trace file {trace_file}: {e}")
        
        # Deduplicate and rank injection points
        unique_injection_points = self._deduplicate_injection_points(injection_points)
        
        analysis_result = {
            "success": True,
            "total_trace_files": len(trace_files),
            "injection_points": unique_injection_points,
            "external_data_sources": external_data_sources,
            "high_risk_points": [p for p in unique_injection_points if p.get("risk", "").upper() == "HIGH"],
            "overall_risk": "HIGH" if any(p.get("risk", "").upper() == "HIGH" for p in unique_injection_points) else "MEDIUM"
        }
        
        return analysis_result
    
    async def _analyze_single_trace(self, trace_data: Dict, file_path: str) -> Dict[str, Any]:
        """Analyze a single trace file for injection points."""
        
        injection_points = []
        external_sources = []
        
        # Convert trace data to searchable text
        trace_text = json.dumps(trace_data) if isinstance(trace_data, dict) else str(trace_data)
        
        # Patterns indicating external data sources
        external_patterns = [
            ("github", "GitHub API/Issue data"),
            ("http://", "HTTP request"),
            ("https://", "HTTPS request"),
            ("api", "API call"),
            ("fetch", "Data fetching"),
            ("request", "Network request"),
            ("download", "File download"),
            ("user_input", "User input"),
            ("stdin", "Standard input"),
            ("file", "File read"),
            ("json", "JSON data"),
            ("xml", "XML data"),
            ("csv", "CSV data")
        ]
        
        # Tool call patterns that might be injectable
        tool_patterns = [
            ("execute", "Command execution"),
            ("run", "Code/script execution"),
            ("eval", "Code evaluation"),
            ("subprocess", "Process execution"),
            ("shell", "Shell command"),
            ("system", "System call"),
            ("write", "File write"),
            ("create", "File/resource creation")
        ]
        
        # Check for external data sources
        for pattern, description in external_patterns:
            if pattern in trace_text.lower():
                external_sources.append({
                    "type": pattern,
                    "description": description,
                    "file": file_path
                })
        
        # Check for potential injection points
        for tool_pattern, tool_desc in tool_patterns:
            if tool_pattern in trace_text.lower():
                # Look for external data flow to this tool
                for ext_pattern, ext_desc in external_patterns:
                    if ext_pattern in trace_text.lower():
                        injection_points.append({
                            "type": f"{ext_desc} -> {tool_desc}",
                            "source": ext_pattern,
                            "target": tool_pattern,
                            "risk": self._assess_risk(ext_pattern, tool_pattern),
                            "file": file_path,
                            "description": f"External {ext_desc} data flows to {tool_desc}"
                        })
        
        # Special focus on GitHub/SWE-Bench patterns
        if "github" in trace_text.lower() or "issue" in trace_text.lower():
            if any(pattern in trace_text.lower() for pattern in ["execute", "run", "eval", "subprocess"]):
                injection_points.append({
                    "type": "GitHub Issue -> Code Execution",
                    "source": "github_issue",
                    "target": "code_execution",
                    "risk": "HIGH",
                    "file": file_path,
                    "description": "GitHub issue content can potentially influence code execution (SWE-Bench vulnerability)"
                })
        
        return {
            "injection_points": injection_points,
            "external_sources": external_sources
        }
    
    def _assess_risk(self, source: str, target: str) -> str:
        """Assess risk level of injection point."""
        
        high_risk_sources = ["github", "http", "https", "user_input", "stdin"]
        high_risk_targets = ["execute", "eval", "subprocess", "shell", "system"]
        
        if source in high_risk_sources and target in high_risk_targets:
            return "HIGH"
        elif source in high_risk_sources or target in high_risk_targets:
            return "MEDIUM"
        else:
            return "LOW"
    
    def _deduplicate_injection_points(self, injection_points: List[Dict]) -> List[Dict]:
        """Remove duplicate injection points."""
        
        seen = set()
        unique_points = []
        
        for point in injection_points:
            key = (point.get("type"), point.get("source"), point.get("target"))
            if key not in seen:
                seen.add(key)
                unique_points.append(point)
        
        # Sort by risk level (HIGH first)
        risk_order = {"HIGH": 0, "MEDIUM": 1, "LOW": 2}
        unique_points.sort(key=lambda p: risk_order.get(p.get("risk"), 3))
        
        return unique_points


async def execute_agent_with_trace_analysis(
    target_path: str,
    deployment_id: str,
    task_command: str = None,
    custom_trace_path: str = None
) -> Dict[str, Any]:
    """Complete workflow: execute agent task and analyze traces."""
    
    executor = AgentExecutor(target_path, deployment_id)
    
    # Step 1: Execute target agent task
    logger.info("Step 1: Executing target agent task")
    execution_result = await executor.execute_target_agent_task(task_command)
    
    # Step 2: Find and analyze trace files
    logger.info("Step 2: Finding trace files")
    trace_files = await executor.find_trace_files(custom_trace_path)
    
    if not trace_files:
        logger.warning("No trace files found, using execution output as trace")
        # Create a temporary trace from execution output
        temp_trace = {
            "execution_output": execution_result,
            "stdout": execution_result.get("stdout", ""),
            "stderr": execution_result.get("stderr", ""),
            "command": execution_result.get("command", "")
        }
        
        analysis_result = await executor._analyze_single_trace(temp_trace, "execution_output")
        analysis_result["success"] = True
        analysis_result["total_trace_files"] = 0
    else:
        logger.info("Step 3: Analyzing trace files for injection points")
        analysis_result = await executor.analyze_trace_for_injection_points(trace_files)
    
    return {
        "execution_result": execution_result,
        "trace_analysis": analysis_result,
        "trace_files_found": len(trace_files),
        "target_path": target_path
    }


# Export main functions
__all__ = [
    'AgentExecutor',
    'execute_agent_with_trace_analysis'
]